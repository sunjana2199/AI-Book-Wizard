{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WuWoDclMu_QF"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnO_99aevGTp",
        "outputId": "caef18d7-3ab4-4036-9037-299de127fef2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/final_data.csv')"
      ],
      "metadata": {
        "id": "K3TwIWjLvKpK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Open the zip file\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/images3-20221221T145509Z-001.zip', 'r') as zip_ref:\n",
        "    # Extract the contents to a directory\n",
        "    zip_ref.extractall('/content/')"
      ],
      "metadata": {
        "id": "-KcD9pS9vRQd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "folder = '/content/images3'\n",
        "image_filenames = os.listdir(folder)\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for filename in image_filenames:\n",
        "    try:\n",
        "        isbn = filename.split('.')[0]\n",
        "        rating = df[df['ISBN'] == isbn]['Book-Rating'].iloc[0]\n",
        "        img = cv2.imread(f'{folder}/{filename}')\n",
        "        img = cv2.resize(img, (64, 64)) \n",
        "        X.append(img)\n",
        "        y.append(rating)\n",
        "    except:\n",
        "        print('Loading')\n",
        "\n"
      ],
      "metadata": {
        "id": "XXdejV4bvTh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models, layers\n",
        "print(tf.config.list_physical_devices('GPU'))\n",
        "with tf.device('GPU:0'):  # specify that the block of code should run on GPU:0\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dense(1))\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBgyXDI-vVYH",
        "outputId": "9225a583-abb2-4f4a-8b29-75d5b51792f9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MgW5qKIqrJ6",
        "outputId": "b8acfd6e-d7cb-41b0-cd87-30146e5b722a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 64)        36928     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                589888    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 646,273\n",
            "Trainable params: 646,273\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y)"
      ],
      "metadata": {
        "id": "Y9P-8bnfwvQs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "y_train_tensor = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
        "X_test_tensor=tf.convert_to_tensor(X_test,dtype=tf.float32)\n",
        "y_test_tensor=tf.convert_to_tensor(y_test,dtype=tf.float32)\n"
      ],
      "metadata": {
        "id": "fju3kxxhwwX5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_tensor, y_train_tensor))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(32)\n"
      ],
      "metadata": {
        "id": "cLujldJnw2H4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Create a directory to store the models\n",
        "model_dir = \"models\"\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "\n",
        "# Get the number of batches in the dataset\n",
        "num_batches = tf.data.experimental.cardinality(train_dataset).numpy()\n",
        "\n",
        "# Initialize variables to keep track of the best validation accuracy and the corresponding model\n",
        "best_val_loss = float(\"inf\")\n",
        "best_model = None\n",
        "\n",
        "# Create lists to store the loss and accuracy for each epoch\n",
        "loss_history = []\n",
        "val_loss_history = []\n",
        "\n",
        "# Iterate over the dataset and train the model for 10 epochs\n",
        "for epoch in range(10):\n",
        "    epoch_loss = []  # store the loss for each epoch\n",
        "    epoch_val_loss = []  # store the validation loss for each epoch\n",
        "\n",
        "    for _ in range(num_batches):\n",
        "        X_batch, y_batch = next(iter(train_dataset))\n",
        "        result = model.fit(X_batch, y_batch, epochs=1, validation_data=(X_test_tensor, y_test_tensor))  # include validation data\n",
        "        epoch_loss.append(result.history[\"loss\"])  # add loss to epoch_loss list\n",
        "        epoch_val_loss.append(result.history[\"val_loss\"])  # add validation loss to epoch_val_loss list\n",
        "\n",
        "    # Calculate the mean loss and accuracy for the epoch\n",
        "    mean_loss = np.mean(epoch_loss)\n",
        "    mean_val_loss = np.mean(epoch_val_loss)\n",
        "\n",
        "    # Append the mean loss and accuracy to the history lists\n",
        "    loss_history.append(mean_loss)\n",
        "    val_loss_history.append(mean_val_loss)\n",
        "\n",
        "    # If the current validation accuracy is the best so far, save the model\n",
        "    if mean_val_loss < best_val_loss:\n",
        "        best_val_loss = mean_val_loss\n",
        "        best_model = model\n",
        "        model.save(os.path.join(model_dir, \"best_model.h5\"))\n",
        "\n",
        "# Plot the loss and accuracy over every epoch\n",
        "plt.plot(loss_history, label=\"loss\")\n",
        "plt.plot(val_loss_history, label=\"validation loss\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oiCJD_-Nwb4V",
        "outputId": "0eed2f57-e6c1-4b76-8c3e-365356f68fc4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.0511 - val_loss: 10.3248\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.0902 - val_loss: 10.1568\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.0657 - val_loss: 10.0423\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.1020 - val_loss: 10.0816\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1046 - val_loss: 10.3310\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0410 - val_loss: 10.6053\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1080 - val_loss: 10.6500\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1578 - val_loss: 10.3756\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0736 - val_loss: 10.2179\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.1082 - val_loss: 10.1712\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.0796 - val_loss: 10.2332\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0570 - val_loss: 10.3411\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0489 - val_loss: 10.4933\n",
            "1/1 [==============================] - 1s 871ms/step - loss: 0.1116 - val_loss: 10.4671\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.2865 - val_loss: 10.2547\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0923 - val_loss: 10.0725\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.0729 - val_loss: 10.0403\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1050 - val_loss: 10.0793\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.0805 - val_loss: 10.1637\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0798 - val_loss: 10.2688\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.0645 - val_loss: 10.3645\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.0732 - val_loss: 10.3026\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.0335 - val_loss: 10.2395\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.0765 - val_loss: 10.2155\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 0.0699 - val_loss: 10.2784\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.1222 - val_loss: 10.4594\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1945 - val_loss: 10.5733\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1019 - val_loss: 10.3594\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1038 - val_loss: 10.1955\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1460 - val_loss: 10.1420\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.1181 - val_loss: 10.2482\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0564 - val_loss: 10.4524\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.1014 - val_loss: 10.5939\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.1454 - val_loss: 10.4482\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1447 - val_loss: 10.2896\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.0399 - val_loss: 10.1973\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0750 - val_loss: 10.2224\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1509 - val_loss: 10.4458\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.0796 - val_loss: 10.6330\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.1418 - val_loss: 10.6610\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1412 - val_loss: 10.4783\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.1270 - val_loss: 10.2503\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 0.0263 - val_loss: 10.0946\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0743 - val_loss: 10.0447\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0832 - val_loss: 10.1195\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2276 - val_loss: 10.4125\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0507 - val_loss: 10.5802\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1052 - val_loss: 10.4391\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.0663 - val_loss: 10.2257\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.0860 - val_loss: 10.1363\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3056 - val_loss: 10.1228\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1200 - val_loss: 10.1808\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.0871 - val_loss: 10.3737\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.0569 - val_loss: 10.6301\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1372 - val_loss: 10.6870\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.1563 - val_loss: 10.4003\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1400 - val_loss: 10.1231\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0950 - val_loss: 10.0272\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1760 - val_loss: 10.0847\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.1913 - val_loss: 10.3361\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.1786 - val_loss: 10.6099\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2870 - val_loss: 10.7425\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.1772 - val_loss: 10.3327\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.1723 - val_loss: 10.0745\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.1401 - val_loss: 9.9803\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.1785 - val_loss: 10.0328\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2089 - val_loss: 10.3691\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3818 - val_loss: 10.6762\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4235 - val_loss: 10.5445\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1709 - val_loss: 10.3017\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.1312 - val_loss: 10.2023\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3930 - val_loss: 10.2470\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.2545 - val_loss: 10.4224\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1973 - val_loss: 10.7065\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2738 - val_loss: 10.5968\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1805 - val_loss: 10.3183\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1317 - val_loss: 10.1300\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1370 - val_loss: 10.0742\n",
            "1/1 [==============================] - 1s 861ms/step - loss: 0.2479 - val_loss: 10.2433\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0875 - val_loss: 10.2651\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.2469 - val_loss: 10.3075\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1084 - val_loss: 10.3154\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1840 - val_loss: 10.1850\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2613 - val_loss: 10.1292\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.1346 - val_loss: 10.1305\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0873 - val_loss: 10.2013\n",
            "1/1 [==============================] - 1s 897ms/step - loss: 0.0968 - val_loss: 10.3278\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1981 - val_loss: 10.4876\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.1312 - val_loss: 10.6916\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.3623 - val_loss: 10.6249\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1378 - val_loss: 10.4199\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2352 - val_loss: 10.3409\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.1910 - val_loss: 10.4855\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.1414 - val_loss: 10.7262\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.1347 - val_loss: 10.8302\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2232 - val_loss: 10.5452\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2583 - val_loss: 10.1591\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2118 - val_loss: 10.0113\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.0968 - val_loss: 10.0131\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.2425 - val_loss: 10.2080\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.1713 - val_loss: 10.4746\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.1268 - val_loss: 10.6062\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.3081 - val_loss: 10.3997\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1208 - val_loss: 10.3270\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.2247 - val_loss: 10.3887\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0845 - val_loss: 10.4763\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0931 - val_loss: 10.5038\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.1097 - val_loss: 10.4880\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1341 - val_loss: 10.4690\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0749 - val_loss: 10.5097\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1223 - val_loss: 10.4186\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.1925 - val_loss: 10.2860\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1701 - val_loss: 10.2321\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0917 - val_loss: 10.2323\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3207 - val_loss: 10.4265\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1037 - val_loss: 10.4097\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1552 - val_loss: 10.2843\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1653 - val_loss: 10.0972\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.2614 - val_loss: 10.0241\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2526 - val_loss: 10.0671\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1772 - val_loss: 10.1417\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.1044 - val_loss: 10.2567\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.1093 - val_loss: 10.3559\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.1245 - val_loss: 10.2995\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.1691 - val_loss: 10.0854\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1194 - val_loss: 10.0168\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2166 - val_loss: 10.1223\n",
            "1/1 [==============================] - 1s 860ms/step - loss: 0.0882 - val_loss: 10.3816\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.0735 - val_loss: 10.6122\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1740 - val_loss: 10.4952\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.0711 - val_loss: 10.3749\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0776 - val_loss: 10.2721\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.1394 - val_loss: 10.2356\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1316 - val_loss: 10.2594\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.0982 - val_loss: 10.4055\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.1404 - val_loss: 10.4876\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.1237 - val_loss: 10.3884\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2532 - val_loss: 10.1455\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0947 - val_loss: 10.0644\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.4070 - val_loss: 10.2010\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1036 - val_loss: 10.4870\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1400 - val_loss: 10.7669\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2722 - val_loss: 10.5367\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1677 - val_loss: 10.1905\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0593 - val_loss: 10.0459\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1445 - val_loss: 10.0727\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2259 - val_loss: 10.2788\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0814 - val_loss: 10.5366\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.1876 - val_loss: 10.5359\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.1803 - val_loss: 10.2042\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1333 - val_loss: 10.0312\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1876 - val_loss: 10.0239\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2098 - val_loss: 10.1807\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.1234 - val_loss: 10.5992\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1863 - val_loss: 10.8231\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.2647 - val_loss: 10.3742\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1147 - val_loss: 10.0500\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.2514 - val_loss: 10.0047\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3782 - val_loss: 10.2390\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.1682 - val_loss: 10.5608\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2358 - val_loss: 10.5866\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3308 - val_loss: 10.0930\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0737 - val_loss: 9.8693\n",
            "1/1 [==============================] - 1s 871ms/step - loss: 0.1624 - val_loss: 9.8935\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1533 - val_loss: 10.0046\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2093 - val_loss: 10.2426\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2047 - val_loss: 10.4327\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3185 - val_loss: 10.2383\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1417 - val_loss: 10.0057\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2428 - val_loss: 10.0241\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.1792 - val_loss: 10.1449\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.1353 - val_loss: 10.3336\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1947 - val_loss: 10.3593\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1033 - val_loss: 10.2553\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1389 - val_loss: 10.2620\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 0.2290 - val_loss: 10.0628\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3181 - val_loss: 10.0070\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.2264 - val_loss: 10.0909\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1448 - val_loss: 10.2783\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1155 - val_loss: 10.4804\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1181 - val_loss: 10.6000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1849 - val_loss: 10.4749\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.2273 - val_loss: 10.0564\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.1837 - val_loss: 9.8130\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1875 - val_loss: 9.7715\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3219 - val_loss: 9.8170\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.4120 - val_loss: 10.0349\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.1300 - val_loss: 10.3397\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.1945 - val_loss: 10.3751\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.3429 - val_loss: 10.1020\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.3482 - val_loss: 9.9677\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2790 - val_loss: 10.0359\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 0.3767 - val_loss: 10.3514\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1553 - val_loss: 10.7631\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.2141 - val_loss: 10.8813\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5015 - val_loss: 10.2929\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1341 - val_loss: 10.1063\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5048 - val_loss: 10.1810\n",
            "1/1 [==============================] - 1s 878ms/step - loss: 0.2103 - val_loss: 10.4728\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0935 - val_loss: 10.8638\n",
            "1/1 [==============================] - 1s 873ms/step - loss: 0.2691 - val_loss: 10.6456\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.1626 - val_loss: 10.3480\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.1419 - val_loss: 10.1125\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2470 - val_loss: 10.0357\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2952 - val_loss: 10.0960\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2745 - val_loss: 10.3873\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.1348 - val_loss: 10.6085\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.2990 - val_loss: 10.4382\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2544 - val_loss: 10.0252\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1421 - val_loss: 9.8298\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 0.2017 - val_loss: 9.8102\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.1966 - val_loss: 9.9468\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1590 - val_loss: 10.2068\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.2748 - val_loss: 10.5583\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2608 - val_loss: 10.4535\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.2488 - val_loss: 10.1096\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3865 - val_loss: 9.9993\n",
            "1/1 [==============================] - 1s 861ms/step - loss: 0.2063 - val_loss: 10.0588\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2228 - val_loss: 10.3966\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.1724 - val_loss: 10.6039\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.1956 - val_loss: 10.3765\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.2012 - val_loss: 10.1435\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1447 - val_loss: 10.0391\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2404 - val_loss: 10.0705\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4842 - val_loss: 10.4241\n",
            "1/1 [==============================] - 1s 872ms/step - loss: 0.2465 - val_loss: 10.5202\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1867 - val_loss: 10.4788\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.2764 - val_loss: 10.1143\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4858 - val_loss: 9.9338\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4600 - val_loss: 9.9670\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.2918 - val_loss: 10.2053\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.1188 - val_loss: 10.5018\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.1947 - val_loss: 10.5906\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.3340 - val_loss: 10.3747\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4290 - val_loss: 10.1954\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2972 - val_loss: 10.0393\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3249 - val_loss: 10.0489\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.1351 - val_loss: 10.1311\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.1341 - val_loss: 10.2015\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.1977 - val_loss: 10.1853\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.1469 - val_loss: 10.0896\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1414 - val_loss: 10.0819\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1274 - val_loss: 10.1657\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2942 - val_loss: 10.4038\n",
            "1/1 [==============================] - 1s 868ms/step - loss: 0.3144 - val_loss: 10.4499\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.3459 - val_loss: 10.3847\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2858 - val_loss: 10.4641\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.1452 - val_loss: 10.5225\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1157 - val_loss: 10.5040\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2093 - val_loss: 10.2942\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1630 - val_loss: 10.0529\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.2649 - val_loss: 10.0029\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2048 - val_loss: 10.0500\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.1641 - val_loss: 10.1255\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.2386 - val_loss: 10.2734\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.1861 - val_loss: 10.2259\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1791 - val_loss: 10.1068\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1854 - val_loss: 10.1800\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.2731 - val_loss: 10.2987\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.4242 - val_loss: 10.3912\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1457 - val_loss: 10.5717\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2283 - val_loss: 10.3036\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.1424 - val_loss: 10.0304\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2245 - val_loss: 9.9098\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2217 - val_loss: 9.9348\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1140 - val_loss: 10.1370\n",
            "1/1 [==============================] - 1s 860ms/step - loss: 0.1630 - val_loss: 10.3080\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2186 - val_loss: 10.1862\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2996 - val_loss: 9.8983\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1489 - val_loss: 9.7020\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.1497 - val_loss: 9.6725\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1486 - val_loss: 9.7455\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.1524 - val_loss: 10.0011\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.1999 - val_loss: 10.4122\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.2308 - val_loss: 10.4943\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2239 - val_loss: 10.1394\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1024 - val_loss: 9.8623\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.1489 - val_loss: 9.8223\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.2591 - val_loss: 9.9117\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2655 - val_loss: 10.2144\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1446 - val_loss: 10.5120\n",
            "1/1 [==============================] - 1s 860ms/step - loss: 0.4180 - val_loss: 10.4471\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.1651 - val_loss: 10.1886\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.1517 - val_loss: 9.9543\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1576 - val_loss: 9.9030\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2165 - val_loss: 9.9664\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.8091 - val_loss: 10.1178\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.1790 - val_loss: 10.1605\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2985 - val_loss: 10.2209\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.2751 - val_loss: 10.2078\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1772 - val_loss: 9.9820\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1958 - val_loss: 9.8843\n",
            "1/1 [==============================] - 1s 882ms/step - loss: 0.2794 - val_loss: 9.9456\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.3028 - val_loss: 10.2436\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.2991 - val_loss: 10.5726\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1953 - val_loss: 10.5310\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.1799 - val_loss: 10.2005\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3206 - val_loss: 10.0826\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4465 - val_loss: 10.1857\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0881 - val_loss: 10.3351\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2394 - val_loss: 10.5290\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3810 - val_loss: 10.5660\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.2673 - val_loss: 10.3503\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1301 - val_loss: 10.1089\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3343 - val_loss: 10.0119\n",
            "1/1 [==============================] - 1s 871ms/step - loss: 0.2436 - val_loss: 10.0168\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.0875 - val_loss: 10.0936\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.1240 - val_loss: 10.2243\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.2984 - val_loss: 10.5259\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2863 - val_loss: 10.3714\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.2442 - val_loss: 9.9886\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.0850 - val_loss: 9.8031\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4092 - val_loss: 9.8877\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.1334 - val_loss: 10.0872\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.1641 - val_loss: 10.4282\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.1468 - val_loss: 10.5018\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.1831 - val_loss: 10.3000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2313 - val_loss: 10.1355\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.2067 - val_loss: 10.0657\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1657 - val_loss: 10.1981\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2254 - val_loss: 10.3019\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.1456 - val_loss: 10.3108\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.2122 - val_loss: 10.0657\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.1186 - val_loss: 9.9061\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.2638 - val_loss: 9.9128\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.3756 - val_loss: 10.0866\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1992 - val_loss: 10.2283\n",
            "1/1 [==============================] - 1s 873ms/step - loss: 0.1712 - val_loss: 10.1355\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.1581 - val_loss: 10.0700\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1596 - val_loss: 10.1184\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.1679 - val_loss: 10.2558\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.2151 - val_loss: 10.3987\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 0.2425 - val_loss: 10.4317\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.2520 - val_loss: 10.2991\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2587 - val_loss: 10.1552\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1275 - val_loss: 10.1074\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.2960 - val_loss: 10.0303\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.1762 - val_loss: 9.9838\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2711 - val_loss: 9.8687\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.1461 - val_loss: 9.8629\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.1653 - val_loss: 9.9659\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.1040 - val_loss: 10.1692\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.1094 - val_loss: 10.3332\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.1031 - val_loss: 10.2982\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.1266 - val_loss: 10.1391\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.1220 - val_loss: 10.0901\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.1677 - val_loss: 10.1338\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1989 - val_loss: 10.2807\n",
            "1/1 [==============================] - 1s 878ms/step - loss: 0.2727 - val_loss: 10.4175\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1703 - val_loss: 10.3861\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2646 - val_loss: 10.2540\n",
            "1/1 [==============================] - 1s 896ms/step - loss: 0.1129 - val_loss: 9.9880\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.0881 - val_loss: 9.8785\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3514 - val_loss: 9.8878\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.0821 - val_loss: 9.9511\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3579 - val_loss: 10.0612\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0512 - val_loss: 10.2463\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.3992 - val_loss: 10.2441\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.1144 - val_loss: 10.1699\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0844 - val_loss: 10.0973\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.1614 - val_loss: 10.0698\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1904 - val_loss: 10.0951\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1149 - val_loss: 10.1318\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1283 - val_loss: 10.2098\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.1182 - val_loss: 10.2426\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.3992 - val_loss: 10.1425\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0986 - val_loss: 10.0456\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2543 - val_loss: 10.0670\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.1407 - val_loss: 10.1765\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.1720 - val_loss: 10.2973\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.1745 - val_loss: 10.3186\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.2081 - val_loss: 10.2648\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.1348 - val_loss: 10.2472\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1382 - val_loss: 10.2105\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 0.1479 - val_loss: 10.0937\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3849 - val_loss: 9.9423\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2374 - val_loss: 9.8577\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.2446 - val_loss: 10.0143\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.1061 - val_loss: 10.3529\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2254 - val_loss: 10.2633\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2136 - val_loss: 10.0320\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1198 - val_loss: 9.9738\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1665 - val_loss: 9.9869\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.1959 - val_loss: 10.1751\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1619 - val_loss: 10.2812\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.1220 - val_loss: 10.2701\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.1620 - val_loss: 10.1649\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.0802 - val_loss: 10.1140\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.3491 - val_loss: 10.1895\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1848 - val_loss: 10.3903\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.2274 - val_loss: 10.5691\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2230 - val_loss: 10.3715\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1060 - val_loss: 10.1634\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.1758 - val_loss: 10.0569\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3133 - val_loss: 10.0120\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.6128 - val_loss: 10.2183\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2363 - val_loss: 10.7318\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.3428 - val_loss: 10.5117\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.2572 - val_loss: 10.0553\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1972 - val_loss: 9.9925\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.2741 - val_loss: 10.1332\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2591 - val_loss: 10.4205\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1700 - val_loss: 10.7775\n",
            "1/1 [==============================] - 1s 890ms/step - loss: 0.2041 - val_loss: 10.7365\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.3348 - val_loss: 10.1849\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1532 - val_loss: 9.8398\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2653 - val_loss: 9.6871\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.5062 - val_loss: 9.6516\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5044 - val_loss: 9.8217\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3396 - val_loss: 10.3022\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.5362 - val_loss: 10.4246\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6658 - val_loss: 10.0420\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1542 - val_loss: 9.9267\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3652 - val_loss: 10.0610\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4343 - val_loss: 10.4584\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.2624 - val_loss: 11.0830\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4846 - val_loss: 11.1442\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4337 - val_loss: 10.4885\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3435 - val_loss: 10.0301\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.4314 - val_loss: 9.8734\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.2867 - val_loss: 9.7830\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3082 - val_loss: 9.9552\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.2047 - val_loss: 10.1717\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2669 - val_loss: 10.1389\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.3408 - val_loss: 9.7578\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.2592 - val_loss: 9.5217\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.2805 - val_loss: 9.4687\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3108 - val_loss: 9.6439\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1566 - val_loss: 9.9494\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1895 - val_loss: 10.3382\n",
            "1/1 [==============================] - 1s 859ms/step - loss: 0.2359 - val_loss: 10.5545\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2822 - val_loss: 10.3795\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.2204 - val_loss: 10.1093\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1686 - val_loss: 10.0534\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.4943 - val_loss: 10.1097\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3433 - val_loss: 10.3487\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1305 - val_loss: 10.4193\n",
            "1/1 [==============================] - 1s 869ms/step - loss: 0.2146 - val_loss: 10.0757\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.2885 - val_loss: 9.6091\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.4551 - val_loss: 9.4674\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.3584 - val_loss: 9.4843\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5313 - val_loss: 9.8541\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.1987 - val_loss: 10.8101\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.6008 - val_loss: 10.8285\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4934 - val_loss: 10.1621\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1899 - val_loss: 10.0233\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.5122 - val_loss: 9.9682\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.6425 - val_loss: 10.1336\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2249 - val_loss: 10.6735\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4520 - val_loss: 10.7526\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7004 - val_loss: 9.8926\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3498 - val_loss: 9.5362\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4113 - val_loss: 9.5460\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3851 - val_loss: 9.8694\n",
            "1/1 [==============================] - 1s 907ms/step - loss: 0.1716 - val_loss: 10.4029\n",
            "1/1 [==============================] - 1s 859ms/step - loss: 0.2086 - val_loss: 10.7622\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.5993 - val_loss: 10.0992\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.5138 - val_loss: 9.7841\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4941 - val_loss: 9.7059\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.5886 - val_loss: 9.7129\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4766 - val_loss: 9.9090\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2815 - val_loss: 10.2229\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.3876 - val_loss: 10.3422\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.4194 - val_loss: 10.0393\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2912 - val_loss: 9.8847\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2244 - val_loss: 9.9059\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.3251 - val_loss: 10.0362\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.3772 - val_loss: 10.3612\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.2542 - val_loss: 10.7198\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 0.2606 - val_loss: 10.7920\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4237 - val_loss: 10.5034\n",
            "1/1 [==============================] - 1s 869ms/step - loss: 0.3482 - val_loss: 10.1435\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3729 - val_loss: 9.9293\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 0.3944 - val_loss: 9.9706\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.1699 - val_loss: 10.2445\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.1563 - val_loss: 10.5051\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.4141 - val_loss: 10.1770\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1539 - val_loss: 9.9824\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.4157 - val_loss: 9.9671\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.4253 - val_loss: 10.0310\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.1865 - val_loss: 10.2458\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.2841 - val_loss: 10.3462\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.3162 - val_loss: 10.2295\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.1776 - val_loss: 9.9325\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.5216 - val_loss: 9.7224\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1999 - val_loss: 9.6778\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.4250 - val_loss: 9.9347\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.2134 - val_loss: 10.2689\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2253 - val_loss: 10.4077\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.3315 - val_loss: 10.3593\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5240 - val_loss: 10.2522\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.1277 - val_loss: 10.1996\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.2946 - val_loss: 10.1506\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2664 - val_loss: 10.2029\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4237 - val_loss: 10.0579\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1129 - val_loss: 9.9702\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0804 - val_loss: 9.9710\n",
            "1/1 [==============================] - 1s 879ms/step - loss: 0.2126 - val_loss: 10.0719\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.5747 - val_loss: 9.8974\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.1338 - val_loss: 9.7829\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3007 - val_loss: 9.7510\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4558 - val_loss: 9.8394\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.4426 - val_loss: 9.9765\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2031 - val_loss: 10.0417\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1602 - val_loss: 10.1885\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1455 - val_loss: 10.1801\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2208 - val_loss: 10.0979\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3311 - val_loss: 10.1558\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2669 - val_loss: 10.0516\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2886 - val_loss: 10.0369\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2818 - val_loss: 10.2546\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2608 - val_loss: 10.4075\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.1733 - val_loss: 10.4153\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3728 - val_loss: 9.8960\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.2159 - val_loss: 9.6483\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.2835 - val_loss: 9.6405\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2890 - val_loss: 9.7762\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.3445 - val_loss: 9.8919\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.2497 - val_loss: 10.0742\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1130 - val_loss: 10.3113\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2745 - val_loss: 10.3507\n",
            "1/1 [==============================] - 1s 871ms/step - loss: 0.2478 - val_loss: 10.2263\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.2505 - val_loss: 10.1009\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.1173 - val_loss: 10.0536\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.1457 - val_loss: 10.1428\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2116 - val_loss: 10.2506\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.0869 - val_loss: 10.4216\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2492 - val_loss: 10.3398\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1890 - val_loss: 10.1160\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.1629 - val_loss: 9.8309\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2594 - val_loss: 9.7332\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.4171 - val_loss: 9.6335\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1715 - val_loss: 9.5728\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 0.5660 - val_loss: 9.6809\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2255 - val_loss: 9.9204\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.1922 - val_loss: 10.0149\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.5523 - val_loss: 9.5545\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.2635 - val_loss: 9.3381\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2207 - val_loss: 9.3417\n",
            "1/1 [==============================] - 1s 900ms/step - loss: 0.3591 - val_loss: 9.4536\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.3409 - val_loss: 9.7786\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.2713 - val_loss: 10.2416\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2041 - val_loss: 10.5699\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2963 - val_loss: 10.2652\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3389 - val_loss: 9.7739\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0975 - val_loss: 9.6353\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.4515 - val_loss: 9.6419\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.3118 - val_loss: 9.8243\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1547 - val_loss: 10.1287\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2923 - val_loss: 10.7113\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.6362 - val_loss: 10.2097\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3826 - val_loss: 9.7414\n",
            "1/1 [==============================] - 1s 880ms/step - loss: 0.2121 - val_loss: 9.6018\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4886 - val_loss: 9.5440\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.3310 - val_loss: 9.6201\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1661 - val_loss: 10.0842\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.2985 - val_loss: 10.4387\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3346 - val_loss: 10.1663\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3441 - val_loss: 9.7399\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.1797 - val_loss: 9.6365\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.4844 - val_loss: 9.6927\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6847 - val_loss: 9.7381\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.5231 - val_loss: 10.0433\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2230 - val_loss: 10.7168\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5896 - val_loss: 10.2997\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4122 - val_loss: 9.6891\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2163 - val_loss: 9.4814\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.3552 - val_loss: 9.4775\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.5159 - val_loss: 9.5686\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.2684 - val_loss: 9.8016\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1471 - val_loss: 10.2908\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2300 - val_loss: 10.3236\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.3497 - val_loss: 10.0179\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.4070 - val_loss: 9.7231\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.2897 - val_loss: 9.6411\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.5127 - val_loss: 9.6714\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2908 - val_loss: 9.9255\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1254 - val_loss: 10.4847\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2620 - val_loss: 10.6497\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4480 - val_loss: 9.9855\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2365 - val_loss: 9.6281\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2593 - val_loss: 9.4746\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2218 - val_loss: 9.4626\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6527 - val_loss: 9.6788\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.2635 - val_loss: 10.2382\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.2990 - val_loss: 10.7577\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.4674 - val_loss: 10.3944\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2667 - val_loss: 9.8642\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.1394 - val_loss: 9.6187\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2066 - val_loss: 9.5136\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.3438 - val_loss: 9.5222\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2871 - val_loss: 9.7614\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.2027 - val_loss: 10.1699\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3676 - val_loss: 10.3910\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.4977 - val_loss: 9.8565\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1961 - val_loss: 9.6768\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1984 - val_loss: 9.6685\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.4635 - val_loss: 9.7377\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3653 - val_loss: 9.9523\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2507 - val_loss: 10.2506\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.1838 - val_loss: 10.4021\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3087 - val_loss: 10.2997\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2176 - val_loss: 10.1266\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.2768 - val_loss: 10.0138\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.5022 - val_loss: 10.1651\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2407 - val_loss: 10.3795\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.2367 - val_loss: 10.3357\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1912 - val_loss: 10.1280\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.2089 - val_loss: 10.0716\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.1602 - val_loss: 10.0142\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.2380 - val_loss: 10.1271\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2158 - val_loss: 10.1457\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.1234 - val_loss: 10.0515\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2378 - val_loss: 9.8731\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2488 - val_loss: 9.8340\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.2506 - val_loss: 9.8656\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1901 - val_loss: 10.1295\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.1802 - val_loss: 10.4860\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2890 - val_loss: 10.4049\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.4564 - val_loss: 10.0560\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1692 - val_loss: 9.8356\n",
            "1/1 [==============================] - 1s 888ms/step - loss: 0.2558 - val_loss: 9.7366\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2621 - val_loss: 9.8016\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.4081 - val_loss: 9.9717\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1488 - val_loss: 10.1401\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.1923 - val_loss: 10.2047\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.1829 - val_loss: 10.1489\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1947 - val_loss: 9.9949\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2559 - val_loss: 9.8437\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 0.1547 - val_loss: 9.8530\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2353 - val_loss: 10.0252\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4391 - val_loss: 10.0035\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.1655 - val_loss: 9.7748\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1909 - val_loss: 9.5235\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.1147 - val_loss: 9.4663\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.2659 - val_loss: 9.5796\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2017 - val_loss: 9.8581\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1443 - val_loss: 10.1662\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2136 - val_loss: 10.2160\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2641 - val_loss: 10.1711\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2239 - val_loss: 10.0681\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1219 - val_loss: 9.9495\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.1987 - val_loss: 9.9495\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.2685 - val_loss: 10.0173\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.0922 - val_loss: 10.0458\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.3926 - val_loss: 9.9436\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0795 - val_loss: 9.8180\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1582 - val_loss: 9.7247\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2343 - val_loss: 9.7657\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2782 - val_loss: 9.7759\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.1222 - val_loss: 9.8092\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1993 - val_loss: 9.9101\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.1574 - val_loss: 9.9941\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1069 - val_loss: 9.9140\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1483 - val_loss: 9.8071\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.1194 - val_loss: 9.7528\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.0970 - val_loss: 9.7290\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1441 - val_loss: 9.7712\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.2158 - val_loss: 9.8922\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.2122 - val_loss: 9.9230\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2041 - val_loss: 9.7260\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 0.1299 - val_loss: 9.5709\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1687 - val_loss: 9.5795\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.1777 - val_loss: 9.7210\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.2014 - val_loss: 10.0492\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1929 - val_loss: 10.3590\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.2588 - val_loss: 10.2841\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.2481 - val_loss: 10.0911\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 0.1197 - val_loss: 10.0187\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.1672 - val_loss: 10.0140\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2019 - val_loss: 10.0424\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.1925 - val_loss: 10.0036\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1288 - val_loss: 10.0364\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.1124 - val_loss: 9.9903\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1621 - val_loss: 9.9029\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1194 - val_loss: 9.8103\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.1348 - val_loss: 9.7173\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2562 - val_loss: 9.7557\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1971 - val_loss: 9.8325\n",
            "1/1 [==============================] - 1s 861ms/step - loss: 0.1311 - val_loss: 9.8224\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2062 - val_loss: 9.6514\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0899 - val_loss: 9.5599\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.1493 - val_loss: 9.5643\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.1566 - val_loss: 9.6230\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.0850 - val_loss: 9.6954\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.0853 - val_loss: 9.8155\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1751 - val_loss: 9.8781\n",
            "1/1 [==============================] - 1s 871ms/step - loss: 0.1653 - val_loss: 9.8868\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.1246 - val_loss: 9.8873\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.1051 - val_loss: 9.9475\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.0906 - val_loss: 10.1038\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1397 - val_loss: 10.1697\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0786 - val_loss: 10.1877\n",
            "1/1 [==============================] - 1s 868ms/step - loss: 0.1093 - val_loss: 10.0616\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.1290 - val_loss: 9.9165\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.0931 - val_loss: 9.8647\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1630 - val_loss: 9.9264\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0774 - val_loss: 9.9806\n",
            "1/1 [==============================] - 1s 859ms/step - loss: 0.0677 - val_loss: 10.0593\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0736 - val_loss: 10.0268\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1429 - val_loss: 9.7831\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.1221 - val_loss: 9.6633\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.0918 - val_loss: 9.6544\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3033 - val_loss: 9.7943\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.2306 - val_loss: 10.1241\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2631 - val_loss: 10.4665\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.2054 - val_loss: 10.3327\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1643 - val_loss: 9.9906\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1247 - val_loss: 9.8381\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2365 - val_loss: 9.8386\n",
            "1/1 [==============================] - 1s 870ms/step - loss: 0.2742 - val_loss: 9.9665\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0861 - val_loss: 10.2495\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.2088 - val_loss: 10.3492\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1115 - val_loss: 10.2726\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1236 - val_loss: 10.0947\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.1483 - val_loss: 9.8989\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.1253 - val_loss: 9.8603\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2188 - val_loss: 9.9109\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.2040 - val_loss: 10.0511\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1572 - val_loss: 10.3119\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1423 - val_loss: 10.4608\n",
            "1/1 [==============================] - 1s 872ms/step - loss: 0.2709 - val_loss: 10.1576\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2225 - val_loss: 9.7909\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1169 - val_loss: 9.6382\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1466 - val_loss: 9.5840\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.1541 - val_loss: 9.6795\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.1049 - val_loss: 9.8719\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0960 - val_loss: 10.0903\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.1688 - val_loss: 10.0830\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1367 - val_loss: 9.8281\n",
            "1/1 [==============================] - 1s 868ms/step - loss: 0.0539 - val_loss: 9.6761\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.1447 - val_loss: 9.6460\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2327 - val_loss: 9.7049\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1437 - val_loss: 9.8607\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.1490 - val_loss: 10.0851\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1099 - val_loss: 10.1232\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2004 - val_loss: 9.9906\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1302 - val_loss: 9.8592\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.2341 - val_loss: 9.8304\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1261 - val_loss: 9.8720\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.1951 - val_loss: 9.9465\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.1737 - val_loss: 9.9921\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0752 - val_loss: 9.9647\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0869 - val_loss: 9.8392\n",
            "1/1 [==============================] - 1s 868ms/step - loss: 0.0987 - val_loss: 9.7274\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.1290 - val_loss: 9.6995\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.3019 - val_loss: 9.8050\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.1341 - val_loss: 9.9979\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1658 - val_loss: 10.1134\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.1434 - val_loss: 10.0603\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2076 - val_loss: 9.7915\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2012 - val_loss: 9.7735\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.2113 - val_loss: 9.9196\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0774 - val_loss: 10.1495\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.0697 - val_loss: 10.2904\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.1526 - val_loss: 10.1847\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.1021 - val_loss: 10.0413\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.1849 - val_loss: 10.0232\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.1307 - val_loss: 10.0787\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1523 - val_loss: 10.2860\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1015 - val_loss: 10.3386\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.1568 - val_loss: 10.0777\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.0428 - val_loss: 9.9085\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.1325 - val_loss: 9.8604\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.0862 - val_loss: 9.8622\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 0.0685 - val_loss: 9.9034\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 0.0826 - val_loss: 9.9987\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.2393 - val_loss: 9.9373\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1532 - val_loss: 9.8074\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1941 - val_loss: 9.6241\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1417 - val_loss: 9.5804\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.1384 - val_loss: 9.6361\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3589 - val_loss: 9.7764\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.1513 - val_loss: 10.0595\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.1311 - val_loss: 10.1657\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1491 - val_loss: 10.0432\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.1772 - val_loss: 9.9442\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.1141 - val_loss: 9.9277\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.1139 - val_loss: 10.0000\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.2255 - val_loss: 10.1979\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2020 - val_loss: 10.2823\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2232 - val_loss: 10.0746\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0833 - val_loss: 9.9015\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.1288 - val_loss: 9.8146\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.1506 - val_loss: 9.7713\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.2083 - val_loss: 9.8016\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.1588 - val_loss: 9.9674\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1376 - val_loss: 10.1045\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2407 - val_loss: 9.9824\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1590 - val_loss: 9.8768\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4382 - val_loss: 9.8764\n",
            "1/1 [==============================] - 1s 860ms/step - loss: 0.1802 - val_loss: 9.9469\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.1824 - val_loss: 9.9921\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1222 - val_loss: 10.1144\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2585 - val_loss: 10.2653\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1227 - val_loss: 10.4245\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.2985 - val_loss: 9.9980\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1302 - val_loss: 9.6600\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1228 - val_loss: 9.5598\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2835 - val_loss: 9.5356\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3215 - val_loss: 9.6294\n",
            "1/1 [==============================] - 1s 878ms/step - loss: 0.1378 - val_loss: 9.9263\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.1175 - val_loss: 10.2695\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.1460 - val_loss: 10.3477\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3785 - val_loss: 9.8876\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.2885 - val_loss: 9.7299\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3338 - val_loss: 9.7268\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.3203 - val_loss: 9.7904\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.1182 - val_loss: 9.9460\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1811 - val_loss: 9.9863\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.1536 - val_loss: 9.9068\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.2566 - val_loss: 9.7273\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.1785 - val_loss: 9.8116\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.2391 - val_loss: 9.8260\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1258 - val_loss: 9.7761\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.1593 - val_loss: 9.7536\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1813 - val_loss: 9.8008\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0610 - val_loss: 9.8306\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2111 - val_loss: 9.9551\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2226 - val_loss: 9.9394\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1387 - val_loss: 9.8196\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.1142 - val_loss: 9.7155\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.1568 - val_loss: 9.7771\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0938 - val_loss: 9.8090\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.1656 - val_loss: 9.7889\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.1188 - val_loss: 9.7589\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1159 - val_loss: 9.7986\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0891 - val_loss: 9.7905\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1509 - val_loss: 9.9172\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.0953 - val_loss: 10.0099\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.1541 - val_loss: 9.8670\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1079 - val_loss: 9.7131\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1416 - val_loss: 9.6591\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0544 - val_loss: 9.6686\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2136 - val_loss: 9.7650\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.1029 - val_loss: 9.9939\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.1459 - val_loss: 10.2093\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1234 - val_loss: 10.2298\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1520 - val_loss: 10.0178\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.0684 - val_loss: 9.8376\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0922 - val_loss: 9.7573\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3014 - val_loss: 9.8134\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1459 - val_loss: 9.9868\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1560 - val_loss: 10.1744\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1152 - val_loss: 10.0981\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1360 - val_loss: 9.8702\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0655 - val_loss: 9.6826\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1088 - val_loss: 9.6075\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.1209 - val_loss: 9.6429\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0704 - val_loss: 9.7722\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0902 - val_loss: 9.9197\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.1043 - val_loss: 10.0309\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1269 - val_loss: 9.8951\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0729 - val_loss: 9.8058\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1942 - val_loss: 9.8269\n",
            "1/1 [==============================] - 1s 870ms/step - loss: 0.2075 - val_loss: 9.8354\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0656 - val_loss: 9.8788\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1275 - val_loss: 9.8344\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0625 - val_loss: 9.8253\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0625 - val_loss: 9.8146\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0611 - val_loss: 9.7998\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0744 - val_loss: 9.7235\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 0.0691 - val_loss: 9.7216\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1236 - val_loss: 9.8308\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.1443 - val_loss: 9.9309\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.1032 - val_loss: 9.9878\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0888 - val_loss: 9.9512\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0926 - val_loss: 9.9289\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.1760 - val_loss: 9.9644\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.1121 - val_loss: 9.8932\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1460 - val_loss: 9.8062\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.0864 - val_loss: 9.8333\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0746 - val_loss: 9.8439\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1313 - val_loss: 9.8505\n",
            "1/1 [==============================] - 1s 873ms/step - loss: 0.1158 - val_loss: 9.7980\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0399 - val_loss: 9.7294\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0901 - val_loss: 9.6572\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 0.0868 - val_loss: 9.6670\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.0840 - val_loss: 9.7054\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.0760 - val_loss: 9.6883\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0266 - val_loss: 9.7071\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1264 - val_loss: 9.8070\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0899 - val_loss: 9.9237\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.0776 - val_loss: 10.0039\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0584 - val_loss: 10.0139\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0509 - val_loss: 9.9517\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.1008 - val_loss: 9.8756\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.0720 - val_loss: 9.7846\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.0573 - val_loss: 9.7675\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.1069 - val_loss: 9.8304\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.0957 - val_loss: 10.0373\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.0785 - val_loss: 10.0852\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.1660 - val_loss: 9.8676\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0484 - val_loss: 9.6854\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.1017 - val_loss: 9.5922\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0832 - val_loss: 9.6044\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.1323 - val_loss: 9.7305\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.0347 - val_loss: 9.8743\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.2029 - val_loss: 9.9566\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1082 - val_loss: 9.8796\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1139 - val_loss: 9.8098\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0760 - val_loss: 9.8348\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6648 - val_loss: 9.9072\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.0637 - val_loss: 10.0275\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.1512 - val_loss: 10.0777\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.2283 - val_loss: 10.0066\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.0704 - val_loss: 9.8786\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.1087 - val_loss: 9.8174\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.1687 - val_loss: 9.8951\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.0958 - val_loss: 9.9990\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.0635 - val_loss: 10.0432\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1945 - val_loss: 9.8336\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.1176 - val_loss: 9.7457\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 0.0715 - val_loss: 9.7583\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.1008 - val_loss: 9.8203\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1767 - val_loss: 9.9113\n",
            "1/1 [==============================] - 1s 869ms/step - loss: 0.1086 - val_loss: 10.0301\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0674 - val_loss: 10.0678\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.1018 - val_loss: 9.9031\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1049 - val_loss: 9.7989\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.1300 - val_loss: 9.8201\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.0833 - val_loss: 9.9345\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.1755 - val_loss: 10.1049\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.1600 - val_loss: 10.1716\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.1090 - val_loss: 9.9713\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0668 - val_loss: 9.7862\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1779 - val_loss: 9.7810\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1012 - val_loss: 9.7251\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0826 - val_loss: 9.6961\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1013 - val_loss: 9.7458\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1108 - val_loss: 9.8192\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 0.0585 - val_loss: 9.8775\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.1035 - val_loss: 9.9702\n",
            "1/1 [==============================] - 1s 881ms/step - loss: 0.1397 - val_loss: 9.9784\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1652 - val_loss: 9.9063\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.0712 - val_loss: 9.8773\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0644 - val_loss: 9.8619\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.2007 - val_loss: 9.9477\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.0833 - val_loss: 10.0830\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0929 - val_loss: 10.1817\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.5473 - val_loss: 9.9090\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0506 - val_loss: 9.6856\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1704 - val_loss: 9.6893\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.1176 - val_loss: 9.7603\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0885 - val_loss: 9.9142\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0740 - val_loss: 10.1077\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1242 - val_loss: 10.1041\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.1039 - val_loss: 9.9514\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0810 - val_loss: 9.7965\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.0653 - val_loss: 9.7313\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.1254 - val_loss: 9.8022\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.1330 - val_loss: 10.0158\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0733 - val_loss: 10.1733\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1480 - val_loss: 10.0399\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0722 - val_loss: 9.8783\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0771 - val_loss: 9.8160\n",
            "1/1 [==============================] - 1s 872ms/step - loss: 0.1088 - val_loss: 9.8449\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1400 - val_loss: 10.0234\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1459 - val_loss: 9.9999\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.1168 - val_loss: 9.7924\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.0581 - val_loss: 9.6063\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0503 - val_loss: 9.5494\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1191 - val_loss: 9.6750\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.0622 - val_loss: 9.8811\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0776 - val_loss: 10.0743\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.0739 - val_loss: 10.0958\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0799 - val_loss: 10.0905\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.1034 - val_loss: 10.0326\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1244 - val_loss: 10.0942\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.0890 - val_loss: 10.0322\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.0509 - val_loss: 9.9773\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0412 - val_loss: 9.9107\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1339 - val_loss: 9.8325\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 0.1262 - val_loss: 9.8169\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.1088 - val_loss: 9.8144\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.0733 - val_loss: 9.7943\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0443 - val_loss: 9.7758\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0819 - val_loss: 9.7173\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0819 - val_loss: 9.7010\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.0869 - val_loss: 9.6977\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.0975 - val_loss: 9.6921\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.1193 - val_loss: 9.6701\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.0753 - val_loss: 9.8046\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.1442 - val_loss: 9.8971\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.0782 - val_loss: 9.9494\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1557 - val_loss: 9.9453\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.0751 - val_loss: 9.9893\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1120 - val_loss: 10.0033\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0950 - val_loss: 9.9186\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1075 - val_loss: 9.9153\n",
            "1/1 [==============================] - 1s 876ms/step - loss: 0.1570 - val_loss: 9.9213\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0523 - val_loss: 9.9599\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.0810 - val_loss: 9.9603\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1520 - val_loss: 9.9238\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.0956 - val_loss: 9.9007\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.1638 - val_loss: 9.7581\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.1071 - val_loss: 9.7102\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.1129 - val_loss: 9.7175\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.1080 - val_loss: 9.8447\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0550 - val_loss: 9.9288\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1617 - val_loss: 9.7534\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1244 - val_loss: 9.6677\n",
            "1/1 [==============================] - 1s 872ms/step - loss: 0.0884 - val_loss: 9.6178\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0845 - val_loss: 9.6350\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.0683 - val_loss: 9.7103\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.0479 - val_loss: 9.7725\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.0797 - val_loss: 9.7856\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.0694 - val_loss: 9.7522\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1936 - val_loss: 9.6153\n",
            "1/1 [==============================] - 1s 861ms/step - loss: 0.0438 - val_loss: 9.5850\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0823 - val_loss: 9.6882\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1152 - val_loss: 9.8428\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0821 - val_loss: 9.9979\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1367 - val_loss: 9.9996\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0709 - val_loss: 9.8587\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.1289 - val_loss: 9.8887\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.0577 - val_loss: 9.9039\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0696 - val_loss: 10.0057\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.0717 - val_loss: 10.1106\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.0885 - val_loss: 10.0944\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.0807 - val_loss: 9.9848\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 0.0724 - val_loss: 9.9167\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.0720 - val_loss: 9.9194\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.0687 - val_loss: 9.9861\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.0527 - val_loss: 9.9059\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0659 - val_loss: 9.8092\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0620 - val_loss: 9.7689\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0603 - val_loss: 9.7384\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.1364 - val_loss: 9.8522\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.0274 - val_loss: 9.9236\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0642 - val_loss: 9.8860\n",
            "1/1 [==============================] - 1s 874ms/step - loss: 0.0824 - val_loss: 9.7887\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.0587 - val_loss: 9.7755\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.0964 - val_loss: 9.8222\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0409 - val_loss: 9.8755\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.0808 - val_loss: 10.0118\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0936 - val_loss: 10.0668\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.1463 - val_loss: 10.0285\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.1916 - val_loss: 9.8482\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.0918 - val_loss: 9.6992\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1293 - val_loss: 9.7149\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0881 - val_loss: 9.7512\n",
            "1/1 [==============================] - 1s 872ms/step - loss: 0.0757 - val_loss: 9.8366\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0642 - val_loss: 9.9315\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 0.0927 - val_loss: 9.9949\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2064 - val_loss: 9.8422\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1330 - val_loss: 9.6800\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0535 - val_loss: 9.6606\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.0765 - val_loss: 9.7320\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.1484 - val_loss: 9.9240\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.1502 - val_loss: 9.9742\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1403 - val_loss: 9.7853\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1589 - val_loss: 9.7058\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1113 - val_loss: 9.7839\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1002 - val_loss: 9.9232\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0924 - val_loss: 9.9783\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.0665 - val_loss: 10.0839\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.1750 - val_loss: 10.0097\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.1489 - val_loss: 9.9349\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1439 - val_loss: 9.9398\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.0645 - val_loss: 9.8898\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0792 - val_loss: 9.8187\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0453 - val_loss: 9.8161\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.0733 - val_loss: 9.8759\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.1359 - val_loss: 9.9928\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0643 - val_loss: 9.9694\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0402 - val_loss: 9.9187\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0957 - val_loss: 9.7723\n",
            "1/1 [==============================] - 1s 868ms/step - loss: 0.0701 - val_loss: 9.7119\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.0528 - val_loss: 9.7418\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.1050 - val_loss: 9.8624\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 0.0733 - val_loss: 9.8884\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0903 - val_loss: 9.7919\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0670 - val_loss: 9.7542\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.0774 - val_loss: 9.7321\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.0534 - val_loss: 9.7655\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0474 - val_loss: 9.8150\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0862 - val_loss: 9.8579\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1251 - val_loss: 9.9770\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.0567 - val_loss: 9.9658\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.0494 - val_loss: 9.8395\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0626 - val_loss: 9.7541\n",
            "1/1 [==============================] - 1s 861ms/step - loss: 0.0643 - val_loss: 9.6956\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0723 - val_loss: 9.6925\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.0919 - val_loss: 9.8330\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0941 - val_loss: 9.8946\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.1598 - val_loss: 9.8577\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0592 - val_loss: 9.8182\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1323 - val_loss: 9.7242\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.0804 - val_loss: 9.7321\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.1089 - val_loss: 9.8139\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0813 - val_loss: 9.9274\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.1071 - val_loss: 9.9798\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.1110 - val_loss: 10.0020\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0893 - val_loss: 9.9216\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 0.0832 - val_loss: 9.8826\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.0929 - val_loss: 9.8628\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0622 - val_loss: 9.8527\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0518 - val_loss: 9.8350\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0726 - val_loss: 9.8694\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.1400 - val_loss: 9.9943\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.1134 - val_loss: 9.9166\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.1669 - val_loss: 9.7360\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0835 - val_loss: 9.6789\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0962 - val_loss: 9.7394\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0601 - val_loss: 9.8818\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1171 - val_loss: 10.0281\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1157 - val_loss: 9.9394\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0436 - val_loss: 9.8100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1049 - val_loss: 9.7193\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2304 - val_loss: 9.8028\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0422 - val_loss: 9.9356\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1448 - val_loss: 10.0248\n",
            "1/1 [==============================] - 1s 859ms/step - loss: 0.1238 - val_loss: 9.9876\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1508 - val_loss: 9.8273\n",
            "1/1 [==============================] - 1s 873ms/step - loss: 0.0972 - val_loss: 9.7755\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.1923 - val_loss: 9.8318\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.0522 - val_loss: 9.8006\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1174 - val_loss: 9.7474\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1322 - val_loss: 9.7147\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0645 - val_loss: 9.6794\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 0.0938 - val_loss: 9.6369\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0758 - val_loss: 9.6192\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 0.0942 - val_loss: 9.6263\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.1074 - val_loss: 9.7319\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 0.1538 - val_loss: 9.7204\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0634 - val_loss: 9.7025\n",
            "1/1 [==============================] - 1s 891ms/step - loss: 0.0377 - val_loss: 9.6718\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0456 - val_loss: 9.6832\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0839 - val_loss: 9.8027\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0710 - val_loss: 9.8774\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0682 - val_loss: 9.8294\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1242 - val_loss: 9.8562\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.0532 - val_loss: 9.8200\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0447 - val_loss: 9.8134\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.0486 - val_loss: 9.8136\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.0685 - val_loss: 9.8343\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.0768 - val_loss: 9.8932\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.1282 - val_loss: 9.9332\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.0462 - val_loss: 9.9172\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0872 - val_loss: 9.8071\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.0883 - val_loss: 9.6703\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0921 - val_loss: 9.6351\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1107 - val_loss: 9.7446\n",
            "1/1 [==============================] - 1s 986ms/step - loss: 0.0683 - val_loss: 9.9040\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0813 - val_loss: 9.9980\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0668 - val_loss: 9.8757\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.0364 - val_loss: 9.7680\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1050 - val_loss: 9.7557\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0966 - val_loss: 9.7816\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0565 - val_loss: 9.8956\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0329 - val_loss: 10.0212\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0822 - val_loss: 9.9554\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.0562 - val_loss: 9.8161\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.0778 - val_loss: 9.7742\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.1577 - val_loss: 9.8212\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0599 - val_loss: 9.8857\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0519 - val_loss: 9.8548\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.0600 - val_loss: 9.8456\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0581 - val_loss: 9.8213\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0352 - val_loss: 9.8025\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0521 - val_loss: 9.8330\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0462 - val_loss: 9.8843\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0268 - val_loss: 9.9036\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0849 - val_loss: 9.8988\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0761 - val_loss: 9.7823\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0283 - val_loss: 9.7040\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.0596 - val_loss: 9.7463\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0813 - val_loss: 9.8298\n",
            "1/1 [==============================] - 1s 872ms/step - loss: 0.0596 - val_loss: 9.8991\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1004 - val_loss: 9.9292\n",
            "1/1 [==============================] - 1s 873ms/step - loss: 0.1496 - val_loss: 9.7776\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0710 - val_loss: 9.6779\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0586 - val_loss: 9.6311\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.0576 - val_loss: 9.6504\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1231 - val_loss: 9.8179\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0772 - val_loss: 10.0531\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0467 - val_loss: 10.1981\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1328 - val_loss: 9.9942\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.0262 - val_loss: 9.8402\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.0392 - val_loss: 9.7882\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.0812 - val_loss: 9.8182\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.0559 - val_loss: 9.9118\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0697 - val_loss: 10.0086\n",
            "1/1 [==============================] - 1s 872ms/step - loss: 0.0768 - val_loss: 9.9643\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.0404 - val_loss: 9.8703\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.0681 - val_loss: 9.7519\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0571 - val_loss: 9.7379\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.0692 - val_loss: 9.8393\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0506 - val_loss: 9.9692\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.0686 - val_loss: 9.9309\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.1224 - val_loss: 9.8686\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0592 - val_loss: 9.7442\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0673 - val_loss: 9.6884\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0735 - val_loss: 9.7578\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3599 - val_loss: 10.0659\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.0713 - val_loss: 10.2251\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.1453 - val_loss: 9.9624\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0675 - val_loss: 9.7958\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1213 - val_loss: 9.7895\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.1563 - val_loss: 9.8630\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.1215 - val_loss: 9.9794\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.0566 - val_loss: 10.0293\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1174 - val_loss: 9.8949\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0646 - val_loss: 9.8576\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1062 - val_loss: 9.8275\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2493 - val_loss: 9.8324\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0683 - val_loss: 9.8956\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.0622 - val_loss: 9.9433\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.0599 - val_loss: 10.0310\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0944 - val_loss: 10.0666\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1709 - val_loss: 9.8697\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.1848 - val_loss: 9.8499\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.0436 - val_loss: 9.8510\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0912 - val_loss: 9.7913\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1322 - val_loss: 9.8976\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0959 - val_loss: 10.0352\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1227 - val_loss: 9.9404\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1138 - val_loss: 9.7132\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.1007 - val_loss: 9.6428\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.1199 - val_loss: 9.6642\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1668 - val_loss: 9.7896\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.1406 - val_loss: 10.1341\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1287 - val_loss: 10.3236\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1171 - val_loss: 10.1206\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2084 - val_loss: 9.7703\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.0870 - val_loss: 9.6792\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.1676 - val_loss: 9.7227\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.0718 - val_loss: 9.8710\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.1178 - val_loss: 10.0223\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1472 - val_loss: 9.9543\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1200 - val_loss: 9.7494\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1077 - val_loss: 9.6450\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.1259 - val_loss: 9.7384\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.0748 - val_loss: 9.9145\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.1392 - val_loss: 9.9861\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.0577 - val_loss: 9.9803\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5799 - val_loss: 9.7156\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1829 - val_loss: 9.6354\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0880 - val_loss: 9.6200\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.1056 - val_loss: 9.6641\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1672 - val_loss: 9.9540\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.1766 - val_loss: 10.0816\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.1317 - val_loss: 9.8488\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.1436 - val_loss: 9.7103\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2138 - val_loss: 9.7150\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2748 - val_loss: 9.7753\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.1336 - val_loss: 9.9198\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1832 - val_loss: 9.7343\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0963 - val_loss: 9.5830\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.0790 - val_loss: 9.4730\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2195 - val_loss: 9.6025\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.1078 - val_loss: 9.8007\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1230 - val_loss: 9.9265\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.0812 - val_loss: 9.9342\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.0755 - val_loss: 9.9609\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.0701 - val_loss: 10.0243\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1149 - val_loss: 10.0469\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1757 - val_loss: 10.0208\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.0878 - val_loss: 10.0585\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.1071 - val_loss: 10.0200\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.0905 - val_loss: 9.8061\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0677 - val_loss: 9.6512\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.0733 - val_loss: 9.5648\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.1581 - val_loss: 9.6987\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1236 - val_loss: 9.8851\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0621 - val_loss: 9.9620\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.1572 - val_loss: 9.6975\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.0620 - val_loss: 9.6179\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.1040 - val_loss: 9.7057\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1194 - val_loss: 9.8964\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0850 - val_loss: 9.9241\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1425 - val_loss: 9.9054\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.1242 - val_loss: 9.8423\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.1431 - val_loss: 9.7892\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1194 - val_loss: 9.8434\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.1542 - val_loss: 9.8576\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2467 - val_loss: 10.0558\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1686 - val_loss: 9.9108\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1515 - val_loss: 9.6055\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0578 - val_loss: 9.4556\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.2053 - val_loss: 9.5227\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0902 - val_loss: 9.6966\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.1470 - val_loss: 9.8228\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1466 - val_loss: 9.7207\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1514 - val_loss: 9.4827\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.1244 - val_loss: 9.4233\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.1155 - val_loss: 9.3805\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1420 - val_loss: 9.5106\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0917 - val_loss: 9.7849\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.1173 - val_loss: 9.8633\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.1146 - val_loss: 9.7305\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0789 - val_loss: 9.7062\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1035 - val_loss: 9.7399\n",
            "1/1 [==============================] - 1s 880ms/step - loss: 0.1349 - val_loss: 9.8791\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0812 - val_loss: 10.1475\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.1068 - val_loss: 10.1419\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1369 - val_loss: 9.8527\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.0936 - val_loss: 9.6536\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.0814 - val_loss: 9.5951\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1271 - val_loss: 9.6589\n",
            "1/1 [==============================] - 1s 861ms/step - loss: 0.0654 - val_loss: 9.9113\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.1081 - val_loss: 10.0422\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.1363 - val_loss: 9.9165\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.1409 - val_loss: 9.8393\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.0944 - val_loss: 9.7021\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.1020 - val_loss: 9.6900\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.1515 - val_loss: 9.7595\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.2154 - val_loss: 9.9911\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.0722 - val_loss: 10.2299\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.2135 - val_loss: 9.9693\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.0894 - val_loss: 9.6881\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.1252 - val_loss: 9.6296\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1378 - val_loss: 9.7263\n",
            "1/1 [==============================] - 1s 874ms/step - loss: 0.1666 - val_loss: 10.0998\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.1171 - val_loss: 10.2997\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.1651 - val_loss: 10.1722\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.2036 - val_loss: 9.9615\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1573 - val_loss: 9.9499\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2600 - val_loss: 9.9452\n",
            "1/1 [==============================] - 1s 875ms/step - loss: 0.1114 - val_loss: 9.9244\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.4329 - val_loss: 10.1413\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3617 - val_loss: 9.9219\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.1078 - val_loss: 9.6661\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.0850 - val_loss: 9.5761\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.1125 - val_loss: 9.5867\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1500 - val_loss: 9.6271\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1490 - val_loss: 9.8323\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.1282 - val_loss: 9.8638\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1817 - val_loss: 9.9020\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.0686 - val_loss: 9.8385\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.1001 - val_loss: 9.7014\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1602 - val_loss: 9.6412\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.1352 - val_loss: 9.6667\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.2076 - val_loss: 9.9366\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.1387 - val_loss: 10.0519\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1398 - val_loss: 9.9618\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0941 - val_loss: 9.6996\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2204 - val_loss: 9.6016\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.1070 - val_loss: 9.6144\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1137 - val_loss: 9.7752\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.1373 - val_loss: 10.1207\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.1673 - val_loss: 10.2673\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.2587 - val_loss: 9.9596\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.1662 - val_loss: 9.8314\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.1749 - val_loss: 9.8435\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.1015 - val_loss: 9.8265\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.0550 - val_loss: 9.8387\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2178 - val_loss: 10.0204\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1039 - val_loss: 10.1888\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1774 - val_loss: 9.9849\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1089 - val_loss: 9.8571\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1280 - val_loss: 9.8992\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0639 - val_loss: 10.0063\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.1997 - val_loss: 10.0331\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0693 - val_loss: 9.9684\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0887 - val_loss: 9.8355\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.1977 - val_loss: 9.7737\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.0986 - val_loss: 9.7491\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 0.0786 - val_loss: 9.8142\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.0759 - val_loss: 9.9377\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2594 - val_loss: 9.8333\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0626 - val_loss: 9.7846\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.0343 - val_loss: 9.7631\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.1893 - val_loss: 9.7458\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0828 - val_loss: 9.7667\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1183 - val_loss: 9.8521\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.1386 - val_loss: 9.8347\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0709 - val_loss: 9.7913\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0572 - val_loss: 9.7432\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.0875 - val_loss: 9.8193\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.1007 - val_loss: 9.9041\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.1073 - val_loss: 9.8273\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.0810 - val_loss: 9.8323\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.0862 - val_loss: 9.8154\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2215 - val_loss: 9.8160\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0961 - val_loss: 9.7812\n",
            "1/1 [==============================] - 1s 890ms/step - loss: 0.0679 - val_loss: 9.7290\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1109 - val_loss: 9.7416\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1104 - val_loss: 9.8225\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.1200 - val_loss: 10.0016\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.1888 - val_loss: 9.9876\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1445 - val_loss: 9.8098\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0956 - val_loss: 9.6568\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.0710 - val_loss: 9.6239\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.1321 - val_loss: 9.6921\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1330 - val_loss: 9.8442\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1206 - val_loss: 10.0004\n",
            "1/1 [==============================] - 1s 869ms/step - loss: 0.1092 - val_loss: 9.9042\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.0889 - val_loss: 9.8197\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0933 - val_loss: 9.7378\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1291 - val_loss: 9.6714\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1597 - val_loss: 9.8170\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.1567 - val_loss: 10.0512\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1184 - val_loss: 10.1592\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2205 - val_loss: 9.8083\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 0.2418 - val_loss: 9.5386\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.3123 - val_loss: 9.4386\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2586 - val_loss: 9.5156\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.1825 - val_loss: 9.9076\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.2303 - val_loss: 10.0709\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.1687 - val_loss: 9.8639\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.1535 - val_loss: 9.6796\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0662 - val_loss: 9.6710\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1482 - val_loss: 9.7620\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.1453 - val_loss: 10.0547\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.2119 - val_loss: 10.5341\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.2609 - val_loss: 10.3795\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2175 - val_loss: 9.9320\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1113 - val_loss: 9.6592\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3444 - val_loss: 9.6032\n",
            "1/1 [==============================] - 1s 859ms/step - loss: 0.3718 - val_loss: 9.6844\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.0987 - val_loss: 9.9505\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.1543 - val_loss: 10.2241\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.3019 - val_loss: 9.9667\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2113 - val_loss: 9.6291\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2847 - val_loss: 9.5006\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3084 - val_loss: 9.5016\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.3099 - val_loss: 9.6748\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1365 - val_loss: 10.2421\n",
            "1/1 [==============================] - 1s 859ms/step - loss: 0.1888 - val_loss: 10.5452\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3493 - val_loss: 10.3313\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2711 - val_loss: 9.8050\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2472 - val_loss: 9.6587\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4477 - val_loss: 9.6561\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5662 - val_loss: 9.9535\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4190 - val_loss: 10.2438\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.2783 - val_loss: 10.1068\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2435 - val_loss: 9.7245\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.0754 - val_loss: 9.5094\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3751 - val_loss: 9.5104\n",
            "1/1 [==============================] - 1s 860ms/step - loss: 0.1252 - val_loss: 9.5679\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2958 - val_loss: 9.8534\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3142 - val_loss: 10.2099\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.3642 - val_loss: 10.0184\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.1774 - val_loss: 9.7857\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.1525 - val_loss: 9.6734\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.3727 - val_loss: 9.6631\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2826 - val_loss: 9.7800\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1170 - val_loss: 10.0319\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.1244 - val_loss: 10.1288\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2771 - val_loss: 9.8316\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1088 - val_loss: 9.6571\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.2420 - val_loss: 9.6820\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1579 - val_loss: 9.8143\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.1802 - val_loss: 10.1417\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.1583 - val_loss: 10.3579\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2079 - val_loss: 10.0866\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.3161 - val_loss: 9.7554\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1720 - val_loss: 9.6203\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.2643 - val_loss: 9.6244\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1385 - val_loss: 9.8125\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0726 - val_loss: 10.0047\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.2308 - val_loss: 9.8676\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.1696 - val_loss: 9.5163\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0951 - val_loss: 9.3460\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1869 - val_loss: 9.4023\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.2025 - val_loss: 9.5756\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.1081 - val_loss: 9.8219\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.2981 - val_loss: 9.7898\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1160 - val_loss: 9.7761\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.2796 - val_loss: 9.7825\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.1472 - val_loss: 9.8528\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3787 - val_loss: 9.9215\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2169 - val_loss: 9.9224\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.1128 - val_loss: 9.8640\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.2438 - val_loss: 9.7086\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.1199 - val_loss: 9.7234\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1874 - val_loss: 9.9261\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1211 - val_loss: 10.1159\n",
            "1/1 [==============================] - 1s 881ms/step - loss: 0.2230 - val_loss: 9.9698\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 0.1155 - val_loss: 9.8249\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.2265 - val_loss: 9.5623\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1997 - val_loss: 9.5249\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2873 - val_loss: 9.5396\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.1794 - val_loss: 9.6552\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2206 - val_loss: 9.9508\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2648 - val_loss: 9.9990\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 0.2759 - val_loss: 9.8138\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.1154 - val_loss: 9.6306\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2055 - val_loss: 9.5831\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2546 - val_loss: 9.6314\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.1753 - val_loss: 9.6990\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1021 - val_loss: 9.7755\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2180 - val_loss: 9.7761\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2632 - val_loss: 9.5616\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1478 - val_loss: 9.3654\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2613 - val_loss: 9.3766\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.1102 - val_loss: 9.4438\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1884 - val_loss: 9.6474\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.1037 - val_loss: 10.0428\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.1763 - val_loss: 10.1552\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.1740 - val_loss: 10.0729\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1122 - val_loss: 9.8480\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1417 - val_loss: 9.7889\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5346 - val_loss: 9.7244\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.2421 - val_loss: 9.8476\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0995 - val_loss: 10.1060\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.2370 - val_loss: 9.9688\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3655 - val_loss: 9.4502\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1305 - val_loss: 9.2437\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5889 - val_loss: 9.2171\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3493 - val_loss: 9.4629\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.1807 - val_loss: 9.8996\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2104 - val_loss: 9.9806\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4883 - val_loss: 9.5217\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.1767 - val_loss: 9.3203\n",
            "1/1 [==============================] - 1s 861ms/step - loss: 0.2471 - val_loss: 9.3609\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.3502 - val_loss: 9.5822\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2037 - val_loss: 9.9279\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1630 - val_loss: 10.1776\n",
            "1/1 [==============================] - 1s 870ms/step - loss: 0.2678 - val_loss: 10.0517\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.1468 - val_loss: 9.6791\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.2735 - val_loss: 9.5148\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.3359 - val_loss: 9.5243\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1744 - val_loss: 9.6455\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2453 - val_loss: 9.7024\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.1321 - val_loss: 9.7864\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1672 - val_loss: 9.7855\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1297 - val_loss: 9.5815\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1293 - val_loss: 9.4821\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1288 - val_loss: 9.5145\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.1746 - val_loss: 9.6540\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2111 - val_loss: 9.8914\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2089 - val_loss: 9.9115\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.1157 - val_loss: 9.8503\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1527 - val_loss: 9.9183\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 0.0990 - val_loss: 9.8991\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.0831 - val_loss: 9.8336\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0938 - val_loss: 9.8056\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.1913 - val_loss: 9.6722\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3306 - val_loss: 9.5409\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3865 - val_loss: 9.4607\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3778 - val_loss: 9.6075\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1885 - val_loss: 9.9652\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2435 - val_loss: 9.8279\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2044 - val_loss: 9.5326\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.3447 - val_loss: 9.5729\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.2669 - val_loss: 9.6925\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.1294 - val_loss: 9.9250\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.1785 - val_loss: 10.1411\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.4359 - val_loss: 10.0369\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.1324 - val_loss: 9.8924\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3606 - val_loss: 9.8353\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.0526 - val_loss: 9.8126\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2113 - val_loss: 9.9158\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0832 - val_loss: 10.0152\n",
            "1/1 [==============================] - 1s 870ms/step - loss: 0.3056 - val_loss: 9.8648\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1489 - val_loss: 9.5719\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.1215 - val_loss: 9.4363\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1861 - val_loss: 9.4076\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 0.2261 - val_loss: 9.5920\n",
            "1/1 [==============================] - 1s 990ms/step - loss: 0.1263 - val_loss: 9.8662\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3704 - val_loss: 9.6356\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1935 - val_loss: 9.5336\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.1772 - val_loss: 9.6145\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1731 - val_loss: 9.7561\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1777 - val_loss: 9.6770\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.1430 - val_loss: 9.6711\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2136 - val_loss: 9.7030\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1294 - val_loss: 9.7714\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2214 - val_loss: 9.6898\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1533 - val_loss: 9.6032\n",
            "1/1 [==============================] - 1s 885ms/step - loss: 0.1518 - val_loss: 9.6296\n",
            "1/1 [==============================] - 1s 869ms/step - loss: 0.0882 - val_loss: 9.7638\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2623 - val_loss: 9.9590\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1609 - val_loss: 9.9210\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1385 - val_loss: 9.7070\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 0.0611 - val_loss: 9.5754\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.3533 - val_loss: 9.5947\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.2831 - val_loss: 9.6095\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2254 - val_loss: 9.7422\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.0752 - val_loss: 10.0177\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2209 - val_loss: 9.8446\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.1415 - val_loss: 9.6211\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.2453 - val_loss: 9.5170\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.2221 - val_loss: 9.5293\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.2731 - val_loss: 9.6982\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.2378 - val_loss: 9.8896\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.2370 - val_loss: 9.8201\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.1363 - val_loss: 9.6275\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1594 - val_loss: 9.5910\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.2258 - val_loss: 9.6334\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.1639 - val_loss: 9.7048\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.4419 - val_loss: 9.7752\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1282 - val_loss: 9.6397\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0802 - val_loss: 9.5530\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.1987 - val_loss: 9.5816\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1996 - val_loss: 9.6948\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.1885 - val_loss: 9.6793\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2417 - val_loss: 9.8016\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2568 - val_loss: 9.7344\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2550 - val_loss: 9.6975\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.1528 - val_loss: 9.6946\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1054 - val_loss: 9.7275\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1459 - val_loss: 9.7849\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.2392 - val_loss: 9.7010\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.1591 - val_loss: 9.6454\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.1028 - val_loss: 9.6379\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.1436 - val_loss: 9.7229\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1114 - val_loss: 9.7708\n",
            "1/1 [==============================] - 1s 871ms/step - loss: 0.1525 - val_loss: 9.7947\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.1279 - val_loss: 9.6418\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1485 - val_loss: 9.6133\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1566 - val_loss: 9.6039\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1877 - val_loss: 9.5847\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1941 - val_loss: 9.7561\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.1406 - val_loss: 9.7910\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.1572 - val_loss: 9.7792\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1000 - val_loss: 9.6431\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0944 - val_loss: 9.5181\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.1111 - val_loss: 9.4952\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1026 - val_loss: 9.4476\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.2018 - val_loss: 9.4824\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1117 - val_loss: 9.5903\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.0884 - val_loss: 9.6291\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.0885 - val_loss: 9.6976\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.0553 - val_loss: 9.6905\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.1422 - val_loss: 9.7221\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.1407 - val_loss: 9.7221\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.0627 - val_loss: 9.7487\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1015 - val_loss: 9.7719\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1816 - val_loss: 9.8009\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0855 - val_loss: 9.8419\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.1706 - val_loss: 9.7259\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0675 - val_loss: 9.5749\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0741 - val_loss: 9.5002\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1068 - val_loss: 9.4667\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0925 - val_loss: 9.4204\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.1133 - val_loss: 9.4752\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.1472 - val_loss: 9.4692\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0780 - val_loss: 9.4851\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0679 - val_loss: 9.5725\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.1244 - val_loss: 9.6775\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0715 - val_loss: 9.8484\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.1608 - val_loss: 10.0394\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.2234 - val_loss: 9.8426\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.1072 - val_loss: 9.5276\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0923 - val_loss: 9.3865\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2351 - val_loss: 9.3445\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.1886 - val_loss: 9.4849\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.1110 - val_loss: 9.9291\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.3570 - val_loss: 9.9069\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.1517 - val_loss: 9.5570\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 0.0452 - val_loss: 9.4126\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.1708 - val_loss: 9.4696\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1181 - val_loss: 9.6358\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0849 - val_loss: 9.7560\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1593 - val_loss: 9.7106\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.1004 - val_loss: 9.6268\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1197 - val_loss: 9.6018\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0741 - val_loss: 9.6153\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.1281 - val_loss: 9.6579\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.0986 - val_loss: 9.6722\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1138 - val_loss: 9.7154\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.1214 - val_loss: 9.7227\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1905 - val_loss: 9.7551\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.0929 - val_loss: 9.6640\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.0850 - val_loss: 9.5838\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.1585 - val_loss: 9.5764\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1328 - val_loss: 9.5686\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.1325 - val_loss: 9.6855\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0973 - val_loss: 9.8063\n",
            "1/1 [==============================] - 1s 891ms/step - loss: 0.0829 - val_loss: 9.8810\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1595 - val_loss: 9.8572\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1411 - val_loss: 9.7726\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.1881 - val_loss: 9.5813\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.1166 - val_loss: 9.4957\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.1405 - val_loss: 9.4714\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1238 - val_loss: 9.5291\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1008 - val_loss: 9.7517\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.1420 - val_loss: 9.7570\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1196 - val_loss: 9.6400\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0988 - val_loss: 9.5433\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.1085 - val_loss: 9.6103\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.1562 - val_loss: 9.7533\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1219 - val_loss: 9.9272\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0915 - val_loss: 9.9334\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.1150 - val_loss: 9.7731\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.0574 - val_loss: 9.7245\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1390 - val_loss: 9.7800\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0981 - val_loss: 9.9723\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.1134 - val_loss: 9.9842\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.1252 - val_loss: 9.7683\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0787 - val_loss: 9.5941\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0643 - val_loss: 9.4767\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.1083 - val_loss: 9.4686\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.1074 - val_loss: 9.5507\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0716 - val_loss: 9.5997\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0820 - val_loss: 9.6052\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0865 - val_loss: 9.5865\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1537 - val_loss: 9.6263\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1110 - val_loss: 9.6201\n",
            "1/1 [==============================] - 1s 859ms/step - loss: 0.1233 - val_loss: 9.6817\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0328 - val_loss: 9.7396\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0961 - val_loss: 9.6984\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.0941 - val_loss: 9.6183\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.1302 - val_loss: 9.6766\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.1108 - val_loss: 9.7951\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0476 - val_loss: 9.9223\n",
            "1/1 [==============================] - 1s 859ms/step - loss: 0.1303 - val_loss: 9.8674\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0826 - val_loss: 9.7834\n",
            "1/1 [==============================] - 1s 875ms/step - loss: 0.1050 - val_loss: 9.6534\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.0474 - val_loss: 9.5877\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1458 - val_loss: 9.6221\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1929 - val_loss: 9.6956\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0985 - val_loss: 9.7326\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0998 - val_loss: 9.7472\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.1629 - val_loss: 9.7646\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1483 - val_loss: 9.6552\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0658 - val_loss: 9.5815\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1340 - val_loss: 9.5726\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0694 - val_loss: 9.6703\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.0504 - val_loss: 9.8062\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0774 - val_loss: 9.8938\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.1134 - val_loss: 9.6942\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.0394 - val_loss: 9.5772\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.0773 - val_loss: 9.5189\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0830 - val_loss: 9.5564\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0815 - val_loss: 9.7334\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.0986 - val_loss: 9.7303\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.1700 - val_loss: 9.5637\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.0720 - val_loss: 9.5149\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.0569 - val_loss: 9.5179\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.2397 - val_loss: 9.5656\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0716 - val_loss: 9.6853\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.0503 - val_loss: 9.7683\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.0671 - val_loss: 9.7494\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0687 - val_loss: 9.6439\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.1409 - val_loss: 9.6549\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0971 - val_loss: 9.7118\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0764 - val_loss: 9.8103\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.0939 - val_loss: 9.7655\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0558 - val_loss: 9.7177\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0730 - val_loss: 9.7112\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.0792 - val_loss: 9.6668\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.0909 - val_loss: 9.6398\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.0549 - val_loss: 9.5976\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0326 - val_loss: 9.6056\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0692 - val_loss: 9.5773\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1322 - val_loss: 9.5414\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.0821 - val_loss: 9.4800\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0696 - val_loss: 9.4961\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0899 - val_loss: 9.6052\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0478 - val_loss: 9.7014\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.0783 - val_loss: 9.8035\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0598 - val_loss: 9.8133\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.0578 - val_loss: 9.7380\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0629 - val_loss: 9.7147\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0623 - val_loss: 9.7225\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0614 - val_loss: 9.7671\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.4980 - val_loss: 9.9020\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.1010 - val_loss: 9.8390\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.0559 - val_loss: 9.6869\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0424 - val_loss: 9.5491\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0655 - val_loss: 9.4604\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.0766 - val_loss: 9.4653\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0938 - val_loss: 9.6059\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0641 - val_loss: 9.7121\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1545 - val_loss: 9.5935\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0540 - val_loss: 9.5305\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.1355 - val_loss: 9.7162\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.0905 - val_loss: 9.8747\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1069 - val_loss: 9.7722\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.1071 - val_loss: 9.6532\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.1032 - val_loss: 9.7081\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.0570 - val_loss: 9.7860\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0833 - val_loss: 9.8724\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1293 - val_loss: 9.9193\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0976 - val_loss: 9.7924\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0891 - val_loss: 9.6014\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.0676 - val_loss: 9.5267\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.0744 - val_loss: 9.5401\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.1514 - val_loss: 9.7356\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0769 - val_loss: 10.1792\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2450 - val_loss: 10.1027\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.1951 - val_loss: 9.7787\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.0658 - val_loss: 9.6350\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1611 - val_loss: 9.6345\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1143 - val_loss: 9.7679\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.0703 - val_loss: 9.9186\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.1682 - val_loss: 9.8605\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.0800 - val_loss: 9.6824\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.2785 - val_loss: 9.5749\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.1655 - val_loss: 9.5911\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1748 - val_loss: 9.7680\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.1128 - val_loss: 10.0213\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2919 - val_loss: 9.9751\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.0581 - val_loss: 9.7812\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1113 - val_loss: 9.5630\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.1574 - val_loss: 9.5044\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1158 - val_loss: 9.5073\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.1140 - val_loss: 9.6650\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0660 - val_loss: 9.9942\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3541 - val_loss: 9.5895\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1026 - val_loss: 9.3288\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 0.2554 - val_loss: 9.3331\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.2130 - val_loss: 9.4736\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.0746 - val_loss: 9.6900\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.0973 - val_loss: 9.8651\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1490 - val_loss: 9.7554\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1420 - val_loss: 9.5845\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1370 - val_loss: 9.6394\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1514 - val_loss: 9.7219\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1386 - val_loss: 9.9125\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1280 - val_loss: 9.9174\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1045 - val_loss: 9.6930\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.0822 - val_loss: 9.5619\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.1401 - val_loss: 9.5861\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1501 - val_loss: 9.6378\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.1297 - val_loss: 9.6253\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1855 - val_loss: 9.6077\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.0922 - val_loss: 9.6032\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1370 - val_loss: 9.5721\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0659 - val_loss: 9.5623\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.1178 - val_loss: 9.6620\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0555 - val_loss: 9.8194\n",
            "1/1 [==============================] - 1s 874ms/step - loss: 0.0961 - val_loss: 10.0398\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1643 - val_loss: 9.9062\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.1196 - val_loss: 9.6695\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1176 - val_loss: 9.6434\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.0682 - val_loss: 9.6234\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0931 - val_loss: 9.7449\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0939 - val_loss: 9.7897\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1236 - val_loss: 9.6632\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1164 - val_loss: 9.5978\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.0840 - val_loss: 9.5451\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0362 - val_loss: 9.5549\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.0719 - val_loss: 9.6303\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.0710 - val_loss: 9.7537\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0931 - val_loss: 9.7647\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.0865 - val_loss: 9.7198\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0821 - val_loss: 9.5996\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0860 - val_loss: 9.4931\n",
            "1/1 [==============================] - 1s 861ms/step - loss: 0.1150 - val_loss: 9.5054\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.0979 - val_loss: 9.6618\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0380 - val_loss: 9.8222\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0549 - val_loss: 9.8662\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1038 - val_loss: 9.7748\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.0607 - val_loss: 9.6719\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.1039 - val_loss: 9.6200\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2170 - val_loss: 9.7465\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0931 - val_loss: 10.0141\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1015 - val_loss: 10.0796\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1430 - val_loss: 9.8869\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.1327 - val_loss: 9.7133\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1435 - val_loss: 9.5486\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.1033 - val_loss: 9.5202\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1722 - val_loss: 9.7273\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2015 - val_loss: 9.8213\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1853 - val_loss: 9.6869\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1076 - val_loss: 9.4956\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1528 - val_loss: 9.4211\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1261 - val_loss: 9.4887\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.2750 - val_loss: 9.6926\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1312 - val_loss: 9.8238\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1725 - val_loss: 9.8345\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1626 - val_loss: 9.6446\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0921 - val_loss: 9.4670\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.1845 - val_loss: 9.4520\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2202 - val_loss: 9.5555\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0994 - val_loss: 9.8307\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1491 - val_loss: 9.9090\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.1411 - val_loss: 9.6752\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0961 - val_loss: 9.5050\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1334 - val_loss: 9.4486\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.2786 - val_loss: 9.5692\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.0875 - val_loss: 9.7687\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.1742 - val_loss: 9.7573\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1597 - val_loss: 9.7534\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0584 - val_loss: 9.6930\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.0856 - val_loss: 9.7119\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0805 - val_loss: 9.7645\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0864 - val_loss: 9.7479\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1245 - val_loss: 9.7415\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0655 - val_loss: 9.7507\n",
            "1/1 [==============================] - 1s 859ms/step - loss: 0.0634 - val_loss: 9.7016\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.0806 - val_loss: 9.6549\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0712 - val_loss: 9.6217\n",
            "1/1 [==============================] - 1s 868ms/step - loss: 0.0720 - val_loss: 9.6275\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.0450 - val_loss: 9.6308\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1032 - val_loss: 9.6750\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.0468 - val_loss: 9.6924\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.1020 - val_loss: 9.6011\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.1020 - val_loss: 9.4436\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1335 - val_loss: 9.3823\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.1024 - val_loss: 9.4520\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.0874 - val_loss: 9.5950\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0889 - val_loss: 9.6626\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1324 - val_loss: 9.6086\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0535 - val_loss: 9.5883\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0816 - val_loss: 9.6079\n",
            "1/1 [==============================] - 1s 880ms/step - loss: 0.0713 - val_loss: 9.7311\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.1105 - val_loss: 9.8679\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0989 - val_loss: 9.8080\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1035 - val_loss: 9.7933\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.1872 - val_loss: 9.8590\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.1447 - val_loss: 9.7557\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0981 - val_loss: 9.6843\n",
            "1/1 [==============================] - 1s 890ms/step - loss: 0.1307 - val_loss: 9.5804\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2076 - val_loss: 9.4831\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0998 - val_loss: 9.5311\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1352 - val_loss: 9.7070\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0820 - val_loss: 9.8023\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.0741 - val_loss: 9.7598\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.1795 - val_loss: 9.5942\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0701 - val_loss: 9.5055\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1233 - val_loss: 9.5325\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.0627 - val_loss: 9.6098\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0955 - val_loss: 9.6123\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.0686 - val_loss: 9.6673\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0760 - val_loss: 9.6171\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.0852 - val_loss: 9.6367\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.0423 - val_loss: 9.6145\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.0575 - val_loss: 9.5723\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0714 - val_loss: 9.5543\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.0696 - val_loss: 9.5937\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.0690 - val_loss: 9.7791\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.0758 - val_loss: 9.9493\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1049 - val_loss: 9.8697\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0606 - val_loss: 9.6755\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0264 - val_loss: 9.5751\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1273 - val_loss: 9.6079\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.0695 - val_loss: 9.7343\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.0406 - val_loss: 9.9803\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2373 - val_loss: 9.8045\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.0890 - val_loss: 9.6108\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0532 - val_loss: 9.5375\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.0672 - val_loss: 9.5418\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.0971 - val_loss: 9.7015\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.0911 - val_loss: 9.8817\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1277 - val_loss: 9.7249\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1032 - val_loss: 9.4657\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.0500 - val_loss: 9.3499\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1558 - val_loss: 9.2898\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1939 - val_loss: 9.5198\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0833 - val_loss: 9.8915\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1792 - val_loss: 9.9470\n",
            "1/1 [==============================] - 1s 859ms/step - loss: 0.1958 - val_loss: 9.6196\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.1716 - val_loss: 9.4858\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0559 - val_loss: 9.4762\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1612 - val_loss: 9.5458\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0973 - val_loss: 9.6907\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0561 - val_loss: 9.8887\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0950 - val_loss: 9.9631\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.1063 - val_loss: 9.7364\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.0911 - val_loss: 9.5745\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.1688 - val_loss: 9.5307\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1661 - val_loss: 9.6528\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.0797 - val_loss: 9.9752\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.1752 - val_loss: 10.0398\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.1822 - val_loss: 9.6097\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.1040 - val_loss: 9.4265\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.1398 - val_loss: 9.4253\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2194 - val_loss: 9.6162\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0586 - val_loss: 9.9749\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.0800 - val_loss: 10.1096\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2413 - val_loss: 9.7767\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.0667 - val_loss: 9.5832\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1696 - val_loss: 9.5649\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1485 - val_loss: 9.6517\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.1076 - val_loss: 9.8194\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.0899 - val_loss: 9.9229\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.1830 - val_loss: 9.6648\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0934 - val_loss: 9.4682\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1124 - val_loss: 9.4582\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1219 - val_loss: 9.6168\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1471 - val_loss: 9.8093\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1007 - val_loss: 9.7574\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0736 - val_loss: 9.6006\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0868 - val_loss: 9.6159\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.1534 - val_loss: 9.8348\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0752 - val_loss: 10.0816\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1443 - val_loss: 10.0463\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.0651 - val_loss: 9.8514\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.0972 - val_loss: 9.7006\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.0859 - val_loss: 9.6279\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2337 - val_loss: 9.6521\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.1032 - val_loss: 9.8359\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.1210 - val_loss: 10.0592\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.2234 - val_loss: 9.7630\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1181 - val_loss: 9.4827\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1034 - val_loss: 9.4071\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.1374 - val_loss: 9.4701\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1720 - val_loss: 9.5533\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1351 - val_loss: 9.6278\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1804 - val_loss: 9.5509\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1406 - val_loss: 9.5419\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.1033 - val_loss: 9.5801\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.0689 - val_loss: 9.6287\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.0652 - val_loss: 9.5855\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1187 - val_loss: 9.5804\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1811 - val_loss: 9.7438\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1121 - val_loss: 9.8474\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.0751 - val_loss: 9.8540\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.1183 - val_loss: 9.6682\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0752 - val_loss: 9.5113\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1192 - val_loss: 9.5182\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.1580 - val_loss: 9.4644\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1049 - val_loss: 9.5086\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0968 - val_loss: 9.6652\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0914 - val_loss: 9.6961\n",
            "1/1 [==============================] - 1s 872ms/step - loss: 0.0886 - val_loss: 9.5771\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.1181 - val_loss: 9.4406\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1638 - val_loss: 9.4469\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.0979 - val_loss: 9.5946\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.0486 - val_loss: 9.7899\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1307 - val_loss: 9.7908\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1348 - val_loss: 9.7283\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1851 - val_loss: 9.7280\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.0871 - val_loss: 9.7630\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.1287 - val_loss: 9.9632\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0723 - val_loss: 10.0147\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.1952 - val_loss: 9.6980\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0986 - val_loss: 9.5084\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.1554 - val_loss: 9.4955\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0567 - val_loss: 9.5274\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.1246 - val_loss: 9.5718\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1339 - val_loss: 9.5242\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0897 - val_loss: 9.4406\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0999 - val_loss: 9.5344\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1015 - val_loss: 9.6637\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.0548 - val_loss: 9.8202\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0677 - val_loss: 9.8195\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2371 - val_loss: 9.8406\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.1950 - val_loss: 9.6796\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1072 - val_loss: 9.6834\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1072 - val_loss: 9.6867\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.1443 - val_loss: 9.5234\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0988 - val_loss: 9.5024\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1005 - val_loss: 9.5124\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2836 - val_loss: 9.6705\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2038 - val_loss: 9.7348\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1757 - val_loss: 9.5533\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0466 - val_loss: 9.4760\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0749 - val_loss: 9.4864\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.1142 - val_loss: 9.5945\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1359 - val_loss: 9.8047\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1241 - val_loss: 10.0949\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2070 - val_loss: 9.7910\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0848 - val_loss: 9.5521\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0953 - val_loss: 9.4325\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2212 - val_loss: 9.4541\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1320 - val_loss: 9.5101\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0667 - val_loss: 9.6592\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.1343 - val_loss: 9.7900\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0744 - val_loss: 9.7666\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1673 - val_loss: 9.4751\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1351 - val_loss: 9.2876\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2401 - val_loss: 9.3178\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.1903 - val_loss: 9.4637\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.1672 - val_loss: 9.6564\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.1506 - val_loss: 9.6878\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.2559 - val_loss: 9.6256\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 0.1495 - val_loss: 9.5855\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.1696 - val_loss: 9.5680\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.0821 - val_loss: 9.6069\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.1327 - val_loss: 9.7167\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.1235 - val_loss: 9.8148\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.1203 - val_loss: 9.6489\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2163 - val_loss: 9.3660\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0904 - val_loss: 9.3177\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1873 - val_loss: 9.3601\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1686 - val_loss: 9.6215\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1829 - val_loss: 10.0296\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2094 - val_loss: 9.9485\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2745 - val_loss: 9.5664\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1395 - val_loss: 9.3310\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.2286 - val_loss: 9.3582\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.1853 - val_loss: 9.5319\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1618 - val_loss: 10.0170\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.1760 - val_loss: 10.2534\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.2641 - val_loss: 9.9925\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2992 - val_loss: 9.6995\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.1966 - val_loss: 9.6828\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3370 - val_loss: 9.7190\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3179 - val_loss: 9.9019\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.1615 - val_loss: 9.9345\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.2946 - val_loss: 9.5903\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3333 - val_loss: 9.2191\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2406 - val_loss: 9.1237\n",
            "1/1 [==============================] - 1s 860ms/step - loss: 0.5490 - val_loss: 9.2790\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.1378 - val_loss: 9.8084\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2191 - val_loss: 10.1782\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5043 - val_loss: 9.6353\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1457 - val_loss: 9.4368\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2267 - val_loss: 9.3830\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1579 - val_loss: 9.3741\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.1550 - val_loss: 9.5748\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.1604 - val_loss: 9.8869\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.1924 - val_loss: 10.1017\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.1958 - val_loss: 9.8502\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2341 - val_loss: 9.5270\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2433 - val_loss: 9.5050\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.5009 - val_loss: 9.5932\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.2415 - val_loss: 9.9969\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1471 - val_loss: 10.5448\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.4589 - val_loss: 10.1830\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1965 - val_loss: 9.7009\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2416 - val_loss: 9.6023\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3680 - val_loss: 9.6270\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.2885 - val_loss: 10.0319\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2587 - val_loss: 10.1657\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.1841 - val_loss: 9.8207\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.1964 - val_loss: 9.4739\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.1117 - val_loss: 9.3524\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3338 - val_loss: 9.3422\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2865 - val_loss: 9.4085\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2075 - val_loss: 9.6477\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1996 - val_loss: 10.0034\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2763 - val_loss: 9.8047\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2178 - val_loss: 9.4839\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.1973 - val_loss: 9.3555\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.3555 - val_loss: 9.3862\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2733 - val_loss: 9.5011\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1729 - val_loss: 9.7838\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2440 - val_loss: 10.0507\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3123 - val_loss: 9.8367\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.2329 - val_loss: 9.5344\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.1910 - val_loss: 9.4266\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2806 - val_loss: 9.4239\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.3527 - val_loss: 9.5628\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.2790 - val_loss: 9.9907\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3335 - val_loss: 9.8947\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 0.1913 - val_loss: 9.7195\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.1678 - val_loss: 9.5120\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2885 - val_loss: 9.4057\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.2141 - val_loss: 9.3507\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.4599 - val_loss: 9.4625\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.9219 - val_loss: 10.2879\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.4794 - val_loss: 10.6029\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.6360 - val_loss: 9.6673\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.3113 - val_loss: 9.5225\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4547 - val_loss: 9.5208\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6709 - val_loss: 9.6798\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.2132 - val_loss: 10.3343\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.1863 - val_loss: 10.8094\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5921 - val_loss: 10.0481\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.8300 - val_loss: 9.3346\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7713 - val_loss: 9.2965\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 1.6737 - val_loss: 9.3451\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2212 - val_loss: 10.0967\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 0.6175 - val_loss: 10.4166\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4790 - val_loss: 10.1443\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6752 - val_loss: 9.7993\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5192 - val_loss: 9.7837\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6271 - val_loss: 9.8274\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.3334 - val_loss: 10.0910\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.6580 - val_loss: 10.0748\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.3265 - val_loss: 9.7346\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4087 - val_loss: 9.6909\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.3959 - val_loss: 9.6000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3352 - val_loss: 9.8127\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.0218 - val_loss: 9.8442\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 0.5397 - val_loss: 9.3414\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3228 - val_loss: 9.2129\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6747 - val_loss: 9.1776\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3266 - val_loss: 9.2804\n",
            "1/1 [==============================] - 1s 860ms/step - loss: 0.4641 - val_loss: 9.7475\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3768 - val_loss: 9.7223\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.4676 - val_loss: 9.3424\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4479 - val_loss: 9.1941\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.2945 - val_loss: 9.1937\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.1020 - val_loss: 9.3419\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.5182 - val_loss: 9.9071\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.2145 - val_loss: 10.7679\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.9743 - val_loss: 10.0441\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.4368 - val_loss: 9.6776\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.2778 - val_loss: 9.6650\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.9210 - val_loss: 9.5943\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.5855 - val_loss: 9.7624\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.5622 - val_loss: 10.5873\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.6003 - val_loss: 10.7001\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 1.2277 - val_loss: 9.6858\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4593 - val_loss: 9.4171\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.9280 - val_loss: 9.4531\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 1.3145 - val_loss: 9.3663\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.1585 - val_loss: 9.8792\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6695 - val_loss: 11.1541\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 1.6661 - val_loss: 9.9745\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5973 - val_loss: 9.2544\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.0958 - val_loss: 9.2717\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5978 - val_loss: 9.3908\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.8552 - val_loss: 9.6138\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4224 - val_loss: 10.2260\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.4372 - val_loss: 10.4874\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.5598 - val_loss: 9.9276\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.6535 - val_loss: 9.6424\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.3768 - val_loss: 9.6118\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5061 - val_loss: 9.7373\n",
            "1/1 [==============================] - 1s 860ms/step - loss: 0.4645 - val_loss: 10.0938\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5367 - val_loss: 10.6714\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.8793 - val_loss: 9.9040\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.4209 - val_loss: 9.6589\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7040 - val_loss: 9.5315\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4585 - val_loss: 9.4799\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.4602 - val_loss: 9.6694\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4648 - val_loss: 9.8695\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6065 - val_loss: 9.7138\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4142 - val_loss: 9.6604\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6768 - val_loss: 9.7509\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4313 - val_loss: 9.8459\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.6548 - val_loss: 10.0776\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7480 - val_loss: 9.9022\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.4632 - val_loss: 9.7354\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6977 - val_loss: 9.6384\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.6163 - val_loss: 9.7047\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.9292 - val_loss: 9.4523\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.6428 - val_loss: 9.4914\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7300 - val_loss: 9.7051\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4368 - val_loss: 9.7359\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2919 - val_loss: 9.6664\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3584 - val_loss: 9.6691\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.8993 - val_loss: 9.8257\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3217 - val_loss: 9.9258\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.7240 - val_loss: 9.7223\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.5466 - val_loss: 9.4388\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3697 - val_loss: 9.3639\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.2939 - val_loss: 9.3372\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.2686 - val_loss: 9.4670\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6918 - val_loss: 9.5211\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.9017 - val_loss: 9.5517\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.2754 - val_loss: 9.5682\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 1.2208 - val_loss: 9.5750\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2503 - val_loss: 9.6129\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 0.3531 - val_loss: 9.6938\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.2264 - val_loss: 9.7783\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3699 - val_loss: 9.8443\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3221 - val_loss: 9.9178\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4658 - val_loss: 10.0327\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.9414 - val_loss: 9.8630\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.3594 - val_loss: 9.6316\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4380 - val_loss: 9.5064\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.4177 - val_loss: 9.5170\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.5424 - val_loss: 9.6720\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3079 - val_loss: 9.5976\n",
            "1/1 [==============================] - 1s 870ms/step - loss: 0.6487 - val_loss: 9.4211\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2590 - val_loss: 9.3362\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.3813 - val_loss: 9.3920\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.3132 - val_loss: 9.5361\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1256 - val_loss: 9.7189\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5373 - val_loss: 9.7708\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.4687 - val_loss: 9.6543\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6355 - val_loss: 9.5697\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.2407 - val_loss: 9.6071\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.2998 - val_loss: 9.6109\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2204 - val_loss: 9.7840\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4656 - val_loss: 9.4821\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.3163 - val_loss: 9.2655\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3305 - val_loss: 9.1862\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.2939 - val_loss: 9.3236\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.3142 - val_loss: 9.5636\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.2410 - val_loss: 9.6358\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4350 - val_loss: 9.4335\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2711 - val_loss: 9.4233\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1949 - val_loss: 9.4508\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1734 - val_loss: 9.5429\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.3752 - val_loss: 9.8127\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.3283 - val_loss: 9.8205\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3091 - val_loss: 9.6945\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2803 - val_loss: 9.5059\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 0.2370 - val_loss: 9.4002\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.2520 - val_loss: 9.4558\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2874 - val_loss: 9.6430\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 0.2083 - val_loss: 9.8340\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.3759 - val_loss: 9.8073\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.3652 - val_loss: 9.4095\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1861 - val_loss: 9.2397\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4026 - val_loss: 9.2393\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.3770 - val_loss: 9.3210\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.2459 - val_loss: 9.6754\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3852 - val_loss: 9.8186\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.4707 - val_loss: 9.5065\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.1814 - val_loss: 9.2552\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2612 - val_loss: 9.1952\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4229 - val_loss: 9.2788\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2513 - val_loss: 9.4705\n",
            "1/1 [==============================] - 1s 876ms/step - loss: 0.2796 - val_loss: 9.5784\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.3417 - val_loss: 9.6534\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.1761 - val_loss: 9.7010\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.2058 - val_loss: 9.7246\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2185 - val_loss: 9.5581\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.1336 - val_loss: 9.5364\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2026 - val_loss: 9.5823\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.3437 - val_loss: 9.6721\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1316 - val_loss: 9.8913\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2479 - val_loss: 9.9012\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2831 - val_loss: 9.8355\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.2613 - val_loss: 9.6083\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.2992 - val_loss: 9.5100\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.4243 - val_loss: 9.4986\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.3145 - val_loss: 9.7331\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1319 - val_loss: 10.2237\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2965 - val_loss: 10.2576\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.3339 - val_loss: 9.8106\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1374 - val_loss: 9.5692\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6431 - val_loss: 9.4598\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.3901 - val_loss: 9.5279\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2864 - val_loss: 9.7360\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3193 - val_loss: 9.9008\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.1848 - val_loss: 9.7903\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2291 - val_loss: 9.5972\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.1588 - val_loss: 9.5131\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.3099 - val_loss: 9.4904\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4732 - val_loss: 9.5920\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.1865 - val_loss: 9.7002\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1965 - val_loss: 9.7639\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.2072 - val_loss: 9.7813\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.1566 - val_loss: 9.7290\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2393 - val_loss: 9.7222\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3226 - val_loss: 9.6822\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.2827 - val_loss: 9.6889\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4067 - val_loss: 9.8297\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2332 - val_loss: 9.9968\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.3428 - val_loss: 9.9110\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.2039 - val_loss: 9.7032\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2137 - val_loss: 9.4828\n",
            "1/1 [==============================] - 1s 872ms/step - loss: 0.3180 - val_loss: 9.4199\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.2461 - val_loss: 9.4750\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3331 - val_loss: 9.6060\n",
            "1/1 [==============================] - 1s 860ms/step - loss: 0.3255 - val_loss: 9.5572\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2076 - val_loss: 9.5028\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.1842 - val_loss: 9.4750\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.1762 - val_loss: 9.3791\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3171 - val_loss: 9.4401\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2311 - val_loss: 9.4663\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5374 - val_loss: 9.5571\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0933 - val_loss: 9.6953\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.3250 - val_loss: 9.6001\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1421 - val_loss: 9.5711\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.1766 - val_loss: 9.6219\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1545 - val_loss: 9.6514\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1257 - val_loss: 9.7470\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1260 - val_loss: 9.8826\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1611 - val_loss: 9.9529\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.2699 - val_loss: 9.8773\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.1867 - val_loss: 9.7920\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1651 - val_loss: 9.7303\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1108 - val_loss: 9.6822\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2192 - val_loss: 9.6875\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.3733 - val_loss: 9.6624\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.3292 - val_loss: 9.7526\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1780 - val_loss: 9.7837\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2598 - val_loss: 9.4834\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3022 - val_loss: 9.2446\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1425 - val_loss: 9.2108\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2379 - val_loss: 9.3016\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.1517 - val_loss: 9.4650\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.1837 - val_loss: 9.6395\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.2728 - val_loss: 9.4488\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3664 - val_loss: 9.2986\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2808 - val_loss: 9.2401\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3784 - val_loss: 9.3335\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1402 - val_loss: 9.5208\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2712 - val_loss: 9.6595\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1630 - val_loss: 9.6168\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.1655 - val_loss: 9.4575\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1329 - val_loss: 9.3495\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1930 - val_loss: 9.3189\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.1632 - val_loss: 9.3445\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1711 - val_loss: 9.4301\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.3088 - val_loss: 9.5954\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.1365 - val_loss: 9.7872\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.3852 - val_loss: 9.4462\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1491 - val_loss: 9.2717\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.1952 - val_loss: 9.2194\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.2569 - val_loss: 9.4474\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1600 - val_loss: 9.7406\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.1864 - val_loss: 9.7455\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.2662 - val_loss: 9.5921\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1222 - val_loss: 9.4600\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.1261 - val_loss: 9.4518\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2413 - val_loss: 9.5750\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1198 - val_loss: 9.8292\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.1263 - val_loss: 10.0445\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.1132 - val_loss: 10.0487\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3320 - val_loss: 9.8394\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.1288 - val_loss: 9.7078\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2984 - val_loss: 9.6364\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2736 - val_loss: 9.5968\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1836 - val_loss: 9.6490\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.1652 - val_loss: 9.7509\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2275 - val_loss: 9.6788\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2286 - val_loss: 9.4322\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1040 - val_loss: 9.2908\n",
            "1/1 [==============================] - 1s 869ms/step - loss: 0.2689 - val_loss: 9.3620\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1505 - val_loss: 9.4927\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1268 - val_loss: 9.7390\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.1991 - val_loss: 9.7767\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.4228 - val_loss: 9.5122\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3342 - val_loss: 9.4207\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.1813 - val_loss: 9.4128\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.1955 - val_loss: 9.4781\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4348 - val_loss: 9.7281\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1287 - val_loss: 9.9577\n",
            "1/1 [==============================] - 1s 869ms/step - loss: 0.1807 - val_loss: 9.9598\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.2554 - val_loss: 9.7151\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.2104 - val_loss: 9.5795\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.1414 - val_loss: 9.5836\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.2044 - val_loss: 9.5887\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1585 - val_loss: 9.5957\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1599 - val_loss: 9.6155\n",
            "1/1 [==============================] - 1s 861ms/step - loss: 0.1955 - val_loss: 9.5382\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.0949 - val_loss: 9.4208\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0779 - val_loss: 9.3838\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2213 - val_loss: 9.3481\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.2073 - val_loss: 9.4485\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.1114 - val_loss: 9.5949\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1260 - val_loss: 9.7650\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0550 - val_loss: 9.8671\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2831 - val_loss: 9.7035\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1372 - val_loss: 9.6670\n",
            "1/1 [==============================] - 1s 860ms/step - loss: 0.3186 - val_loss: 9.5870\n",
            "1/1 [==============================] - 1s 870ms/step - loss: 0.1210 - val_loss: 9.5583\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.1409 - val_loss: 9.6787\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.2040 - val_loss: 9.8324\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.1158 - val_loss: 9.9103\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.3031 - val_loss: 9.6798\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.1676 - val_loss: 9.3386\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.1119 - val_loss: 9.2602\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.1267 - val_loss: 9.2535\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1837 - val_loss: 9.3459\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.2435 - val_loss: 9.5699\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.1756 - val_loss: 9.9251\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.2159 - val_loss: 9.9016\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.1445 - val_loss: 9.7114\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1810 - val_loss: 9.5681\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1709 - val_loss: 9.5366\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0853 - val_loss: 9.5124\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1367 - val_loss: 9.5342\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1458 - val_loss: 9.6808\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2787 - val_loss: 9.7418\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.1046 - val_loss: 9.5489\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1172 - val_loss: 9.3464\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1768 - val_loss: 9.2945\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1444 - val_loss: 9.3249\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.1641 - val_loss: 9.4405\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.1388 - val_loss: 9.6316\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.1134 - val_loss: 9.7575\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2287 - val_loss: 9.5916\n",
            "1/1 [==============================] - 1s 873ms/step - loss: 0.0881 - val_loss: 9.5198\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.0880 - val_loss: 9.5012\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.1703 - val_loss: 9.5428\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1138 - val_loss: 9.6308\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1651 - val_loss: 9.9316\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.1018 - val_loss: 10.1157\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.2258 - val_loss: 9.8103\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1288 - val_loss: 9.4352\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1840 - val_loss: 9.3358\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2073 - val_loss: 9.3262\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0679 - val_loss: 9.3450\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.2456 - val_loss: 9.6410\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.1644 - val_loss: 9.8309\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2320 - val_loss: 9.7123\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1046 - val_loss: 9.4742\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.1178 - val_loss: 9.3968\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.1858 - val_loss: 9.3927\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.1525 - val_loss: 9.5181\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1016 - val_loss: 9.6149\n",
            "1/1 [==============================] - 1s 874ms/step - loss: 0.1547 - val_loss: 9.5802\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1105 - val_loss: 9.4830\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1107 - val_loss: 9.3856\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.1046 - val_loss: 9.3195\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1945 - val_loss: 9.4488\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0829 - val_loss: 9.6135\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1847 - val_loss: 9.6943\n",
            "1/1 [==============================] - 1s 874ms/step - loss: 0.1878 - val_loss: 9.5730\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1149 - val_loss: 9.3869\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.1092 - val_loss: 9.3341\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3621 - val_loss: 9.4898\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1841 - val_loss: 9.7813\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2029 - val_loss: 9.7523\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.1058 - val_loss: 9.5650\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1475 - val_loss: 9.4700\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.0771 - val_loss: 9.4223\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1373 - val_loss: 9.4531\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1393 - val_loss: 9.5513\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2287 - val_loss: 9.5863\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.1866 - val_loss: 9.4907\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1764 - val_loss: 9.3228\n",
            "1/1 [==============================] - 1s 879ms/step - loss: 0.2207 - val_loss: 9.2443\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.1077 - val_loss: 9.2332\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2489 - val_loss: 9.4135\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.0716 - val_loss: 9.6575\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.1012 - val_loss: 9.8335\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.1990 - val_loss: 9.6903\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0778 - val_loss: 9.5529\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1001 - val_loss: 9.5663\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1633 - val_loss: 9.6809\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.0531 - val_loss: 9.8148\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1196 - val_loss: 9.8409\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0523 - val_loss: 9.7982\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.0900 - val_loss: 9.6516\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0491 - val_loss: 9.6064\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.0544 - val_loss: 9.5634\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0996 - val_loss: 9.5676\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.0933 - val_loss: 9.6046\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.0838 - val_loss: 9.6424\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.0703 - val_loss: 9.6640\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.0711 - val_loss: 9.6421\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.1076 - val_loss: 9.5892\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1044 - val_loss: 9.4382\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.0962 - val_loss: 9.4375\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0938 - val_loss: 9.5308\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0836 - val_loss: 9.7248\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1455 - val_loss: 9.7694\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3109 - val_loss: 9.5302\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1440 - val_loss: 9.3649\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.1110 - val_loss: 9.3442\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.1330 - val_loss: 9.3952\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1256 - val_loss: 9.5699\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.1100 - val_loss: 9.5726\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1241 - val_loss: 9.4927\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1079 - val_loss: 9.4282\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0857 - val_loss: 9.4136\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1143 - val_loss: 9.4581\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0789 - val_loss: 9.5295\n",
            "1/1 [==============================] - 1s 859ms/step - loss: 0.0529 - val_loss: 9.6963\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.0667 - val_loss: 9.9018\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.1531 - val_loss: 9.7033\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.1843 - val_loss: 9.4329\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.0749 - val_loss: 9.2817\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.3321 - val_loss: 9.2990\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1781 - val_loss: 9.4605\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1077 - val_loss: 9.7303\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1223 - val_loss: 9.9438\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2353 - val_loss: 9.7094\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1206 - val_loss: 9.4022\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0762 - val_loss: 9.3017\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.2688 - val_loss: 9.3333\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2285 - val_loss: 9.4977\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 0.1132 - val_loss: 9.7384\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2193 - val_loss: 9.6406\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0920 - val_loss: 9.4533\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.1019 - val_loss: 9.4260\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0927 - val_loss: 9.4578\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0871 - val_loss: 9.6089\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0627 - val_loss: 9.7412\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0933 - val_loss: 9.7402\n",
            "1/1 [==============================] - 1s 868ms/step - loss: 0.1010 - val_loss: 9.5938\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.1157 - val_loss: 9.3895\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.1072 - val_loss: 9.3342\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1210 - val_loss: 9.3706\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.1557 - val_loss: 9.5307\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.0520 - val_loss: 9.7213\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0626 - val_loss: 9.8124\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.1233 - val_loss: 9.6406\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.0667 - val_loss: 9.5355\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1273 - val_loss: 9.4933\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0891 - val_loss: 9.5720\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0991 - val_loss: 9.7402\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.1481 - val_loss: 9.7737\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0464 - val_loss: 9.7392\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1039 - val_loss: 9.5494\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.0716 - val_loss: 9.4299\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0615 - val_loss: 9.4164\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0710 - val_loss: 9.4681\n",
            "1/1 [==============================] - 1s 873ms/step - loss: 0.0628 - val_loss: 9.5925\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0953 - val_loss: 9.5886\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0421 - val_loss: 9.5521\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0423 - val_loss: 9.5207\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1273 - val_loss: 9.5471\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.0863 - val_loss: 9.5641\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.0412 - val_loss: 9.5210\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0291 - val_loss: 9.5083\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.0626 - val_loss: 9.4617\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0731 - val_loss: 9.4912\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0873 - val_loss: 9.5774\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0535 - val_loss: 9.7290\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0885 - val_loss: 9.7498\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.1072 - val_loss: 9.5978\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.0747 - val_loss: 9.4827\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0459 - val_loss: 9.4366\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0618 - val_loss: 9.4286\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.0532 - val_loss: 9.4688\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.0720 - val_loss: 9.5960\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.0568 - val_loss: 9.6905\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1352 - val_loss: 9.5282\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1173 - val_loss: 9.3250\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0694 - val_loss: 9.2544\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.1509 - val_loss: 9.3188\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.1206 - val_loss: 9.5208\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1330 - val_loss: 9.7146\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0961 - val_loss: 9.7704\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.1030 - val_loss: 9.6041\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0677 - val_loss: 9.4794\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.0369 - val_loss: 9.4307\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.1200 - val_loss: 9.4790\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0743 - val_loss: 9.5394\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.0734 - val_loss: 9.6305\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1054 - val_loss: 9.6681\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0870 - val_loss: 9.6837\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0931 - val_loss: 9.7379\n",
            "1/1 [==============================] - 1s 868ms/step - loss: 0.1086 - val_loss: 9.6161\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0787 - val_loss: 9.5223\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.0568 - val_loss: 9.5101\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0500 - val_loss: 9.5515\n",
            "1/1 [==============================] - 1s 860ms/step - loss: 0.0824 - val_loss: 9.5859\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1281 - val_loss: 9.5354\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0648 - val_loss: 9.4269\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1136 - val_loss: 9.3627\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0707 - val_loss: 9.3624\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0755 - val_loss: 9.3617\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0703 - val_loss: 9.3638\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.0821 - val_loss: 9.3915\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.0747 - val_loss: 9.4887\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0816 - val_loss: 9.6084\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0553 - val_loss: 9.6578\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.0550 - val_loss: 9.6084\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.0749 - val_loss: 9.5100\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0312 - val_loss: 9.4171\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.0824 - val_loss: 9.3787\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.0522 - val_loss: 9.4149\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.0587 - val_loss: 9.4952\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0876 - val_loss: 9.5137\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1051 - val_loss: 9.4183\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0762 - val_loss: 9.3810\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.0880 - val_loss: 9.4536\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.0403 - val_loss: 9.5023\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.0328 - val_loss: 9.5075\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.1534 - val_loss: 9.3777\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.1216 - val_loss: 9.3915\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.0421 - val_loss: 9.4233\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.0454 - val_loss: 9.5101\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0674 - val_loss: 9.5752\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0701 - val_loss: 9.5759\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0777 - val_loss: 9.5221\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0790 - val_loss: 9.5016\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0512 - val_loss: 9.5193\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.0939 - val_loss: 9.5383\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.0448 - val_loss: 9.6152\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0487 - val_loss: 9.6715\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0952 - val_loss: 9.5928\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0771 - val_loss: 9.5638\n",
            "1/1 [==============================] - 1s 875ms/step - loss: 0.1068 - val_loss: 9.5436\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0699 - val_loss: 9.5295\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0443 - val_loss: 9.5639\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0843 - val_loss: 9.6802\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1002 - val_loss: 9.6246\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0813 - val_loss: 9.4791\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.0607 - val_loss: 9.3815\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0350 - val_loss: 9.3150\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0760 - val_loss: 9.3539\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0846 - val_loss: 9.4860\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0847 - val_loss: 9.5966\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0793 - val_loss: 9.5774\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0772 - val_loss: 9.4970\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0569 - val_loss: 9.4171\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0382 - val_loss: 9.3904\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.0998 - val_loss: 9.4772\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.0381 - val_loss: 9.6466\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0961 - val_loss: 9.6947\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1096 - val_loss: 9.5426\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0924 - val_loss: 9.3432\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0904 - val_loss: 9.2450\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.1212 - val_loss: 9.2487\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1069 - val_loss: 9.3980\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.0710 - val_loss: 9.7429\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1604 - val_loss: 9.8400\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2098 - val_loss: 9.5653\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.0804 - val_loss: 9.4406\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.1194 - val_loss: 9.4444\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1718 - val_loss: 9.5874\n",
            "1/1 [==============================] - 1s 859ms/step - loss: 0.0942 - val_loss: 9.8284\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.1856 - val_loss: 9.8100\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.0882 - val_loss: 9.6494\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.1288 - val_loss: 9.4100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0696 - val_loss: 9.3043\n",
            "1/1 [==============================] - 1s 875ms/step - loss: 0.0564 - val_loss: 9.2716\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.0480 - val_loss: 9.2836\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0427 - val_loss: 9.3648\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0731 - val_loss: 9.4152\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.0978 - val_loss: 9.4207\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0934 - val_loss: 9.4435\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0647 - val_loss: 9.5207\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.0464 - val_loss: 9.6109\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.0511 - val_loss: 9.7281\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0888 - val_loss: 9.6800\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2002 - val_loss: 9.5176\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.1436 - val_loss: 9.4867\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.0775 - val_loss: 9.5426\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0924 - val_loss: 9.6490\n",
            "1/1 [==============================] - 1s 897ms/step - loss: 0.0949 - val_loss: 9.7473\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.0992 - val_loss: 9.6731\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1992 - val_loss: 9.3935\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0431 - val_loss: 9.2873\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.0895 - val_loss: 9.2812\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.0943 - val_loss: 9.3725\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.1468 - val_loss: 9.7337\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0876 - val_loss: 9.9867\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3746 - val_loss: 9.5136\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0395 - val_loss: 9.3670\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.2277 - val_loss: 9.3599\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1506 - val_loss: 9.4007\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1333 - val_loss: 9.6074\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1914 - val_loss: 9.8278\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1749 - val_loss: 9.7262\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.1270 - val_loss: 9.5728\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0665 - val_loss: 9.4117\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1491 - val_loss: 9.3940\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 0.1712 - val_loss: 9.4229\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1325 - val_loss: 9.5991\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.0864 - val_loss: 9.9253\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1204 - val_loss: 9.9942\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1811 - val_loss: 9.8082\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1254 - val_loss: 9.5589\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1084 - val_loss: 9.4901\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0792 - val_loss: 9.4611\n",
            "1/1 [==============================] - 1s 879ms/step - loss: 0.1836 - val_loss: 9.5105\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0945 - val_loss: 9.7781\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0814 - val_loss: 9.9930\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2339 - val_loss: 9.6931\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1326 - val_loss: 9.3213\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.0472 - val_loss: 9.1874\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2873 - val_loss: 9.2569\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1392 - val_loss: 9.4811\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0408 - val_loss: 9.7748\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1426 - val_loss: 9.7603\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.0888 - val_loss: 9.6114\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0874 - val_loss: 9.4966\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2015 - val_loss: 9.5205\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.1559 - val_loss: 9.6322\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.1151 - val_loss: 9.7482\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1321 - val_loss: 9.6528\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.1073 - val_loss: 9.3914\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0941 - val_loss: 9.3113\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.1032 - val_loss: 9.3353\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.0914 - val_loss: 9.4971\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0806 - val_loss: 9.5532\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.1771 - val_loss: 9.4543\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.0634 - val_loss: 9.3743\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.0725 - val_loss: 9.4006\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0787 - val_loss: 9.4769\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0967 - val_loss: 9.6097\n",
            "1/1 [==============================] - 1s 908ms/step - loss: 0.0660 - val_loss: 9.7515\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.1814 - val_loss: 9.6072\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1001 - val_loss: 9.4604\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.0557 - val_loss: 9.3518\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0780 - val_loss: 9.3506\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1089 - val_loss: 9.4234\n",
            "1/1 [==============================] - 1s 861ms/step - loss: 0.0412 - val_loss: 9.5626\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1569 - val_loss: 9.5183\n",
            "1/1 [==============================] - 1s 874ms/step - loss: 0.1818 - val_loss: 9.4956\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.0924 - val_loss: 9.4556\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.0804 - val_loss: 9.4090\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.1101 - val_loss: 9.3867\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.0627 - val_loss: 9.4505\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.0825 - val_loss: 9.5793\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0795 - val_loss: 9.6871\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0896 - val_loss: 9.6335\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0962 - val_loss: 9.4840\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.0875 - val_loss: 9.4047\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.0380 - val_loss: 9.3618\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0790 - val_loss: 9.3575\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.1221 - val_loss: 9.3968\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.0515 - val_loss: 9.4676\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0416 - val_loss: 9.5677\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0403 - val_loss: 9.5579\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0481 - val_loss: 9.4599\n",
            "1/1 [==============================] - 1s 876ms/step - loss: 0.0590 - val_loss: 9.4233\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.0406 - val_loss: 9.3908\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0542 - val_loss: 9.4359\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0735 - val_loss: 9.4703\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0343 - val_loss: 9.5651\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.0810 - val_loss: 9.6113\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0623 - val_loss: 9.5868\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0686 - val_loss: 9.5076\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.0401 - val_loss: 9.4282\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0608 - val_loss: 9.4124\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.0450 - val_loss: 9.4350\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.0340 - val_loss: 9.4825\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0604 - val_loss: 9.5955\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1384 - val_loss: 9.5782\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0940 - val_loss: 9.4658\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.0580 - val_loss: 9.3562\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.0617 - val_loss: 9.3168\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1339 - val_loss: 9.3675\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0512 - val_loss: 9.5217\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.0664 - val_loss: 9.5939\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.1033 - val_loss: 9.4684\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0808 - val_loss: 9.2914\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0548 - val_loss: 9.2275\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.1366 - val_loss: 9.2916\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.0604 - val_loss: 9.4595\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.0680 - val_loss: 9.5807\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.0880 - val_loss: 9.5306\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0557 - val_loss: 9.5056\n",
            "1/1 [==============================] - 1s 892ms/step - loss: 0.1277 - val_loss: 9.5301\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0733 - val_loss: 9.6135\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1302 - val_loss: 9.5717\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0755 - val_loss: 9.5326\n",
            "1/1 [==============================] - 1s 871ms/step - loss: 0.0791 - val_loss: 9.5505\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0706 - val_loss: 9.4895\n",
            "1/1 [==============================] - 1s 860ms/step - loss: 0.0435 - val_loss: 9.4268\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0545 - val_loss: 9.4069\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1048 - val_loss: 9.4600\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 0.1422 - val_loss: 9.5103\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.0665 - val_loss: 9.3848\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0332 - val_loss: 9.2969\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.1031 - val_loss: 9.3119\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0801 - val_loss: 9.3771\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.0860 - val_loss: 9.4322\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.0832 - val_loss: 9.4219\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0906 - val_loss: 9.4430\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0569 - val_loss: 9.4753\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0461 - val_loss: 9.5347\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.0388 - val_loss: 9.5677\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.0476 - val_loss: 9.5835\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.0442 - val_loss: 9.5340\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.0594 - val_loss: 9.4779\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.1016 - val_loss: 9.4619\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.1071 - val_loss: 9.4976\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0645 - val_loss: 9.4657\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0465 - val_loss: 9.4070\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0385 - val_loss: 9.3371\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.0660 - val_loss: 9.3737\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.0335 - val_loss: 9.4175\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.0387 - val_loss: 9.4527\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.0442 - val_loss: 9.3891\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0717 - val_loss: 9.3595\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.0497 - val_loss: 9.3739\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.0724 - val_loss: 9.4663\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0567 - val_loss: 9.5330\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0638 - val_loss: 9.5195\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0921 - val_loss: 9.4908\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0404 - val_loss: 9.5106\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0595 - val_loss: 9.5124\n",
            "1/1 [==============================] - 1s 901ms/step - loss: 0.1195 - val_loss: 9.6803\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.0550 - val_loss: 9.7898\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0951 - val_loss: 9.6921\n",
            "1/1 [==============================] - 1s 901ms/step - loss: 0.0504 - val_loss: 9.5806\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.0547 - val_loss: 9.5225\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1199 - val_loss: 9.4674\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.0782 - val_loss: 9.4950\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0381 - val_loss: 9.5935\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.0452 - val_loss: 9.6529\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0654 - val_loss: 9.5819\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0557 - val_loss: 9.4563\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1061 - val_loss: 9.4172\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1158 - val_loss: 9.5182\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.0560 - val_loss: 9.6237\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0541 - val_loss: 9.6469\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0960 - val_loss: 9.5119\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.0733 - val_loss: 9.4308\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0811 - val_loss: 9.4297\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.0715 - val_loss: 9.4707\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.1068 - val_loss: 9.5781\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.0446 - val_loss: 9.6678\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1248 - val_loss: 9.5324\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0473 - val_loss: 9.4278\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0489 - val_loss: 9.3595\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.1059 - val_loss: 9.4189\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.0404 - val_loss: 9.4745\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0421 - val_loss: 9.5502\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.0488 - val_loss: 9.6797\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.0881 - val_loss: 9.6460\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0813 - val_loss: 9.5662\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0833 - val_loss: 9.4427\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.0514 - val_loss: 9.3529\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.1080 - val_loss: 9.3700\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.0728 - val_loss: 9.5357\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.0881 - val_loss: 9.7356\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1858 - val_loss: 9.5307\n",
            "1/1 [==============================] - 1s 870ms/step - loss: 0.0785 - val_loss: 9.3423\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.0636 - val_loss: 9.2656\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1015 - val_loss: 9.2870\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0744 - val_loss: 9.3566\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1105 - val_loss: 9.4558\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0575 - val_loss: 9.5765\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0448 - val_loss: 9.6084\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.1349 - val_loss: 9.3957\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0664 - val_loss: 9.3050\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0757 - val_loss: 9.2761\n",
            "1/1 [==============================] - 1s 891ms/step - loss: 0.0933 - val_loss: 9.3423\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.0651 - val_loss: 9.4581\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.0666 - val_loss: 9.5237\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0622 - val_loss: 9.4690\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 0.0781 - val_loss: 9.4141\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0707 - val_loss: 9.3611\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0993 - val_loss: 9.3673\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1174 - val_loss: 9.4559\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0612 - val_loss: 9.5193\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0979 - val_loss: 9.5095\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1051 - val_loss: 9.4334\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 0.0632 - val_loss: 9.3383\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1334 - val_loss: 9.3715\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 0.0611 - val_loss: 9.3697\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0357 - val_loss: 9.3800\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.0821 - val_loss: 9.3730\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.1177 - val_loss: 9.4139\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0623 - val_loss: 9.4245\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 0.0645 - val_loss: 9.4486\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0471 - val_loss: 9.4183\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.0470 - val_loss: 9.4007\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0487 - val_loss: 9.3584\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.0570 - val_loss: 9.3432\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.1079 - val_loss: 9.4367\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0662 - val_loss: 9.4761\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.0605 - val_loss: 9.4267\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0325 - val_loss: 9.3925\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 0.0548 - val_loss: 9.3399\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.0658 - val_loss: 9.3516\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.0453 - val_loss: 9.3933\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0421 - val_loss: 9.4491\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0494 - val_loss: 9.4460\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0656 - val_loss: 9.3959\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.0443 - val_loss: 9.3555\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.0570 - val_loss: 9.3014\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0568 - val_loss: 9.3194\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.0981 - val_loss: 9.4365\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0897 - val_loss: 9.6163\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.1643 - val_loss: 9.5563\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.0557 - val_loss: 9.4650\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0649 - val_loss: 9.3914\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0542 - val_loss: 9.3739\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.0649 - val_loss: 9.4502\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.0448 - val_loss: 9.5488\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1041 - val_loss: 9.5168\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.0486 - val_loss: 9.4698\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.0167 - val_loss: 9.4551\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0305 - val_loss: 9.4620\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.0285 - val_loss: 9.4902\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0230 - val_loss: 9.5179\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.0160 - val_loss: 9.5690\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0391 - val_loss: 9.5256\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.0397 - val_loss: 9.4228\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.0655 - val_loss: 9.3037\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.1036 - val_loss: 9.3290\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0447 - val_loss: 9.4551\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0322 - val_loss: 9.5981\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.0757 - val_loss: 9.5492\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0576 - val_loss: 9.4227\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.0409 - val_loss: 9.3911\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0796 - val_loss: 9.4281\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.0900 - val_loss: 9.5079\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.0572 - val_loss: 9.5774\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 0.0430 - val_loss: 9.5158\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 0.0458 - val_loss: 9.4465\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0611 - val_loss: 9.4328\n",
            "1/1 [==============================] - 1s 871ms/step - loss: 0.0647 - val_loss: 9.4501\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0459 - val_loss: 9.5179\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0586 - val_loss: 9.5715\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0578 - val_loss: 9.5931\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0406 - val_loss: 9.5493\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0518 - val_loss: 9.4604\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0434 - val_loss: 9.3579\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0314 - val_loss: 9.3037\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0476 - val_loss: 9.3754\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.0625 - val_loss: 9.4731\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1487 - val_loss: 9.5143\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0321 - val_loss: 9.4625\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0550 - val_loss: 9.3997\n",
            "1/1 [==============================] - 1s 883ms/step - loss: 0.1223 - val_loss: 9.3670\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0263 - val_loss: 9.3781\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0332 - val_loss: 9.4638\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.0522 - val_loss: 9.5890\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.0721 - val_loss: 9.7373\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1235 - val_loss: 9.6142\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0566 - val_loss: 9.4566\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.0353 - val_loss: 9.3392\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0483 - val_loss: 9.3018\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0681 - val_loss: 9.3815\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0322 - val_loss: 9.4679\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.1310 - val_loss: 9.5820\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0514 - val_loss: 9.5867\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.0913 - val_loss: 9.3751\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.0466 - val_loss: 9.3156\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0548 - val_loss: 9.3471\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.0388 - val_loss: 9.4643\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0421 - val_loss: 9.4938\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0373 - val_loss: 9.4078\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.0736 - val_loss: 9.3248\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1124 - val_loss: 9.3446\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0481 - val_loss: 9.3727\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0196 - val_loss: 9.4320\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0433 - val_loss: 9.3809\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.0361 - val_loss: 9.3553\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0538 - val_loss: 9.3960\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0344 - val_loss: 9.4566\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1505 - val_loss: 9.5601\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0722 - val_loss: 9.5019\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.0421 - val_loss: 9.3985\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0165 - val_loss: 9.3151\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0287 - val_loss: 9.2935\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1555 - val_loss: 9.3353\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0284 - val_loss: 9.3690\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0200 - val_loss: 9.4156\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0490 - val_loss: 9.3694\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0465 - val_loss: 9.3180\n",
            "1/1 [==============================] - 1s 861ms/step - loss: 0.1118 - val_loss: 9.3192\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0379 - val_loss: 9.3355\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0676 - val_loss: 9.4016\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.0480 - val_loss: 9.4511\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0166 - val_loss: 9.4610\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1102 - val_loss: 9.4013\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 0.0315 - val_loss: 9.3733\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0748 - val_loss: 9.4347\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.0258 - val_loss: 9.5324\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.0436 - val_loss: 9.5233\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.0301 - val_loss: 9.4202\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0275 - val_loss: 9.2980\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 0.1605 - val_loss: 9.3237\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0427 - val_loss: 9.3757\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.0455 - val_loss: 9.3844\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0407 - val_loss: 9.3829\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.0198 - val_loss: 9.3861\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0270 - val_loss: 9.3734\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0130 - val_loss: 9.3592\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.0433 - val_loss: 9.3564\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.0585 - val_loss: 9.3989\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0729 - val_loss: 9.5175\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0561 - val_loss: 9.5366\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0328 - val_loss: 9.4527\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0369 - val_loss: 9.3565\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0441 - val_loss: 9.2698\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0521 - val_loss: 9.3304\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0285 - val_loss: 9.4550\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0528 - val_loss: 9.4841\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0637 - val_loss: 9.5056\n",
            "1/1 [==============================] - 1s 878ms/step - loss: 0.0543 - val_loss: 9.4714\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.0681 - val_loss: 9.4133\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0211 - val_loss: 9.4016\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0281 - val_loss: 9.3840\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.0240 - val_loss: 9.3974\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.0236 - val_loss: 9.4460\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0455 - val_loss: 9.4121\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.0304 - val_loss: 9.3780\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.0508 - val_loss: 9.3120\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.0481 - val_loss: 9.3120\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0336 - val_loss: 9.3804\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0526 - val_loss: 9.4992\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.0338 - val_loss: 9.5114\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0522 - val_loss: 9.4196\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0374 - val_loss: 9.3968\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.0255 - val_loss: 9.4184\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.0543 - val_loss: 9.4135\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.0313 - val_loss: 9.4034\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0302 - val_loss: 9.3824\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0176 - val_loss: 9.3875\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0410 - val_loss: 9.4245\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.0152 - val_loss: 9.4135\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0201 - val_loss: 9.3369\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0326 - val_loss: 9.2609\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0640 - val_loss: 9.2415\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0428 - val_loss: 9.2816\n",
            "1/1 [==============================] - 1s 880ms/step - loss: 0.0416 - val_loss: 9.3765\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.0254 - val_loss: 9.4907\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0290 - val_loss: 9.5537\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.0526 - val_loss: 9.4897\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0456 - val_loss: 9.4066\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 0.0259 - val_loss: 9.3721\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0280 - val_loss: 9.3892\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.0405 - val_loss: 9.4417\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0408 - val_loss: 9.4725\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.0334 - val_loss: 9.4744\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0328 - val_loss: 9.4317\n",
            "1/1 [==============================] - 1s 878ms/step - loss: 0.0229 - val_loss: 9.4393\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.0211 - val_loss: 9.4504\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.0097 - val_loss: 9.4640\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.0223 - val_loss: 9.4086\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.0208 - val_loss: 9.3909\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0226 - val_loss: 9.3959\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0408 - val_loss: 9.4135\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.0276 - val_loss: 9.4423\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.0703 - val_loss: 9.4773\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0299 - val_loss: 9.4402\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0153 - val_loss: 9.4267\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.0172 - val_loss: 9.4277\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.0349 - val_loss: 9.4148\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.0312 - val_loss: 9.4156\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.0163 - val_loss: 9.3795\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0534 - val_loss: 9.3572\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0217 - val_loss: 9.3826\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0163 - val_loss: 9.4165\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0228 - val_loss: 9.4539\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.0381 - val_loss: 9.4774\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0136 - val_loss: 9.4887\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.0261 - val_loss: 9.4526\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0322 - val_loss: 9.4480\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.0191 - val_loss: 9.4397\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.1047 - val_loss: 9.3849\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.0260 - val_loss: 9.3966\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.0281 - val_loss: 9.3710\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 0.0208 - val_loss: 9.4289\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.0306 - val_loss: 9.4041\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0244 - val_loss: 9.3555\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.0233 - val_loss: 9.3366\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0329 - val_loss: 9.3079\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0426 - val_loss: 9.3575\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0632 - val_loss: 9.4983\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0745 - val_loss: 9.5815\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.0466 - val_loss: 9.5033\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.0187 - val_loss: 9.4227\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0346 - val_loss: 9.4244\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0216 - val_loss: 9.4670\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.0198 - val_loss: 9.4439\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.0232 - val_loss: 9.4441\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.0216 - val_loss: 9.4294\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.0349 - val_loss: 9.3861\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.0349 - val_loss: 9.3604\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0368 - val_loss: 9.3752\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0233 - val_loss: 9.3942\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.0237 - val_loss: 9.4119\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0255 - val_loss: 9.4872\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0231 - val_loss: 9.4972\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0533 - val_loss: 9.4780\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.0246 - val_loss: 9.4343\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0340 - val_loss: 9.3777\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0286 - val_loss: 9.3464\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0240 - val_loss: 9.3425\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.0182 - val_loss: 9.3750\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.0395 - val_loss: 9.3579\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0717 - val_loss: 9.3609\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.0296 - val_loss: 9.3487\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0335 - val_loss: 9.3961\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.0331 - val_loss: 9.4109\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0290 - val_loss: 9.4473\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.0544 - val_loss: 9.4419\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.0312 - val_loss: 9.3861\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.0215 - val_loss: 9.3616\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0220 - val_loss: 9.3705\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0129 - val_loss: 9.3588\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0261 - val_loss: 9.3167\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.0247 - val_loss: 9.3274\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.0330 - val_loss: 9.3328\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1299 - val_loss: 9.3547\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0126 - val_loss: 9.3634\n",
            "1/1 [==============================] - 1s 882ms/step - loss: 0.0321 - val_loss: 9.4049\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0256 - val_loss: 9.4226\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0266 - val_loss: 9.4718\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.0373 - val_loss: 9.4679\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.0688 - val_loss: 9.4319\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0282 - val_loss: 9.4423\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0248 - val_loss: 9.4706\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.0152 - val_loss: 9.5063\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.0256 - val_loss: 9.4679\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0337 - val_loss: 9.4184\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0192 - val_loss: 9.3753\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0170 - val_loss: 9.3505\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0332 - val_loss: 9.3351\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0147 - val_loss: 9.3421\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0225 - val_loss: 9.3477\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.0218 - val_loss: 9.3499\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.0161 - val_loss: 9.3967\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.0497 - val_loss: 9.4304\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0199 - val_loss: 9.4708\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.0136 - val_loss: 9.4836\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.0349 - val_loss: 9.5237\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.0225 - val_loss: 9.5368\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0183 - val_loss: 9.5121\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.0225 - val_loss: 9.4449\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.0367 - val_loss: 9.4121\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0192 - val_loss: 9.4127\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0241 - val_loss: 9.4813\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.0152 - val_loss: 9.5480\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.0663 - val_loss: 9.4604\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0968 - val_loss: 9.3168\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0557 - val_loss: 9.2291\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0480 - val_loss: 9.2545\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.0240 - val_loss: 9.3561\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.0269 - val_loss: 9.4425\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0514 - val_loss: 9.3578\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0297 - val_loss: 9.3006\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0251 - val_loss: 9.3127\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0228 - val_loss: 9.3982\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.0915 - val_loss: 9.5189\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.0306 - val_loss: 9.5579\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0291 - val_loss: 9.4681\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0197 - val_loss: 9.3677\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.0292 - val_loss: 9.3480\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.0512 - val_loss: 9.4081\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.0485 - val_loss: 9.4924\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0246 - val_loss: 9.4953\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0382 - val_loss: 9.3755\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0200 - val_loss: 9.2663\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.0253 - val_loss: 9.2410\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0510 - val_loss: 9.2966\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.0534 - val_loss: 9.4848\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.0477 - val_loss: 9.5693\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0485 - val_loss: 9.4448\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0228 - val_loss: 9.3264\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0803 - val_loss: 9.3723\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0430 - val_loss: 9.5257\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 0.0503 - val_loss: 9.5993\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.0270 - val_loss: 9.5528\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0285 - val_loss: 9.4540\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0247 - val_loss: 9.3775\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.0439 - val_loss: 9.3326\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.0324 - val_loss: 9.3568\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0512 - val_loss: 9.4694\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0323 - val_loss: 9.4709\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.0621 - val_loss: 9.3504\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.0658 - val_loss: 9.3580\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0765 - val_loss: 9.4319\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0644 - val_loss: 9.5822\n",
            "1/1 [==============================] - 1s 879ms/step - loss: 0.0522 - val_loss: 9.7570\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.0892 - val_loss: 9.6299\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0463 - val_loss: 9.5154\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.0703 - val_loss: 9.4470\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0985 - val_loss: 9.4938\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.0388 - val_loss: 9.6045\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0945 - val_loss: 9.4634\n",
            "1/1 [==============================] - 1s 878ms/step - loss: 0.0276 - val_loss: 9.2998\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.0342 - val_loss: 9.2234\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0718 - val_loss: 9.2172\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.1616 - val_loss: 9.3172\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.0452 - val_loss: 9.4680\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0806 - val_loss: 9.5378\n",
            "1/1 [==============================] - 1s 889ms/step - loss: 0.0516 - val_loss: 9.4394\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0305 - val_loss: 9.4002\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.0272 - val_loss: 9.3823\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.0314 - val_loss: 9.3911\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.0543 - val_loss: 9.3769\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0511 - val_loss: 9.3541\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0344 - val_loss: 9.4177\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0696 - val_loss: 9.4020\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0374 - val_loss: 9.3433\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.1345 - val_loss: 9.2381\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0535 - val_loss: 9.2435\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0268 - val_loss: 9.3055\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.0256 - val_loss: 9.3832\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0447 - val_loss: 9.4185\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.0261 - val_loss: 9.3695\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0448 - val_loss: 9.3514\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.0340 - val_loss: 9.3882\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.0291 - val_loss: 9.3979\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0367 - val_loss: 9.4188\n",
            "1/1 [==============================] - 1s 876ms/step - loss: 0.0481 - val_loss: 9.4193\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.0333 - val_loss: 9.4463\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.0545 - val_loss: 9.4438\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.0525 - val_loss: 9.3496\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0520 - val_loss: 9.2877\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0420 - val_loss: 9.2331\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0353 - val_loss: 9.2833\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0451 - val_loss: 9.3351\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.0708 - val_loss: 9.2882\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0301 - val_loss: 9.3091\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.0284 - val_loss: 9.3586\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.0986 - val_loss: 9.3326\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0722 - val_loss: 9.3353\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0472 - val_loss: 9.3944\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0517 - val_loss: 9.4168\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.0463 - val_loss: 9.4310\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0580 - val_loss: 9.3718\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0587 - val_loss: 9.3656\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0624 - val_loss: 9.4543\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0396 - val_loss: 9.4664\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.0592 - val_loss: 9.4240\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0535 - val_loss: 9.4043\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0472 - val_loss: 9.4555\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0691 - val_loss: 9.5591\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0799 - val_loss: 9.5324\n",
            "1/1 [==============================] - 1s 873ms/step - loss: 0.0520 - val_loss: 9.4529\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0451 - val_loss: 9.3985\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.0911 - val_loss: 9.3482\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0592 - val_loss: 9.3947\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0428 - val_loss: 9.4842\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0352 - val_loss: 9.5055\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0519 - val_loss: 9.5365\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.0347 - val_loss: 9.4877\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0673 - val_loss: 9.5029\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.0605 - val_loss: 9.5568\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0677 - val_loss: 9.6642\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0936 - val_loss: 9.6123\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.0635 - val_loss: 9.4632\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.0679 - val_loss: 9.3072\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.0877 - val_loss: 9.2847\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0532 - val_loss: 9.3450\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.0476 - val_loss: 9.4742\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0555 - val_loss: 9.4785\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0527 - val_loss: 9.4068\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0307 - val_loss: 9.3314\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.0581 - val_loss: 9.3204\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0494 - val_loss: 9.3801\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0355 - val_loss: 9.4847\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.0482 - val_loss: 9.5887\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0916 - val_loss: 9.5328\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.0394 - val_loss: 9.4028\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.0496 - val_loss: 9.3254\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1144 - val_loss: 9.3562\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0638 - val_loss: 9.3848\n",
            "1/1 [==============================] - 1s 859ms/step - loss: 0.0941 - val_loss: 9.3574\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.0740 - val_loss: 9.3365\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 0.0370 - val_loss: 9.3099\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.0400 - val_loss: 9.2689\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.0436 - val_loss: 9.2573\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0254 - val_loss: 9.2757\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.0660 - val_loss: 9.3164\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0646 - val_loss: 9.4593\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0870 - val_loss: 9.5140\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.0507 - val_loss: 9.4225\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1037 - val_loss: 9.3676\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.0561 - val_loss: 9.3376\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0387 - val_loss: 9.3579\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.0483 - val_loss: 9.3753\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0426 - val_loss: 9.4800\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.0952 - val_loss: 9.6029\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.0916 - val_loss: 9.5328\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0334 - val_loss: 9.5241\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.0594 - val_loss: 9.5318\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0552 - val_loss: 9.5457\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.0890 - val_loss: 9.6336\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0596 - val_loss: 9.6303\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.1478 - val_loss: 9.4515\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 0.0330 - val_loss: 9.3662\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.0484 - val_loss: 9.3526\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 0.0732 - val_loss: 9.3872\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.0723 - val_loss: 9.3779\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.0383 - val_loss: 9.3300\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.0362 - val_loss: 9.3170\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0877 - val_loss: 9.4062\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.0295 - val_loss: 9.4508\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.0334 - val_loss: 9.4462\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0298 - val_loss: 9.4887\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0401 - val_loss: 9.5070\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.0417 - val_loss: 9.4325\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0537 - val_loss: 9.3314\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.0666 - val_loss: 9.3536\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1268 - val_loss: 9.3406\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.0647 - val_loss: 9.3584\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0463 - val_loss: 9.3945\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0456 - val_loss: 9.4181\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0693 - val_loss: 9.4713\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.1095 - val_loss: 9.3362\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0937 - val_loss: 9.3558\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0852 - val_loss: 9.3302\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0445 - val_loss: 9.3030\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.0556 - val_loss: 9.3571\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0537 - val_loss: 9.5051\n",
            "1/1 [==============================] - 1s 891ms/step - loss: 0.0959 - val_loss: 9.4855\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0461 - val_loss: 9.3429\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0921 - val_loss: 9.1994\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.0997 - val_loss: 9.2452\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.0374 - val_loss: 9.3373\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0521 - val_loss: 9.4874\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.0726 - val_loss: 9.5295\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.0861 - val_loss: 9.3651\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0642 - val_loss: 9.1579\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0245 - val_loss: 9.0841\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 0.2132 - val_loss: 9.2214\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0654 - val_loss: 9.5517\n",
            "1/1 [==============================] - 1s 860ms/step - loss: 0.1105 - val_loss: 9.6770\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.1421 - val_loss: 9.4608\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.0483 - val_loss: 9.3244\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0840 - val_loss: 9.3247\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.1690 - val_loss: 9.4463\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1530 - val_loss: 9.7528\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1373 - val_loss: 9.8609\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.1707 - val_loss: 9.5575\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0785 - val_loss: 9.3738\n",
            "1/1 [==============================] - 1s 876ms/step - loss: 0.0718 - val_loss: 9.2918\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1859 - val_loss: 9.2866\n",
            "1/1 [==============================] - 1s 861ms/step - loss: 0.0654 - val_loss: 9.3560\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0823 - val_loss: 9.4086\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.0525 - val_loss: 9.3708\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 0.0887 - val_loss: 9.2390\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.1326 - val_loss: 9.0905\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.0973 - val_loss: 9.1277\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.1038 - val_loss: 9.2678\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0842 - val_loss: 9.4703\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.0635 - val_loss: 9.4961\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1565 - val_loss: 9.4252\n",
            "1/1 [==============================] - 1s 895ms/step - loss: 0.0962 - val_loss: 9.3982\n",
            "1/1 [==============================] - 1s 861ms/step - loss: 0.1388 - val_loss: 9.4933\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0591 - val_loss: 9.5965\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.0778 - val_loss: 9.6464\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.1211 - val_loss: 9.5390\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0907 - val_loss: 9.4262\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1227 - val_loss: 9.3399\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1758 - val_loss: 9.4000\n",
            "1/1 [==============================] - 1s 886ms/step - loss: 0.1391 - val_loss: 9.4092\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1334 - val_loss: 9.4583\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1536 - val_loss: 9.3686\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0697 - val_loss: 9.3992\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0805 - val_loss: 9.4777\n",
            "1/1 [==============================] - 1s 895ms/step - loss: 0.1178 - val_loss: 9.6226\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2606 - val_loss: 9.4818\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1894 - val_loss: 9.3361\n",
            "1/1 [==============================] - 1s 859ms/step - loss: 0.0818 - val_loss: 9.2845\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1696 - val_loss: 9.3276\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.0779 - val_loss: 9.4682\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.1285 - val_loss: 9.6093\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2062 - val_loss: 9.6357\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0551 - val_loss: 9.6273\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0923 - val_loss: 9.7245\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1024 - val_loss: 9.7635\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0883 - val_loss: 9.7063\n",
            "1/1 [==============================] - 1s 883ms/step - loss: 0.1146 - val_loss: 9.4676\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0955 - val_loss: 9.3197\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2151 - val_loss: 9.2651\n",
            "1/1 [==============================] - 1s 859ms/step - loss: 0.2073 - val_loss: 9.4577\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1430 - val_loss: 9.4355\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0820 - val_loss: 9.2897\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.1240 - val_loss: 9.0508\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1577 - val_loss: 9.0587\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.1221 - val_loss: 9.2108\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.1343 - val_loss: 9.5276\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.1204 - val_loss: 9.5455\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0598 - val_loss: 9.5483\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0937 - val_loss: 9.4297\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.1409 - val_loss: 9.3197\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.1928 - val_loss: 9.3551\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.1494 - val_loss: 9.4642\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.1304 - val_loss: 9.5901\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2122 - val_loss: 9.2991\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.1490 - val_loss: 9.0590\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1978 - val_loss: 9.0356\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 0.3263 - val_loss: 9.1772\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.1620 - val_loss: 9.6385\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.2431 - val_loss: 9.6525\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2220 - val_loss: 9.3770\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.1048 - val_loss: 9.2231\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1402 - val_loss: 9.2070\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1524 - val_loss: 9.3698\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.1013 - val_loss: 9.4830\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1673 - val_loss: 9.4343\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.0935 - val_loss: 9.3715\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.1199 - val_loss: 9.3318\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1380 - val_loss: 9.2731\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1657 - val_loss: 9.3107\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0961 - val_loss: 9.3518\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0972 - val_loss: 9.4292\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1220 - val_loss: 9.7110\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1681 - val_loss: 9.7916\n",
            "1/1 [==============================] - 1s 878ms/step - loss: 0.2483 - val_loss: 9.6305\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.3091 - val_loss: 9.2549\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1010 - val_loss: 9.1329\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.1348 - val_loss: 9.0635\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2213 - val_loss: 9.0820\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2680 - val_loss: 9.5349\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.2641 - val_loss: 9.7764\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2700 - val_loss: 9.4840\n",
            "1/1 [==============================] - 1s 874ms/step - loss: 0.1037 - val_loss: 9.3709\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.1320 - val_loss: 9.3960\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1826 - val_loss: 9.4490\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.3021 - val_loss: 9.6025\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1991 - val_loss: 9.7640\n",
            "1/1 [==============================] - 1s 869ms/step - loss: 0.1664 - val_loss: 9.6591\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.3995 - val_loss: 9.4546\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.1849 - val_loss: 9.3177\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.1731 - val_loss: 9.2424\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1562 - val_loss: 9.1324\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0980 - val_loss: 9.0989\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1485 - val_loss: 9.1801\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1590 - val_loss: 9.3267\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2388 - val_loss: 9.5139\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.1328 - val_loss: 9.5539\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1355 - val_loss: 9.4506\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1692 - val_loss: 9.4395\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.1467 - val_loss: 9.5780\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1907 - val_loss: 9.8167\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.3709 - val_loss: 9.7019\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.2594 - val_loss: 9.4755\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.1854 - val_loss: 9.4603\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.2075 - val_loss: 9.4608\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.1379 - val_loss: 9.4957\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2255 - val_loss: 9.4697\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 0.1177 - val_loss: 9.2822\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.1383 - val_loss: 9.1517\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.4903 - val_loss: 9.1623\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.1994 - val_loss: 9.1975\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2548 - val_loss: 9.3305\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1522 - val_loss: 9.4787\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.1441 - val_loss: 9.5567\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1417 - val_loss: 9.5189\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.1631 - val_loss: 9.5125\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.1480 - val_loss: 9.5833\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.3757 - val_loss: 9.6679\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 0.3237 - val_loss: 9.6934\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2137 - val_loss: 9.7510\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.1605 - val_loss: 9.7575\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.6113 - val_loss: 9.1771\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.2326 - val_loss: 9.0311\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6369 - val_loss: 8.9267\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3250 - val_loss: 9.0906\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.1618 - val_loss: 9.6632\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7802 - val_loss: 9.2564\n",
            "1/1 [==============================] - 1s 860ms/step - loss: 0.2614 - val_loss: 9.1573\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4354 - val_loss: 9.3269\n",
            "1/1 [==============================] - 1s 889ms/step - loss: 0.1355 - val_loss: 9.5888\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.3005 - val_loss: 9.9496\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 0.5196 - val_loss: 9.9105\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.3106 - val_loss: 9.7771\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.3640 - val_loss: 9.6383\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4304 - val_loss: 9.6254\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3410 - val_loss: 9.7398\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.3298 - val_loss: 9.7889\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 0.2180 - val_loss: 9.4648\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3016 - val_loss: 9.0949\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.2616 - val_loss: 9.0656\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.3400 - val_loss: 9.2080\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.1994 - val_loss: 9.3928\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.4256 - val_loss: 9.0246\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.2567 - val_loss: 8.8812\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.4434 - val_loss: 8.9350\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5047 - val_loss: 9.1741\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.2754 - val_loss: 9.5411\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4382 - val_loss: 9.5715\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2840 - val_loss: 9.5559\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2995 - val_loss: 9.5975\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.2061 - val_loss: 9.6367\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.3999 - val_loss: 9.7325\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3403 - val_loss: 9.7979\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5752 - val_loss: 9.8215\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.3225 - val_loss: 9.5288\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1902 - val_loss: 9.4103\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.3431 - val_loss: 9.3505\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4285 - val_loss: 9.6258\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2870 - val_loss: 9.6720\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4656 - val_loss: 9.1508\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.2352 - val_loss: 9.0988\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6651 - val_loss: 9.0868\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3933 - val_loss: 9.1584\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3582 - val_loss: 9.3734\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.5702 - val_loss: 9.3515\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.3194 - val_loss: 9.3385\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4044 - val_loss: 9.1511\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3522 - val_loss: 9.0136\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.2364 - val_loss: 8.9449\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4872 - val_loss: 8.9755\n",
            "1/1 [==============================] - 1s 870ms/step - loss: 0.4411 - val_loss: 9.4869\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.4101 - val_loss: 10.2848\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.9377 - val_loss: 9.4973\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4803 - val_loss: 9.0910\n",
            "1/1 [==============================] - 1s 881ms/step - loss: 0.6149 - val_loss: 9.3085\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.9068 - val_loss: 9.3050\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.1898 - val_loss: 9.8020\n",
            "1/1 [==============================] - 1s 870ms/step - loss: 0.3873 - val_loss: 11.6254\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.8259 - val_loss: 9.7711\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6651 - val_loss: 9.4954\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3878 - val_loss: 9.5867\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.1546 - val_loss: 9.3629\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7158 - val_loss: 9.5258\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6077 - val_loss: 10.1942\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.1945 - val_loss: 8.9876\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.1452 - val_loss: 8.8767\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.1397 - val_loss: 8.8802\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 1.0990 - val_loss: 8.7873\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7720 - val_loss: 9.2832\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.1684 - val_loss: 9.5238\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.0440 - val_loss: 8.8542\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.7607 - val_loss: 8.7801\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 1.5366 - val_loss: 9.1075\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.8215 - val_loss: 9.3233\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 1.1873 - val_loss: 9.6098\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.7738 - val_loss: 9.2472\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6187 - val_loss: 9.1452\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.9059 - val_loss: 9.1752\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.8779 - val_loss: 9.1770\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.0058 - val_loss: 9.5839\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4718 - val_loss: 9.6824\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.9088 - val_loss: 9.3911\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.6261 - val_loss: 9.2042\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.9273 - val_loss: 9.1312\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.8988 - val_loss: 9.0638\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.9293 - val_loss: 9.0135\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.7383 - val_loss: 9.3587\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 1.0053 - val_loss: 9.4504\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5555 - val_loss: 9.2775\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.4544 - val_loss: 9.2117\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.6246 - val_loss: 9.3166\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.5414 - val_loss: 9.4566\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.0180 - val_loss: 10.0758\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5338 - val_loss: 10.4624\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6786 - val_loss: 9.9733\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.4406 - val_loss: 9.4943\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3984 - val_loss: 9.4025\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.6265 - val_loss: 9.4330\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3463 - val_loss: 9.6067\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3487 - val_loss: 9.7311\n",
            "1/1 [==============================] - 1s 915ms/step - loss: 0.5128 - val_loss: 9.6439\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.2897 - val_loss: 9.5293\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4677 - val_loss: 9.6336\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4576 - val_loss: 9.6261\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3187 - val_loss: 9.7115\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.2488 - val_loss: 9.9059\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 0.4647 - val_loss: 10.0602\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5929 - val_loss: 9.7280\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4946 - val_loss: 9.5483\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4102 - val_loss: 9.5250\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5784 - val_loss: 9.4318\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 1.0132 - val_loss: 9.8806\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.9219 - val_loss: 9.8415\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7212 - val_loss: 9.3254\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4030 - val_loss: 9.2016\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.4317 - val_loss: 9.1501\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.3596 - val_loss: 9.1426\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4442 - val_loss: 9.4075\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.5536 - val_loss: 9.8208\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2537 - val_loss: 9.8851\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6309 - val_loss: 9.3724\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2512 - val_loss: 9.1595\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.6277 - val_loss: 9.1012\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.4104 - val_loss: 9.1822\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.0546 - val_loss: 9.3773\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5849 - val_loss: 9.2764\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5636 - val_loss: 9.1138\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6177 - val_loss: 9.0540\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1313 - val_loss: 9.0422\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.4348 - val_loss: 9.0648\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.3901 - val_loss: 9.1498\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.4302 - val_loss: 9.3153\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4916 - val_loss: 9.3452\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.3365 - val_loss: 9.3227\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5055 - val_loss: 9.0720\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.3736 - val_loss: 9.0106\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6167 - val_loss: 9.0944\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6049 - val_loss: 9.2209\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2182 - val_loss: 9.3775\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.5819 - val_loss: 9.3581\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2276 - val_loss: 9.3580\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.2878 - val_loss: 9.2006\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3281 - val_loss: 9.1153\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.2742 - val_loss: 9.1064\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3067 - val_loss: 9.0651\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 0.3017 - val_loss: 9.1364\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2782 - val_loss: 9.4131\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3970 - val_loss: 9.3923\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2251 - val_loss: 9.1851\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2901 - val_loss: 9.0613\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.5987 - val_loss: 8.9181\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.2013 - val_loss: 8.8874\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.4742 - val_loss: 8.9870\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.3292 - val_loss: 9.1523\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.2486 - val_loss: 9.3412\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2646 - val_loss: 9.4176\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1329 - val_loss: 9.4137\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.1569 - val_loss: 9.3838\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.2388 - val_loss: 9.4215\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5262 - val_loss: 9.5472\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2421 - val_loss: 9.8530\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.2680 - val_loss: 10.1454\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3039 - val_loss: 10.0659\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.5676 - val_loss: 9.5464\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.4707 - val_loss: 9.4816\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7172 - val_loss: 9.3342\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.4120 - val_loss: 9.2782\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3605 - val_loss: 9.4564\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.6045 - val_loss: 9.6805\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.4968 - val_loss: 9.4317\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.4710 - val_loss: 8.9997\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2711 - val_loss: 8.9037\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.3496 - val_loss: 8.9853\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.4705 - val_loss: 9.2199\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3541 - val_loss: 9.6301\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5138 - val_loss: 9.5294\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5414 - val_loss: 9.2641\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.2327 - val_loss: 9.1315\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.2502 - val_loss: 9.0941\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.3461 - val_loss: 9.2624\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.2393 - val_loss: 9.5325\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.4375 - val_loss: 9.2050\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5575 - val_loss: 8.9121\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.2820 - val_loss: 8.8147\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.4717 - val_loss: 8.8054\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3546 - val_loss: 8.8657\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.1933 - val_loss: 9.0723\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2799 - val_loss: 9.3096\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3796 - val_loss: 9.1995\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3601 - val_loss: 9.0205\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.1897 - val_loss: 8.9984\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.1688 - val_loss: 9.0063\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4168 - val_loss: 9.1155\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2486 - val_loss: 9.4787\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3097 - val_loss: 9.7443\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.4113 - val_loss: 9.5236\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.2082 - val_loss: 9.2411\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.1641 - val_loss: 9.2057\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4487 - val_loss: 9.2032\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4836 - val_loss: 9.3699\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1145 - val_loss: 9.6723\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.3505 - val_loss: 9.5360\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.4400 - val_loss: 9.1900\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1987 - val_loss: 9.1410\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.3733 - val_loss: 9.1708\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2895 - val_loss: 9.2532\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.0514 - val_loss: 9.4520\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.2642 - val_loss: 9.5156\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1539 - val_loss: 9.5458\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.2787 - val_loss: 9.3627\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2030 - val_loss: 9.2727\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2518 - val_loss: 9.2676\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2554 - val_loss: 9.3268\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.1894 - val_loss: 9.4729\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2365 - val_loss: 9.5575\n",
            "1/1 [==============================] - 1s 902ms/step - loss: 0.3363 - val_loss: 9.3801\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2724 - val_loss: 9.2707\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.2201 - val_loss: 9.1866\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.2571 - val_loss: 9.0953\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6586 - val_loss: 8.9838\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5993 - val_loss: 8.9464\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3805 - val_loss: 8.9700\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3900 - val_loss: 9.1743\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.4130 - val_loss: 9.2477\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3830 - val_loss: 9.0427\n",
            "1/1 [==============================] - 1s 861ms/step - loss: 0.3145 - val_loss: 8.9898\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2528 - val_loss: 9.0142\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2299 - val_loss: 9.0461\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.4452 - val_loss: 9.2189\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1562 - val_loss: 9.2911\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2430 - val_loss: 9.1725\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.1856 - val_loss: 9.1218\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.2611 - val_loss: 9.1150\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2570 - val_loss: 9.1633\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.1632 - val_loss: 9.2792\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.3630 - val_loss: 9.4498\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1249 - val_loss: 9.6151\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2344 - val_loss: 9.4317\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.3087 - val_loss: 9.1523\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2045 - val_loss: 9.1036\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6791 - val_loss: 9.1687\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2249 - val_loss: 9.4448\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2729 - val_loss: 9.6434\n",
            "1/1 [==============================] - 1s 861ms/step - loss: 0.1672 - val_loss: 9.6906\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.2749 - val_loss: 9.3950\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4419 - val_loss: 9.1405\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3184 - val_loss: 9.0466\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4263 - val_loss: 9.1428\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.2625 - val_loss: 9.5682\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4744 - val_loss: 9.6085\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2784 - val_loss: 9.3693\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.1523 - val_loss: 9.3603\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.3275 - val_loss: 9.4311\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2918 - val_loss: 9.5161\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3275 - val_loss: 9.6081\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.2800 - val_loss: 9.6765\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.3502 - val_loss: 9.5527\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2843 - val_loss: 9.3738\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.3790 - val_loss: 9.2252\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3581 - val_loss: 9.1572\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5572 - val_loss: 9.1668\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.2515 - val_loss: 9.1469\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 0.4052 - val_loss: 9.1716\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3416 - val_loss: 8.9312\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.2245 - val_loss: 8.8658\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3194 - val_loss: 8.9445\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2602 - val_loss: 9.0678\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3163 - val_loss: 9.4365\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.8288 - val_loss: 9.2306\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.2427 - val_loss: 9.0570\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1013 - val_loss: 9.0189\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1693 - val_loss: 9.0092\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2149 - val_loss: 9.0358\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2984 - val_loss: 9.1742\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.3085 - val_loss: 9.3194\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.2247 - val_loss: 9.1773\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.2066 - val_loss: 9.0270\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.1657 - val_loss: 8.9860\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.2766 - val_loss: 9.0421\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.1930 - val_loss: 9.0366\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.2896 - val_loss: 9.0652\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1592 - val_loss: 9.1435\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1436 - val_loss: 9.1992\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.2422 - val_loss: 9.2685\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2177 - val_loss: 9.3231\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2137 - val_loss: 9.2432\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.1638 - val_loss: 9.1606\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.1171 - val_loss: 9.1661\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1839 - val_loss: 9.2263\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.1438 - val_loss: 9.2562\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1146 - val_loss: 9.2308\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.1058 - val_loss: 9.1086\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1301 - val_loss: 9.0627\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.0849 - val_loss: 9.0264\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2253 - val_loss: 9.0607\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0835 - val_loss: 9.1442\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1093 - val_loss: 9.1783\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1452 - val_loss: 9.0220\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 0.2921 - val_loss: 8.9948\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0781 - val_loss: 8.9617\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1077 - val_loss: 8.9782\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0854 - val_loss: 9.0047\n",
            "1/1 [==============================] - 1s 859ms/step - loss: 0.5091 - val_loss: 9.1839\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1340 - val_loss: 9.3584\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1902 - val_loss: 9.2940\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2155 - val_loss: 9.0894\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.0664 - val_loss: 9.0542\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.1511 - val_loss: 9.0670\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2391 - val_loss: 9.1729\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.2104 - val_loss: 9.5466\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2210 - val_loss: 9.7294\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2963 - val_loss: 9.4347\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.1947 - val_loss: 9.1782\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.1797 - val_loss: 9.0748\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2710 - val_loss: 9.0472\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.1811 - val_loss: 9.1160\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1842 - val_loss: 9.3414\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.2146 - val_loss: 9.4286\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2554 - val_loss: 9.1497\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.2534 - val_loss: 8.9051\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.2153 - val_loss: 8.8662\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3120 - val_loss: 8.8912\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.2528 - val_loss: 9.0284\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1126 - val_loss: 9.2320\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.1424 - val_loss: 9.3284\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.0798 - val_loss: 9.3557\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2010 - val_loss: 9.1673\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.0814 - val_loss: 9.0713\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.1692 - val_loss: 9.0668\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.1298 - val_loss: 9.0667\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.1805 - val_loss: 9.1834\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0789 - val_loss: 9.3133\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1151 - val_loss: 9.3108\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2294 - val_loss: 9.0710\n",
            "1/1 [==============================] - 1s 872ms/step - loss: 0.0885 - val_loss: 8.9647\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1174 - val_loss: 8.9416\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0814 - val_loss: 9.0131\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1051 - val_loss: 9.1670\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1135 - val_loss: 9.2238\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 0.2005 - val_loss: 9.0747\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0751 - val_loss: 9.0243\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 0.0785 - val_loss: 9.0133\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.0887 - val_loss: 9.0540\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0650 - val_loss: 9.1503\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0758 - val_loss: 9.2559\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.1437 - val_loss: 9.2072\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1369 - val_loss: 9.1414\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1215 - val_loss: 9.0850\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.0761 - val_loss: 9.0434\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.1545 - val_loss: 9.1605\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1022 - val_loss: 9.2670\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.1251 - val_loss: 9.2210\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0503 - val_loss: 9.1401\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0614 - val_loss: 9.0836\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.0399 - val_loss: 9.0910\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0951 - val_loss: 9.1582\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1881 - val_loss: 9.3930\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1064 - val_loss: 9.4579\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2109 - val_loss: 9.3020\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.1088 - val_loss: 9.1678\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1006 - val_loss: 9.1237\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0836 - val_loss: 9.1283\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.0739 - val_loss: 9.1965\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0595 - val_loss: 9.3188\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.1397 - val_loss: 9.3924\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2116 - val_loss: 9.2577\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.2217 - val_loss: 9.2116\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.1043 - val_loss: 9.2472\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0723 - val_loss: 9.3348\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0840 - val_loss: 9.4254\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0635 - val_loss: 9.4230\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.0898 - val_loss: 9.2943\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1548 - val_loss: 9.2233\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.0458 - val_loss: 9.2439\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.0705 - val_loss: 9.2821\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0461 - val_loss: 9.2493\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.1040 - val_loss: 9.2131\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0303 - val_loss: 9.1665\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.0400 - val_loss: 9.1462\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0684 - val_loss: 9.1666\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1531 - val_loss: 9.3042\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0756 - val_loss: 9.4076\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0871 - val_loss: 9.3608\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0597 - val_loss: 9.2869\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0629 - val_loss: 9.2157\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.1391 - val_loss: 9.2116\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.0811 - val_loss: 9.2419\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.0558 - val_loss: 9.2254\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.0920 - val_loss: 9.2208\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0989 - val_loss: 9.2350\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0767 - val_loss: 9.2352\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.0611 - val_loss: 9.2099\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.0393 - val_loss: 9.1945\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.0271 - val_loss: 9.1704\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0772 - val_loss: 9.1431\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0663 - val_loss: 9.1362\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.1021 - val_loss: 9.0870\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0929 - val_loss: 9.0660\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1126 - val_loss: 9.0854\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.0976 - val_loss: 9.1872\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0379 - val_loss: 9.2363\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.0700 - val_loss: 9.1624\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.0368 - val_loss: 9.1089\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.0696 - val_loss: 9.0463\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0695 - val_loss: 9.0330\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0943 - val_loss: 9.1233\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.0519 - val_loss: 9.1883\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0534 - val_loss: 9.2345\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0691 - val_loss: 9.2071\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0454 - val_loss: 9.1752\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.0546 - val_loss: 9.1743\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0733 - val_loss: 9.2247\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.0393 - val_loss: 9.3004\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0783 - val_loss: 9.3082\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.0642 - val_loss: 9.2300\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0439 - val_loss: 9.1448\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0523 - val_loss: 9.1320\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.0444 - val_loss: 9.1715\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.0564 - val_loss: 9.2283\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.0287 - val_loss: 9.2918\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.0981 - val_loss: 9.2304\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0610 - val_loss: 9.1338\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0334 - val_loss: 9.0888\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1095 - val_loss: 9.1475\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.0463 - val_loss: 9.2920\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.0554 - val_loss: 9.3267\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.0656 - val_loss: 9.2388\n",
            "1/1 [==============================] - 1s 781ms/step - loss: 0.0316 - val_loss: 9.1402\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0402 - val_loss: 9.0791\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.0641 - val_loss: 9.0504\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0428 - val_loss: 9.0618\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.0693 - val_loss: 9.1143\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0385 - val_loss: 9.1414\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0392 - val_loss: 9.1373\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0502 - val_loss: 9.0763\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.0346 - val_loss: 9.0216\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.0464 - val_loss: 9.0439\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.0532 - val_loss: 9.1108\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.0328 - val_loss: 9.1504\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0472 - val_loss: 9.1863\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0620 - val_loss: 9.2280\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.0463 - val_loss: 9.2087\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.0367 - val_loss: 9.2009\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.0626 - val_loss: 9.2129\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0414 - val_loss: 9.2558\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.0594 - val_loss: 9.2357\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0368 - val_loss: 9.2131\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0289 - val_loss: 9.2192\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 0.0409 - val_loss: 9.2375\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.0220 - val_loss: 9.2424\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.0242 - val_loss: 9.2522\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.0442 - val_loss: 9.2118\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.0422 - val_loss: 9.1931\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.0346 - val_loss: 9.1699\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0338 - val_loss: 9.1209\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.0183 - val_loss: 9.0784\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.0649 - val_loss: 9.1109\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0402 - val_loss: 9.0910\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.0402 - val_loss: 9.0570\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0369 - val_loss: 9.0243\n",
            "1/1 [==============================] - 1s 888ms/step - loss: 0.0352 - val_loss: 9.0404\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.0317 - val_loss: 9.0990\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.0697 - val_loss: 9.1267\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.0709 - val_loss: 9.2191\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.0365 - val_loss: 9.3395\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.0737 - val_loss: 9.2753\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.0261 - val_loss: 9.1636\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0681 - val_loss: 9.1287\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0492 - val_loss: 9.1269\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.0432 - val_loss: 9.1311\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.0533 - val_loss: 9.1784\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.0402 - val_loss: 9.2603\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0505 - val_loss: 9.2195\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.0355 - val_loss: 9.2037\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0427 - val_loss: 9.1948\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0201 - val_loss: 9.1900\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.0666 - val_loss: 9.1867\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.0319 - val_loss: 9.1698\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.0324 - val_loss: 9.1788\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.0545 - val_loss: 9.2570\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0187 - val_loss: 9.3222\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.0253 - val_loss: 9.3055\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.0301 - val_loss: 9.2205\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0239 - val_loss: 9.1645\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.0361 - val_loss: 9.1465\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.0309 - val_loss: 9.1915\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.0302 - val_loss: 9.2622\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0347 - val_loss: 9.2783\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0635 - val_loss: 9.2002\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0114 - val_loss: 9.1442\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.0257 - val_loss: 9.1277\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0379 - val_loss: 9.1456\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0693 - val_loss: 9.2226\n",
            "1/1 [==============================] - 1s 876ms/step - loss: 0.0138 - val_loss: 9.3112\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0446 - val_loss: 9.2610\n",
            "1/1 [==============================] - 1s 880ms/step - loss: 0.0267 - val_loss: 9.1593\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.0336 - val_loss: 9.0863\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0456 - val_loss: 9.0972\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0324 - val_loss: 9.1362\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.0286 - val_loss: 9.1814\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0164 - val_loss: 9.2378\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.0852 - val_loss: 9.1899\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.0165 - val_loss: 9.1595\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.0355 - val_loss: 9.1713\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0215 - val_loss: 9.1730\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0449 - val_loss: 9.2285\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.0216 - val_loss: 9.2808\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0613 - val_loss: 9.2258\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.1081 - val_loss: 9.0898\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0684 - val_loss: 9.0288\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.0523 - val_loss: 9.0403\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.0538 - val_loss: 9.1095\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.0204 - val_loss: 9.2040\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0199 - val_loss: 9.2479\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0656 - val_loss: 9.1327\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.0729 - val_loss: 9.0811\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0329 - val_loss: 9.0756\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0267 - val_loss: 9.1077\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0481 - val_loss: 9.2047\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.0425 - val_loss: 9.2688\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.0551 - val_loss: 9.2088\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.0132 - val_loss: 9.1382\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.0503 - val_loss: 9.0917\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0642 - val_loss: 9.1129\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.0409 - val_loss: 9.1687\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.0510 - val_loss: 9.2198\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0311 - val_loss: 9.2538\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.0754 - val_loss: 9.0938\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0261 - val_loss: 8.9671\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0905 - val_loss: 8.9700\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0545 - val_loss: 9.0581\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.0467 - val_loss: 9.1583\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0397 - val_loss: 9.1839\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0402 - val_loss: 9.1615\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.0542 - val_loss: 9.1721\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0167 - val_loss: 9.1787\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0381 - val_loss: 9.2002\n",
            "1/1 [==============================] - 1s 979ms/step - loss: 0.0404 - val_loss: 9.1841\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0483 - val_loss: 9.1879\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0380 - val_loss: 9.1969\n",
            "1/1 [==============================] - 1s 869ms/step - loss: 0.0318 - val_loss: 9.2112\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.0446 - val_loss: 9.1370\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.0272 - val_loss: 9.1087\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.0173 - val_loss: 9.0583\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.0422 - val_loss: 9.0566\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.0504 - val_loss: 9.1411\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0495 - val_loss: 9.2275\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.0548 - val_loss: 9.2322\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0324 - val_loss: 9.1647\n",
            "1/1 [==============================] - 1s 870ms/step - loss: 0.0288 - val_loss: 9.1096\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.0208 - val_loss: 9.0995\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.0625 - val_loss: 9.1481\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.0361 - val_loss: 9.2480\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.0448 - val_loss: 9.3835\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0405 - val_loss: 9.4289\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.0556 - val_loss: 9.2974\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.0303 - val_loss: 9.1657\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 0.0224 - val_loss: 9.0955\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.0680 - val_loss: 9.1173\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 0.0657 - val_loss: 9.2100\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 0.0678 - val_loss: 9.2706\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0471 - val_loss: 9.2551\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.0632 - val_loss: 9.1957\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0479 - val_loss: 9.0899\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0478 - val_loss: 9.0831\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0310 - val_loss: 9.1307\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0246 - val_loss: 9.2198\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.0362 - val_loss: 9.3237\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.0592 - val_loss: 9.2641\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.0247 - val_loss: 9.1826\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0491 - val_loss: 9.1578\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.0176 - val_loss: 9.1393\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.0421 - val_loss: 9.1871\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.0357 - val_loss: 9.2231\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.0418 - val_loss: 9.2511\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0297 - val_loss: 9.2083\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.0320 - val_loss: 9.1253\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0200 - val_loss: 9.0562\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0750 - val_loss: 9.0760\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0308 - val_loss: 9.1327\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0410 - val_loss: 9.2003\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.0322 - val_loss: 9.2188\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0255 - val_loss: 9.2040\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.0133 - val_loss: 9.2187\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.0200 - val_loss: 9.2191\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0337 - val_loss: 9.2078\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.0150 - val_loss: 9.2188\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0265 - val_loss: 9.2048\n",
            "1/1 [==============================] - 1s 860ms/step - loss: 0.0428 - val_loss: 9.2200\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.0173 - val_loss: 9.2286\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.0317 - val_loss: 9.2289\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0109 - val_loss: 9.1874\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.0257 - val_loss: 9.1426\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0218 - val_loss: 9.1415\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0174 - val_loss: 9.1306\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.0287 - val_loss: 9.1251\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0225 - val_loss: 9.1701\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0370 - val_loss: 9.2022\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0164 - val_loss: 9.2014\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.0077 - val_loss: 9.1923\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0169 - val_loss: 9.1562\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.0276 - val_loss: 9.1431\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0188 - val_loss: 9.1582\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0359 - val_loss: 9.1874\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0151 - val_loss: 9.2289\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.0201 - val_loss: 9.2348\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0237 - val_loss: 9.2249\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.0268 - val_loss: 9.1538\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.0254 - val_loss: 9.1391\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0114 - val_loss: 9.1398\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0193 - val_loss: 9.1459\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0341 - val_loss: 9.1501\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0236 - val_loss: 9.1640\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0236 - val_loss: 9.1930\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0203 - val_loss: 9.1706\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0190 - val_loss: 9.1206\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.0204 - val_loss: 9.1040\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.0277 - val_loss: 9.1440\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.0241 - val_loss: 9.1826\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 0.0340 - val_loss: 9.2432\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.0438 - val_loss: 9.2448\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.0204 - val_loss: 9.2219\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0185 - val_loss: 9.1823\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.1312 - val_loss: 9.2021\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.0142 - val_loss: 9.2440\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0143 - val_loss: 9.2550\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0199 - val_loss: 9.2570\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0227 - val_loss: 9.2110\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0170 - val_loss: 9.1757\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0270 - val_loss: 9.1795\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0233 - val_loss: 9.2203\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.0386 - val_loss: 9.2282\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.0214 - val_loss: 9.2145\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0188 - val_loss: 9.1950\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0164 - val_loss: 9.1862\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0204 - val_loss: 9.1964\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0253 - val_loss: 9.1762\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0245 - val_loss: 9.2109\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0665 - val_loss: 9.2725\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.0132 - val_loss: 9.3298\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0194 - val_loss: 9.2903\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.0110 - val_loss: 9.2485\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.0293 - val_loss: 9.1842\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0226 - val_loss: 9.1674\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.0187 - val_loss: 9.1791\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.0454 - val_loss: 9.1838\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.0187 - val_loss: 9.2077\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0332 - val_loss: 9.2301\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0222 - val_loss: 9.2058\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0151 - val_loss: 9.1698\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0293 - val_loss: 9.1717\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0230 - val_loss: 9.1999\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.0545 - val_loss: 9.1903\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0139 - val_loss: 9.1666\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.0200 - val_loss: 9.1607\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.0319 - val_loss: 9.1395\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0274 - val_loss: 9.1354\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0154 - val_loss: 9.1697\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0335 - val_loss: 9.2069\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0140 - val_loss: 9.2326\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.0468 - val_loss: 9.1669\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.0185 - val_loss: 9.1574\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.0128 - val_loss: 9.1811\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0341 - val_loss: 9.2104\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.0156 - val_loss: 9.1983\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0369 - val_loss: 9.1846\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0231 - val_loss: 9.1946\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0166 - val_loss: 9.1894\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0157 - val_loss: 9.1894\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0162 - val_loss: 9.1987\n",
            "1/1 [==============================] - 1s 870ms/step - loss: 0.0117 - val_loss: 9.1871\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.0108 - val_loss: 9.1646\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.0103 - val_loss: 9.1551\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0905 - val_loss: 9.1433\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0122 - val_loss: 9.1620\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.0186 - val_loss: 9.1877\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0309 - val_loss: 9.1778\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0114 - val_loss: 9.1479\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.0217 - val_loss: 9.1271\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0338 - val_loss: 9.1480\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.0145 - val_loss: 9.1809\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.0162 - val_loss: 9.2220\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0237 - val_loss: 9.2425\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0138 - val_loss: 9.2451\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.0178 - val_loss: 9.2565\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.0359 - val_loss: 9.2340\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0196 - val_loss: 9.2305\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.0327 - val_loss: 9.1917\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0199 - val_loss: 9.1801\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0198 - val_loss: 9.1266\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0225 - val_loss: 9.1376\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0109 - val_loss: 9.1533\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0175 - val_loss: 9.1271\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0176 - val_loss: 9.1028\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0108 - val_loss: 9.0955\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0078 - val_loss: 9.0868\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.0373 - val_loss: 9.0998\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0151 - val_loss: 9.1216\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0238 - val_loss: 9.1708\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.0182 - val_loss: 9.1850\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.0228 - val_loss: 9.1887\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0211 - val_loss: 9.2026\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.0193 - val_loss: 9.1755\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.0080 - val_loss: 9.1673\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0177 - val_loss: 9.1804\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0097 - val_loss: 9.1858\n",
            "1/1 [==============================] - 1s 890ms/step - loss: 0.0121 - val_loss: 9.1913\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.0368 - val_loss: 9.2073\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.0038 - val_loss: 9.2152\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 0.0171 - val_loss: 9.1758\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.0146 - val_loss: 9.1768\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0162 - val_loss: 9.2050\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.0134 - val_loss: 9.2281\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0144 - val_loss: 9.2272\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0748 - val_loss: 9.2079\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0146 - val_loss: 9.1885\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.0154 - val_loss: 9.1961\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.0204 - val_loss: 9.1980\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.0117 - val_loss: 9.2151\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.0184 - val_loss: 9.2048\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0485 - val_loss: 9.1873\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0081 - val_loss: 9.1645\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0164 - val_loss: 9.1434\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0124 - val_loss: 9.1416\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.0279 - val_loss: 9.1459\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.0088 - val_loss: 9.1586\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.0093 - val_loss: 9.1955\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.0341 - val_loss: 9.2248\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0229 - val_loss: 9.2373\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0139 - val_loss: 9.2140\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.0157 - val_loss: 9.2387\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0072 - val_loss: 9.2625\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0249 - val_loss: 9.2397\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0126 - val_loss: 9.2306\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.0295 - val_loss: 9.2322\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0382 - val_loss: 9.2756\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.0169 - val_loss: 9.2787\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.0243 - val_loss: 9.1815\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0128 - val_loss: 9.1287\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0096 - val_loss: 9.1057\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0373 - val_loss: 9.1483\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0360 - val_loss: 9.1847\n",
            "1/1 [==============================] - 1s 905ms/step - loss: 0.0161 - val_loss: 9.2006\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0249 - val_loss: 9.1894\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.0149 - val_loss: 9.1495\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.0134 - val_loss: 9.1540\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.0270 - val_loss: 9.1795\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0112 - val_loss: 9.2449\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0091 - val_loss: 9.2941\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.0331 - val_loss: 9.2526\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0083 - val_loss: 9.2081\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0235 - val_loss: 9.1876\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.0289 - val_loss: 9.2169\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0205 - val_loss: 9.2161\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0212 - val_loss: 9.1987\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.0181 - val_loss: 9.2086\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.0243 - val_loss: 9.1952\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.0141 - val_loss: 9.2086\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.0120 - val_loss: 9.1793\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0238 - val_loss: 9.1156\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0301 - val_loss: 9.1292\n",
            "1/1 [==============================] - 1s 876ms/step - loss: 0.0191 - val_loss: 9.1689\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.0384 - val_loss: 9.2177\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0157 - val_loss: 9.1926\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.0133 - val_loss: 9.1282\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 0.0116 - val_loss: 9.0838\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0331 - val_loss: 9.1264\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.0212 - val_loss: 9.2093\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0114 - val_loss: 9.2718\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0706 - val_loss: 9.1929\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0169 - val_loss: 9.1680\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.0395 - val_loss: 9.1930\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0181 - val_loss: 9.2343\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0282 - val_loss: 9.2721\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0531 - val_loss: 9.2442\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0329 - val_loss: 9.1867\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.0479 - val_loss: 9.2106\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.0390 - val_loss: 9.2479\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0146 - val_loss: 9.2366\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.0168 - val_loss: 9.1614\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.0306 - val_loss: 9.0834\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0294 - val_loss: 9.0554\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0697 - val_loss: 9.1094\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0363 - val_loss: 9.2197\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0231 - val_loss: 9.2568\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0449 - val_loss: 9.2012\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0376 - val_loss: 9.1405\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0567 - val_loss: 9.0956\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.1006 - val_loss: 9.1179\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0231 - val_loss: 9.1711\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0196 - val_loss: 9.2051\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.0332 - val_loss: 9.1822\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.0303 - val_loss: 9.1521\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.0324 - val_loss: 9.1667\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0319 - val_loss: 9.1837\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.0303 - val_loss: 9.1407\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.0375 - val_loss: 9.1302\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0447 - val_loss: 9.1459\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0128 - val_loss: 9.1591\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0304 - val_loss: 9.1669\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0162 - val_loss: 9.1734\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0114 - val_loss: 9.1722\n",
            "1/1 [==============================] - 1s 868ms/step - loss: 0.0285 - val_loss: 9.1463\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0469 - val_loss: 9.1623\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 0.0158 - val_loss: 9.1776\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0216 - val_loss: 9.2117\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0147 - val_loss: 9.2144\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.0265 - val_loss: 9.1659\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.0152 - val_loss: 9.1848\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.0252 - val_loss: 9.2045\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.0144 - val_loss: 9.1981\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0311 - val_loss: 9.1799\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0189 - val_loss: 9.1749\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.0121 - val_loss: 9.1996\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.0242 - val_loss: 9.1685\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0143 - val_loss: 9.1427\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0165 - val_loss: 9.1433\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.0369 - val_loss: 9.1410\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0252 - val_loss: 9.1641\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0316 - val_loss: 9.2140\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.0159 - val_loss: 9.2798\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0474 - val_loss: 9.1985\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.0393 - val_loss: 9.1784\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.0182 - val_loss: 9.2006\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0353 - val_loss: 9.2553\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0267 - val_loss: 9.2602\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.0155 - val_loss: 9.2106\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.0273 - val_loss: 9.1577\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.0107 - val_loss: 9.1111\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.0256 - val_loss: 9.1105\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0154 - val_loss: 9.1125\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.0114 - val_loss: 9.1120\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.0424 - val_loss: 9.1377\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0123 - val_loss: 9.1831\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0133 - val_loss: 9.2106\n",
            "1/1 [==============================] - 1s 876ms/step - loss: 0.0525 - val_loss: 9.2765\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0288 - val_loss: 9.3214\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0409 - val_loss: 9.2455\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.0205 - val_loss: 9.1707\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0571 - val_loss: 9.1844\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0149 - val_loss: 9.2661\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.0233 - val_loss: 9.3002\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0238 - val_loss: 9.2767\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0198 - val_loss: 9.1987\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0198 - val_loss: 9.1207\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0251 - val_loss: 9.0896\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.0664 - val_loss: 9.0853\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.0213 - val_loss: 9.0912\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0298 - val_loss: 9.1358\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.0123 - val_loss: 9.1974\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0419 - val_loss: 9.2169\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0254 - val_loss: 9.2240\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.0273 - val_loss: 9.1778\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.0205 - val_loss: 9.1465\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0714 - val_loss: 9.2299\n",
            "1/1 [==============================] - 1s 860ms/step - loss: 0.0414 - val_loss: 9.3173\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.0566 - val_loss: 9.3092\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.0525 - val_loss: 9.2251\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0473 - val_loss: 9.1465\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.0376 - val_loss: 9.1544\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 0.0433 - val_loss: 9.1933\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.0284 - val_loss: 9.2070\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0691 - val_loss: 9.1130\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.0278 - val_loss: 9.0585\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 0.0345 - val_loss: 9.0229\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.0463 - val_loss: 9.0980\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.0184 - val_loss: 9.1800\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0462 - val_loss: 9.1973\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0305 - val_loss: 9.2010\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.0295 - val_loss: 9.1998\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.0286 - val_loss: 9.2559\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0456 - val_loss: 9.3186\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0830 - val_loss: 9.2335\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.0589 - val_loss: 9.0983\n",
            "1/1 [==============================] - 1s 840ms/step - loss: 0.0634 - val_loss: 9.0485\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0533 - val_loss: 9.0593\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.0527 - val_loss: 9.2124\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0448 - val_loss: 9.3147\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1290 - val_loss: 9.1417\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.0438 - val_loss: 9.0458\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0790 - val_loss: 9.0691\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0349 - val_loss: 9.1299\n",
            "1/1 [==============================] - 1s 877ms/step - loss: 0.0460 - val_loss: 9.2504\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0287 - val_loss: 9.3368\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.0637 - val_loss: 9.3150\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0612 - val_loss: 9.1901\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0818 - val_loss: 9.1328\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0577 - val_loss: 9.1661\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.0490 - val_loss: 9.2752\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.0305 - val_loss: 9.3459\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0855 - val_loss: 9.2470\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0683 - val_loss: 9.1041\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0594 - val_loss: 9.0858\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.1102 - val_loss: 9.1815\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0485 - val_loss: 9.3205\n",
            "1/1 [==============================] - 1s 872ms/step - loss: 0.1005 - val_loss: 9.3649\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1091 - val_loss: 9.2520\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.0509 - val_loss: 9.1644\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0572 - val_loss: 9.1546\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.0751 - val_loss: 9.2824\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.0413 - val_loss: 9.4343\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.0865 - val_loss: 9.4006\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.0535 - val_loss: 9.2272\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.0572 - val_loss: 9.1800\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1834 - val_loss: 9.1915\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0317 - val_loss: 9.2509\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.0400 - val_loss: 9.2535\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0496 - val_loss: 9.1970\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0400 - val_loss: 9.1737\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.0996 - val_loss: 9.2200\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0629 - val_loss: 9.2692\n",
            "1/1 [==============================] - 1s 994ms/step - loss: 0.0730 - val_loss: 9.1676\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.0758 - val_loss: 9.1203\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1019 - val_loss: 9.0924\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0653 - val_loss: 9.1344\n",
            "1/1 [==============================] - 1s 847ms/step - loss: 0.0277 - val_loss: 9.2212\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.0522 - val_loss: 9.3025\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.0722 - val_loss: 9.2751\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0660 - val_loss: 9.1413\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.0431 - val_loss: 9.0956\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0885 - val_loss: 9.1095\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.0530 - val_loss: 9.1761\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.0360 - val_loss: 9.2427\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.0843 - val_loss: 9.1764\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.0406 - val_loss: 9.1738\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.0354 - val_loss: 9.1733\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0212 - val_loss: 9.1735\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0433 - val_loss: 9.2244\n",
            "1/1 [==============================] - 1s 835ms/step - loss: 0.0559 - val_loss: 9.3190\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.0573 - val_loss: 9.3531\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0884 - val_loss: 9.2682\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.0462 - val_loss: 9.2291\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0397 - val_loss: 9.2292\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.0976 - val_loss: 9.2839\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0760 - val_loss: 9.3636\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.0817 - val_loss: 9.3116\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.0438 - val_loss: 9.2076\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 0.0548 - val_loss: 9.1117\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.0444 - val_loss: 9.0623\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 0.0756 - val_loss: 9.1135\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.0633 - val_loss: 9.1899\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0611 - val_loss: 9.2452\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.0672 - val_loss: 9.1809\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0807 - val_loss: 9.0225\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0932 - val_loss: 9.0005\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0983 - val_loss: 9.0699\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0721 - val_loss: 9.2307\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.0245 - val_loss: 9.4514\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.0796 - val_loss: 9.4536\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.0398 - val_loss: 9.3297\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0668 - val_loss: 9.2249\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0782 - val_loss: 9.2112\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.0657 - val_loss: 9.2094\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0681 - val_loss: 9.2240\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.0417 - val_loss: 9.2449\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.0696 - val_loss: 9.1640\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0820 - val_loss: 9.1105\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.0444 - val_loss: 9.0645\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0549 - val_loss: 9.0650\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.0336 - val_loss: 9.1111\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0719 - val_loss: 9.1630\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0537 - val_loss: 9.1590\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.0426 - val_loss: 9.1069\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.0427 - val_loss: 9.0972\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 0.0455 - val_loss: 9.0951\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0564 - val_loss: 9.1521\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0475 - val_loss: 9.2196\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1265 - val_loss: 9.0660\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.0633 - val_loss: 9.0041\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0898 - val_loss: 9.0376\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.0588 - val_loss: 9.1133\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0332 - val_loss: 9.1993\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0420 - val_loss: 9.2085\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0704 - val_loss: 9.2078\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.0450 - val_loss: 9.1663\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1295 - val_loss: 9.1249\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0232 - val_loss: 9.1254\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0445 - val_loss: 9.1465\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0259 - val_loss: 9.1303\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0309 - val_loss: 9.1179\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1390 - val_loss: 9.1257\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0367 - val_loss: 9.1730\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0445 - val_loss: 9.1940\n",
            "1/1 [==============================] - 1s 867ms/step - loss: 0.0790 - val_loss: 9.2001\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0591 - val_loss: 9.2124\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0531 - val_loss: 9.2711\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.0367 - val_loss: 9.3612\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0583 - val_loss: 9.3820\n",
            "1/1 [==============================] - 1s 879ms/step - loss: 0.0474 - val_loss: 9.3576\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0381 - val_loss: 9.3504\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.0480 - val_loss: 9.3294\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.1522 - val_loss: 9.3284\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0854 - val_loss: 9.2521\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.0675 - val_loss: 9.1660\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.0311 - val_loss: 9.1188\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0502 - val_loss: 9.0780\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.0735 - val_loss: 9.1493\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0478 - val_loss: 9.2963\n",
            "1/1 [==============================] - 1s 828ms/step - loss: 0.0872 - val_loss: 9.2470\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0656 - val_loss: 9.0991\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0342 - val_loss: 9.0533\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0852 - val_loss: 9.0863\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.0529 - val_loss: 9.1673\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0522 - val_loss: 9.2701\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0601 - val_loss: 9.3304\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.0806 - val_loss: 9.2227\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.0705 - val_loss: 9.1604\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0734 - val_loss: 9.1970\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.0970 - val_loss: 9.2888\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.0711 - val_loss: 9.3676\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.1008 - val_loss: 9.2720\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.1159 - val_loss: 9.1546\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0594 - val_loss: 9.0885\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.1053 - val_loss: 9.1193\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.1137 - val_loss: 9.2339\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.0958 - val_loss: 9.1826\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0925 - val_loss: 8.9873\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.0620 - val_loss: 8.8625\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0783 - val_loss: 8.8346\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1108 - val_loss: 8.8974\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0844 - val_loss: 9.1004\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1515 - val_loss: 9.0404\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0751 - val_loss: 9.0231\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0626 - val_loss: 9.0433\n",
            "1/1 [==============================] - 1s 860ms/step - loss: 0.1091 - val_loss: 9.1262\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0603 - val_loss: 9.2626\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.2392 - val_loss: 9.2009\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0385 - val_loss: 9.1095\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.0656 - val_loss: 9.0988\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.0332 - val_loss: 9.1497\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.0522 - val_loss: 9.1844\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.0717 - val_loss: 9.1098\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1616 - val_loss: 9.1406\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.1292 - val_loss: 9.2506\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 0.0686 - val_loss: 9.2832\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1222 - val_loss: 9.2503\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1587 - val_loss: 9.1927\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0913 - val_loss: 9.1615\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1074 - val_loss: 9.1145\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0466 - val_loss: 9.0859\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0851 - val_loss: 9.1128\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0816 - val_loss: 9.1133\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0583 - val_loss: 9.0719\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0518 - val_loss: 9.0670\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.0457 - val_loss: 9.0938\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 0.1033 - val_loss: 9.2622\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.0852 - val_loss: 9.3817\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1245 - val_loss: 9.1099\n",
            "1/1 [==============================] - 1s 861ms/step - loss: 0.1818 - val_loss: 8.9451\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1960 - val_loss: 8.9261\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2723 - val_loss: 8.9786\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1375 - val_loss: 9.4804\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.1765 - val_loss: 9.7670\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.2829 - val_loss: 9.3224\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.1026 - val_loss: 9.1976\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2637 - val_loss: 9.2652\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.3457 - val_loss: 9.3024\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.1539 - val_loss: 9.5418\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.1319 - val_loss: 10.1019\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.3324 - val_loss: 9.9199\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2819 - val_loss: 9.3330\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1620 - val_loss: 9.1602\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3606 - val_loss: 9.0725\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4343 - val_loss: 9.2860\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1748 - val_loss: 9.6456\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.3347 - val_loss: 9.4874\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.2631 - val_loss: 9.1229\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.1209 - val_loss: 8.9841\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.1944 - val_loss: 8.9787\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2014 - val_loss: 9.0821\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.1151 - val_loss: 9.3202\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1487 - val_loss: 9.4464\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3304 - val_loss: 9.1403\n",
            "1/1 [==============================] - 1s 869ms/step - loss: 0.1008 - val_loss: 9.0430\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1914 - val_loss: 9.0765\n",
            "1/1 [==============================] - 1s 859ms/step - loss: 0.1429 - val_loss: 9.1424\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.2506 - val_loss: 9.3899\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2013 - val_loss: 9.7186\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2283 - val_loss: 9.4934\n",
            "1/1 [==============================] - 1s 889ms/step - loss: 0.1118 - val_loss: 9.1896\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1687 - val_loss: 9.1177\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1971 - val_loss: 9.1113\n",
            "1/1 [==============================] - 1s 873ms/step - loss: 0.1343 - val_loss: 9.1226\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1667 - val_loss: 9.2832\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1639 - val_loss: 9.3320\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.1575 - val_loss: 9.1615\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.1401 - val_loss: 9.1071\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1223 - val_loss: 9.0163\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.0905 - val_loss: 8.9558\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.1176 - val_loss: 8.9712\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.0960 - val_loss: 9.0122\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.1310 - val_loss: 9.1033\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1234 - val_loss: 9.2022\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.2124 - val_loss: 9.1757\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.1179 - val_loss: 9.1602\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.0856 - val_loss: 9.1495\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1695 - val_loss: 9.3197\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1673 - val_loss: 9.3717\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1082 - val_loss: 9.2761\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1048 - val_loss: 9.2499\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1502 - val_loss: 9.3383\n",
            "1/1 [==============================] - 1s 883ms/step - loss: 0.2698 - val_loss: 9.2906\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0714 - val_loss: 9.2427\n",
            "1/1 [==============================] - 1s 841ms/step - loss: 0.1601 - val_loss: 9.0619\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.0710 - val_loss: 8.9854\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.0999 - val_loss: 8.9414\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0698 - val_loss: 8.9712\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.1601 - val_loss: 8.9569\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.0531 - val_loss: 8.9772\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.0824 - val_loss: 9.0128\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.1354 - val_loss: 9.0715\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0877 - val_loss: 9.1114\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1224 - val_loss: 9.1367\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1193 - val_loss: 9.1673\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1513 - val_loss: 9.0840\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.0688 - val_loss: 9.0243\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.1114 - val_loss: 9.0340\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.1951 - val_loss: 9.1202\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1270 - val_loss: 9.1375\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.1061 - val_loss: 9.1802\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1787 - val_loss: 9.2411\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0849 - val_loss: 9.2068\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1938 - val_loss: 9.2183\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.1384 - val_loss: 9.1708\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.0694 - val_loss: 9.2412\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.1004 - val_loss: 9.3546\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.1280 - val_loss: 9.3064\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1234 - val_loss: 9.2010\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0678 - val_loss: 9.1462\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0661 - val_loss: 9.1787\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0722 - val_loss: 9.2064\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1159 - val_loss: 9.1158\n",
            "1/1 [==============================] - 1s 825ms/step - loss: 0.1432 - val_loss: 8.8888\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.2494 - val_loss: 8.9120\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.1165 - val_loss: 9.0792\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0653 - val_loss: 9.2376\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1635 - val_loss: 9.3445\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.1670 - val_loss: 9.2466\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1233 - val_loss: 9.1521\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0771 - val_loss: 9.0955\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.2399 - val_loss: 9.1332\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.2507 - val_loss: 9.2357\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.1258 - val_loss: 9.3137\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.1191 - val_loss: 9.3180\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1137 - val_loss: 9.2246\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1218 - val_loss: 9.0638\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.0528 - val_loss: 8.9476\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1128 - val_loss: 8.9400\n",
            "1/1 [==============================] - 1s 852ms/step - loss: 0.0829 - val_loss: 9.0412\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.1091 - val_loss: 9.2411\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2530 - val_loss: 9.1517\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.1489 - val_loss: 9.1016\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.0544 - val_loss: 9.0839\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.1773 - val_loss: 8.9966\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.0584 - val_loss: 8.9452\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.0925 - val_loss: 8.9931\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.1381 - val_loss: 9.1098\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0509 - val_loss: 9.2534\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.0923 - val_loss: 9.3536\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1768 - val_loss: 9.1752\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1021 - val_loss: 9.0562\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1105 - val_loss: 9.0881\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.0893 - val_loss: 9.2036\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1005 - val_loss: 9.4128\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1723 - val_loss: 9.3392\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1226 - val_loss: 9.2262\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.0661 - val_loss: 9.2220\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2138 - val_loss: 9.3190\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.1316 - val_loss: 9.4653\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1784 - val_loss: 9.4021\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 0.1338 - val_loss: 9.2517\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0829 - val_loss: 9.0619\n",
            "1/1 [==============================] - 1s 879ms/step - loss: 0.1725 - val_loss: 9.0290\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0908 - val_loss: 9.0819\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2092 - val_loss: 9.0711\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1672 - val_loss: 9.0157\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1436 - val_loss: 8.9876\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.0587 - val_loss: 8.9830\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0645 - val_loss: 8.9901\n",
            "1/1 [==============================] - 1s 849ms/step - loss: 0.1448 - val_loss: 9.0566\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0571 - val_loss: 9.1609\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.1047 - val_loss: 9.2293\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1181 - val_loss: 9.1979\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1075 - val_loss: 9.1253\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.1262 - val_loss: 9.1189\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.1154 - val_loss: 9.1580\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.1067 - val_loss: 9.3020\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1004 - val_loss: 9.2768\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0941 - val_loss: 9.1132\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 0.0752 - val_loss: 8.9883\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1378 - val_loss: 8.9233\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1318 - val_loss: 8.9621\n",
            "1/1 [==============================] - 1s 860ms/step - loss: 0.0965 - val_loss: 9.0311\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0827 - val_loss: 9.0705\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1387 - val_loss: 9.0119\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0764 - val_loss: 8.9387\n",
            "1/1 [==============================] - 1s 817ms/step - loss: 0.0592 - val_loss: 8.9472\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.1468 - val_loss: 8.9550\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0902 - val_loss: 9.0242\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0987 - val_loss: 9.1913\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.1275 - val_loss: 9.1071\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.0715 - val_loss: 8.9902\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1639 - val_loss: 8.9211\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.1298 - val_loss: 9.0026\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.1273 - val_loss: 9.2005\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.1538 - val_loss: 9.4164\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 0.2048 - val_loss: 9.2044\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1232 - val_loss: 9.0578\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1018 - val_loss: 9.0414\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0576 - val_loss: 9.0794\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1545 - val_loss: 9.2538\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1023 - val_loss: 9.3145\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0688 - val_loss: 9.2078\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0485 - val_loss: 9.1191\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1970 - val_loss: 8.9929\n",
            "1/1 [==============================] - 1s 842ms/step - loss: 0.0919 - val_loss: 8.9556\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.1517 - val_loss: 9.0285\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.1139 - val_loss: 9.1699\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0731 - val_loss: 9.2012\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.0854 - val_loss: 9.1412\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.0614 - val_loss: 9.0479\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.1082 - val_loss: 9.0182\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.1136 - val_loss: 8.9951\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1939 - val_loss: 9.0215\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.1420 - val_loss: 9.1797\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1403 - val_loss: 9.4738\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2340 - val_loss: 9.3260\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.1447 - val_loss: 9.0688\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.0953 - val_loss: 8.8889\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.2776 - val_loss: 8.9218\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1285 - val_loss: 9.1788\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1867 - val_loss: 9.3379\n",
            "1/1 [==============================] - 1s 850ms/step - loss: 0.1708 - val_loss: 9.1988\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.1052 - val_loss: 8.9674\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.0787 - val_loss: 8.9040\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1835 - val_loss: 8.9570\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1230 - val_loss: 9.1071\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.1678 - val_loss: 9.3802\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.1040 - val_loss: 9.3998\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.1933 - val_loss: 9.2077\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0780 - val_loss: 9.0945\n",
            "1/1 [==============================] - 1s 878ms/step - loss: 0.0814 - val_loss: 9.0630\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.1663 - val_loss: 9.0825\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.2809 - val_loss: 9.2888\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1893 - val_loss: 9.2804\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1106 - val_loss: 9.1279\n",
            "1/1 [==============================] - 1s 821ms/step - loss: 0.0938 - val_loss: 9.0433\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1078 - val_loss: 9.0654\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1855 - val_loss: 9.2917\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1569 - val_loss: 9.5075\n",
            "1/1 [==============================] - 1s 869ms/step - loss: 0.2123 - val_loss: 9.3962\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1841 - val_loss: 9.1776\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0994 - val_loss: 9.1187\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1266 - val_loss: 9.1517\n",
            "1/1 [==============================] - 1s 871ms/step - loss: 0.1646 - val_loss: 9.4015\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2580 - val_loss: 9.2853\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1315 - val_loss: 9.0246\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.1273 - val_loss: 8.9202\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0926 - val_loss: 8.9303\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2338 - val_loss: 9.1709\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0994 - val_loss: 9.4557\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2635 - val_loss: 9.0869\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.0686 - val_loss: 8.8772\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0989 - val_loss: 8.8147\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2260 - val_loss: 8.8298\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2268 - val_loss: 9.2086\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1618 - val_loss: 9.4871\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3379 - val_loss: 9.0030\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0918 - val_loss: 8.7973\n",
            "1/1 [==============================] - 1s 856ms/step - loss: 0.2771 - val_loss: 8.7773\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3109 - val_loss: 8.9498\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1085 - val_loss: 9.2084\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.2243 - val_loss: 9.1725\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0833 - val_loss: 9.0785\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.1898 - val_loss: 8.9738\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 0.1624 - val_loss: 8.9252\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.1992 - val_loss: 8.9404\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.1558 - val_loss: 8.9411\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.1498 - val_loss: 9.0594\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.1297 - val_loss: 9.1754\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 0.0929 - val_loss: 9.2766\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2336 - val_loss: 8.9765\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1875 - val_loss: 8.9140\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0901 - val_loss: 8.9620\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2177 - val_loss: 8.9950\n",
            "1/1 [==============================] - 1s 833ms/step - loss: 0.0581 - val_loss: 9.0851\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.2642 - val_loss: 9.1982\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1230 - val_loss: 9.1044\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0751 - val_loss: 8.9547\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3396 - val_loss: 8.9381\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0790 - val_loss: 8.9711\n",
            "1/1 [==============================] - 1s 853ms/step - loss: 0.0859 - val_loss: 9.0375\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.0870 - val_loss: 9.1411\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.1414 - val_loss: 9.0746\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.1133 - val_loss: 8.9844\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.1352 - val_loss: 8.9878\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 0.0865 - val_loss: 9.0228\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2022 - val_loss: 9.2221\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1033 - val_loss: 9.3114\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.1260 - val_loss: 9.1424\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0455 - val_loss: 9.0396\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 0.0739 - val_loss: 9.0039\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0984 - val_loss: 9.0458\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2030 - val_loss: 9.2511\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2325 - val_loss: 9.2093\n",
            "1/1 [==============================] - 1s 874ms/step - loss: 0.1533 - val_loss: 9.1067\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0769 - val_loss: 9.0078\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.0925 - val_loss: 8.9036\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1149 - val_loss: 8.8832\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.1221 - val_loss: 8.9609\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0639 - val_loss: 9.1321\n",
            "1/1 [==============================] - 1s 897ms/step - loss: 0.0748 - val_loss: 9.2142\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.0894 - val_loss: 9.1548\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1352 - val_loss: 9.0044\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1002 - val_loss: 8.9554\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.1280 - val_loss: 8.9765\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1400 - val_loss: 9.0409\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2063 - val_loss: 9.2272\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.1406 - val_loss: 9.3614\n",
            "1/1 [==============================] - 1s 824ms/step - loss: 0.1807 - val_loss: 9.2169\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 0.1226 - val_loss: 9.0233\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.1303 - val_loss: 8.9787\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.1858 - val_loss: 9.0389\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0970 - val_loss: 9.1974\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0432 - val_loss: 9.3697\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1802 - val_loss: 9.1896\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0934 - val_loss: 9.0599\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1071 - val_loss: 9.0351\n",
            "1/1 [==============================] - 1s 904ms/step - loss: 0.1108 - val_loss: 9.0410\n",
            "1/1 [==============================] - 1s 862ms/step - loss: 0.1228 - val_loss: 9.0729\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.1991 - val_loss: 9.2279\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2368 - val_loss: 9.2482\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1775 - val_loss: 9.0187\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.1935 - val_loss: 8.8980\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2433 - val_loss: 9.0095\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1491 - val_loss: 8.9722\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.1648 - val_loss: 8.9415\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0993 - val_loss: 8.9716\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 0.1424 - val_loss: 9.0304\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.5124 - val_loss: 9.1183\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1402 - val_loss: 9.0952\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1010 - val_loss: 9.0531\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.1604 - val_loss: 9.0352\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1900 - val_loss: 9.0478\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.3186 - val_loss: 9.1964\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2389 - val_loss: 9.3188\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 0.1885 - val_loss: 9.2503\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3145 - val_loss: 9.0584\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2104 - val_loss: 8.9567\n",
            "1/1 [==============================] - 1s 837ms/step - loss: 0.2712 - val_loss: 8.9986\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2994 - val_loss: 9.1420\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2475 - val_loss: 9.6382\n",
            "1/1 [==============================] - 1s 838ms/step - loss: 0.3064 - val_loss: 9.3844\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.2000 - val_loss: 9.0321\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1370 - val_loss: 8.8659\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2009 - val_loss: 8.7997\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.1857 - val_loss: 8.7672\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.3797 - val_loss: 9.0325\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 0.3363 - val_loss: 9.3126\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.4721 - val_loss: 9.0182\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1848 - val_loss: 8.8216\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1663 - val_loss: 8.7157\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.4997 - val_loss: 8.7936\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.2942 - val_loss: 8.9842\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.3108 - val_loss: 9.3473\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.2297 - val_loss: 9.4126\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2904 - val_loss: 9.1904\n",
            "1/1 [==============================] - 1s 858ms/step - loss: 0.0894 - val_loss: 9.1447\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2251 - val_loss: 9.1703\n",
            "1/1 [==============================] - 1s 843ms/step - loss: 0.1361 - val_loss: 9.2100\n",
            "1/1 [==============================] - 1s 803ms/step - loss: 0.2129 - val_loss: 9.1975\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.2080 - val_loss: 9.1389\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.1775 - val_loss: 9.1165\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.3412 - val_loss: 9.2312\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.4019 - val_loss: 9.0643\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2620 - val_loss: 8.8283\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.3180 - val_loss: 8.7673\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.2095 - val_loss: 8.8336\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 0.2234 - val_loss: 8.9743\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.2267 - val_loss: 9.0639\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3066 - val_loss: 8.8963\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1854 - val_loss: 8.8296\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.2803 - val_loss: 8.8672\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2405 - val_loss: 8.9762\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2145 - val_loss: 9.2328\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.1670 - val_loss: 9.5421\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1913 - val_loss: 9.4103\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.2046 - val_loss: 9.1584\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2637 - val_loss: 9.0606\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4968 - val_loss: 9.0570\n",
            "1/1 [==============================] - 1s 844ms/step - loss: 0.3132 - val_loss: 9.1595\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3447 - val_loss: 9.6083\n",
            "1/1 [==============================] - 1s 845ms/step - loss: 0.3121 - val_loss: 9.7814\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5470 - val_loss: 9.1005\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0849 - val_loss: 8.9881\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4143 - val_loss: 8.9854\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5464 - val_loss: 8.9033\n",
            "1/1 [==============================] - 1s 857ms/step - loss: 0.1389 - val_loss: 9.2508\n",
            "1/1 [==============================] - 1s 823ms/step - loss: 0.1827 - val_loss: 9.6851\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.6542 - val_loss: 9.0048\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2718 - val_loss: 8.8027\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4464 - val_loss: 8.8516\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4237 - val_loss: 8.8209\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2765 - val_loss: 9.0916\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.2026 - val_loss: 9.5503\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7071 - val_loss: 9.0913\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3243 - val_loss: 8.8594\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 0.2679 - val_loss: 8.9141\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3459 - val_loss: 8.9725\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1640 - val_loss: 9.1473\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0810 - val_loss: 9.4813\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.2066 - val_loss: 9.6139\n",
            "1/1 [==============================] - 1s 820ms/step - loss: 0.4035 - val_loss: 9.2917\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1931 - val_loss: 9.1904\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.2856 - val_loss: 9.1837\n",
            "1/1 [==============================] - 1s 864ms/step - loss: 0.2376 - val_loss: 9.2305\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5639 - val_loss: 9.4221\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.1727 - val_loss: 9.6232\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3593 - val_loss: 9.2332\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2428 - val_loss: 9.0013\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.1907 - val_loss: 8.9507\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4774 - val_loss: 9.0446\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1528 - val_loss: 9.2251\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.1834 - val_loss: 9.3323\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1328 - val_loss: 9.3365\n",
            "1/1 [==============================] - 1s 889ms/step - loss: 0.2165 - val_loss: 9.2592\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.1795 - val_loss: 9.2031\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.2144 - val_loss: 9.2281\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.3972 - val_loss: 9.3423\n",
            "1/1 [==============================] - 1s 819ms/step - loss: 0.2234 - val_loss: 9.3454\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.2918 - val_loss: 9.2446\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1116 - val_loss: 9.1091\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2036 - val_loss: 9.0335\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1827 - val_loss: 8.9912\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.4431 - val_loss: 9.0131\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2773 - val_loss: 9.1537\n",
            "1/1 [==============================] - 1s 848ms/step - loss: 0.2676 - val_loss: 9.1105\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2183 - val_loss: 8.9194\n",
            "1/1 [==============================] - 1s 846ms/step - loss: 0.2508 - val_loss: 8.7907\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.2363 - val_loss: 8.8144\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.2445 - val_loss: 8.8839\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.1482 - val_loss: 9.0185\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.2358 - val_loss: 9.2714\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 0.2663 - val_loss: 9.4678\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 0.4538 - val_loss: 9.2078\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.2827 - val_loss: 9.0164\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1203 - val_loss: 8.9820\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.3029 - val_loss: 8.9593\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2898 - val_loss: 9.0957\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2143 - val_loss: 9.3412\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2253 - val_loss: 9.5535\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3445 - val_loss: 9.1964\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.2237 - val_loss: 9.0097\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.4784 - val_loss: 9.0037\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5335 - val_loss: 8.9706\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2211 - val_loss: 9.0886\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1663 - val_loss: 9.5160\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4011 - val_loss: 9.5211\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4469 - val_loss: 9.1025\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.1505 - val_loss: 8.8731\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3237 - val_loss: 8.8072\n",
            "1/1 [==============================] - 1s 815ms/step - loss: 0.2316 - val_loss: 8.7849\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 0.2939 - val_loss: 8.9399\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3968 - val_loss: 9.2799\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3149 - val_loss: 9.3105\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3953 - val_loss: 8.9231\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1505 - val_loss: 8.8142\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.3015 - val_loss: 8.8702\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2233 - val_loss: 8.9917\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 0.2430 - val_loss: 9.1994\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3746 - val_loss: 9.2611\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.3344 - val_loss: 9.1957\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2598 - val_loss: 9.1811\n",
            "1/1 [==============================] - 1s 863ms/step - loss: 0.3264 - val_loss: 9.1439\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2793 - val_loss: 8.9875\n",
            "1/1 [==============================] - 1s 855ms/step - loss: 0.1401 - val_loss: 8.8949\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2633 - val_loss: 8.9029\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2497 - val_loss: 8.9680\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2638 - val_loss: 8.9123\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1999 - val_loss: 8.8736\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2235 - val_loss: 8.9632\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.1056 - val_loss: 9.0912\n",
            "1/1 [==============================] - 1s 826ms/step - loss: 0.1283 - val_loss: 9.1531\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2799 - val_loss: 9.1377\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1964 - val_loss: 9.0749\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1873 - val_loss: 9.1068\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2539 - val_loss: 9.0233\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2065 - val_loss: 8.9338\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2120 - val_loss: 8.8655\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1067 - val_loss: 8.8476\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2192 - val_loss: 8.7820\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1573 - val_loss: 8.8363\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2678 - val_loss: 8.9257\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1613 - val_loss: 8.9626\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2172 - val_loss: 8.9864\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3138 - val_loss: 8.9910\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.3723 - val_loss: 9.0402\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.1634 - val_loss: 9.1689\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2216 - val_loss: 9.2047\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1592 - val_loss: 9.1611\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1328 - val_loss: 9.1346\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1825 - val_loss: 9.0882\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.1393 - val_loss: 9.0663\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.1736 - val_loss: 9.1387\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 0.1256 - val_loss: 9.1262\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2139 - val_loss: 9.0498\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1436 - val_loss: 9.0118\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1351 - val_loss: 9.0266\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1564 - val_loss: 9.0837\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.1203 - val_loss: 9.2107\n",
            "1/1 [==============================] - 1s 830ms/step - loss: 0.1473 - val_loss: 9.2443\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.2231 - val_loss: 9.1026\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1392 - val_loss: 8.9590\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1155 - val_loss: 8.9010\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 0.2653 - val_loss: 8.9346\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 0.1171 - val_loss: 9.0651\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 0.1196 - val_loss: 9.2930\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 0.2610 - val_loss: 9.1428\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2034 - val_loss: 8.9523\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1650 - val_loss: 8.9328\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1814 - val_loss: 8.9495\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1616 - val_loss: 9.0053\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1378 - val_loss: 9.0807\n",
            "1/1 [==============================] - 1s 980ms/step - loss: 0.1008 - val_loss: 9.0823\n",
            "1/1 [==============================] - 1s 832ms/step - loss: 0.0923 - val_loss: 9.1033\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2121 - val_loss: 8.9264\n",
            "1/1 [==============================] - 1s 872ms/step - loss: 0.1272 - val_loss: 8.8192\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2260 - val_loss: 8.8442\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2227 - val_loss: 8.9356\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3Scdb3v8fd3cmmaZtqmbTppm7ZpaRN6hdaAuHugYt2KV0RFYKFcjtojhyO6cblFXXuja8naKBxkoxw9qGDdIsKqsNEtim52N5V9EGlr76Wl9ALpJU1amjakt2S+5495Mp2muTczz2Tm81prVp77fPOknc88t9/P3B0RERGASNgFiIhI9lAoiIhIkkJBRESSFAoiIpKkUBARkSSFgoiIJKUtFMzsYTM7YGYbu5j3JTNzMxsXjJuZPWBm281svZktTFddIiLSvXQeKfwUuKLzRDObDLwHeD1l8vuAmcFrKfCDNNYlIiLdSFsouPtK4FAXs74L/D2Q+tTclcDPPOHPwGgzm5Cu2kREpGuFmXwzM7sS2OPu68wsddYk4I2U8fpg2r6etjdu3Divrq4e7DJFRHLa6tWrm9y9oqt5GQsFMysFvkbi1NG5bGcpiVNMTJkyhVWrVg1CdSIi+cPMdnc3L5N3H50HTAPWmdkuoApYY2aVwB5gcsqyVcG0s7j7Q+5e5+51FRVdBp2IiAxQxkLB3Te4+3h3r3b3ahKniBa6+37g18ANwV1IlwDN7t7jqSMRERl86bwl9THgRaDWzOrN7NM9LP4MsAPYDvwI+J/pqktERLqXtmsK7n5dL/OrU4YduDVdtYjI4Dl16hT19fUcP3487FKkFyUlJVRVVVFUVNTndTJ695GIDH319fVEo1Gqq6vpdBehZBF35+DBg9TX1zNt2rQ+r6dmLkSkX44fP87YsWMVCFnOzBg7dmy/j+gUCiLSbwqEoWEgf6e8DIWt+49y9+9e4ejxU2GXIiKSVfIyFN441MoPn3+NbQ0tYZciIgNQVlYWdgk5Ky9DobYyCsC2hqMhVyIikl3yMhQmtWzkh8MeYHd9lw9Ni8gQ4e58+ctfZu7cucybN4/HH38cgH379nHZZZdx4YUXMnfuXP70pz/R3t7OTTfdlFz2u9/9bsjVZ6e8vCU1cvIoV9ifeXnveuAdYZcjMmR98zeb2Lz3yKBuc/bEkdz5oTl9WvbJJ59k7dq1rFu3jqamJi666CIuu+wyfvGLX/De976Xr3/967S3t9Pa2sratWvZs2cPGzcmung5fPjwoNadK/LySIHKeQCUHtocciEici5eeOEFrrvuOgoKCojFYixevJiXX36Ziy66iEceeYRvfOMbbNiwgWg0yvTp09mxYwef//zn+f3vf8/IkSPDLj8r5eWRAmXjaS0ex9RjO2hqOcG4smFhVyQyJPX1G32mXXbZZaxcuZLf/va33HTTTdx+++3ccMMNrFu3jmeffZYf/vCHPPHEEzz88MNhl5p18vNIATg+djazbbcuNosMYZdeeimPP/447e3tNDY2snLlSi6++GJ2795NLBbjs5/9LJ/5zGdYs2YNTU1NxONxPvaxj/Gtb32LNWvWhF1+VsrPIwVgWNUFzNj7X/xy7yH+5rxxYZcjIgNw1VVX8eKLL3LBBRdgZnznO9+hsrKSZcuWcc8991BUVERZWRk/+9nP2LNnDzfffDPxeByAf/qnfwq5+uyUt6FQOmUB9nI7h1/fCNSEXY6I9ENLS+IZIzPjnnvu4Z577jlj/o033siNN9541no6Ouhd3p4+sgnzAYg0bAi5EhGR7JG3ocCY6ZyMlDCq+RUSLXeLiEj+hkKkgOZoDTN9J/ua1S68iAjkcygA8dg8Ztlutu4f3IdvRESGqrwOhWj1AkZZK3t3bwu7FBGRrJDXoVA6ZQEAx+vXhVyJiEh2yOtQYPxs4kQoadoUdiUikkYdTW3v3buXj3/8410u8853vpNVq1b1uJ3777+f1tbW5Pj73//+QWlD6Rvf+Ab33nvvOW9nMOR3KBSXcqhkMuPfepX2uO5AEsl1EydOZPny5QNev3MoPPPMM4wePXowSssaaQsFM3vYzA6Y2caUafeY2Stmtt7MnjKz0Snzvmpm281sq5m9N111ddY6Zjbns4vXD7X2vrCIhO6OO+7gwQcfTI53fMtuaWlhyZIlLFy4kHnz5vH000+fte6uXbuYO3cuAMeOHePaa69l1qxZXHXVVRw7diy53C233EJdXR1z5szhzjvvBOCBBx5g7969XH755Vx++eUAVFdX09TUBMB9993H3LlzmTt3Lvfff3/y/WbNmsVnP/tZ5syZw3ve854z3qcra9eu5ZJLLmH+/PlcddVVvPnmm8n3nz17NvPnz+faa68F4Pnnn+fCCy/kwgsvZMGCBRw9eu7N9qTzieafAt8HfpYy7Y/AV929zcy+DXwV+IqZzQauBeYAE4F/N7Mad29PY30AFE68gIl7f8e/v76HaeP0ZLNIv/zuDtg/yA+AVs6D993d7exrrrmGL37xi9x6660APPHEEzz77LOUlJTw1FNPMXLkSJqamrjkkkv48Ic/3G0/xT/4wQ8oLS1ly5YtrF+/noULFybn3XXXXYwZM4b29naWLFnC+vXrue2227jvvvtYsWIF48ad2TTO6tWreeSRR3jppZdwd97+9rezePFiysvLefXVV3nsscf40Y9+xCc+8Ql+9atf8clPfrLb3++GG27ge9/7HosXL+Yf//Ef+eY3v8n999/P3Xffzc6dOxk2bFjylNW9997Lgw8+yKJFi2hpaaGkpKTPu7k7aTtScPeVwKFO0/7g7m3B6J+BqmD4SuCX7n7C3XcC24GL01VbqjEz3gZA8049/i4yFCxYsIADBw6wd+9e1q1bR3l5OZMnT8bd+drXvsb8+fN597vfzZ49e2hoaOh2OytXrkx+OM+fP5/58+cn5z3xxBMsXLiQBQsWsGnTJjZv7rmZ/RdeeIGrrrqKESNGUFZWxkc/+lH+9Kc/ATBt2jQuvPBCAN72trexa9eubrfT3NzM4cOHWbx4MZBormPlypXJGq+//np+/vOfU1iY+D6/aNEibr/9dh544AEOHz6cnH4uwmz76L8DjwfDk0iERIf6YNpZzGwpsBRgypQp51xESVXijxXfv57EwYqI9FkP3+jT6eqrr2b58uXs37+fa665BoBHH32UxsZGVq9eTVFREdXV1Rw/3v8HU3fu3Mm9997Lyy+/THl5OTfddNOAttNh2LDTTfMXFBT0evqoO7/97W9ZuXIlv/nNb7jrrrvYsGEDd9xxBx/4wAd45plnWLRoEc8++yznn3/+gGuFkC40m9nXgTbg0f6u6+4PuXudu9dVVFScezFl4zlcMIaRh185922JSEZcc801/PKXv2T58uVcffXVQOJb9vjx4ykqKmLFihXs3r27x2109NAGsHHjRtavXw/AkSNHGDFiBKNGjaKhoYHf/e53yXWi0WiX5+0vvfRS/vVf/5XW1lbeeustnnrqKS699NJ+/16jRo2ivLw8eZTxL//yLyxevJh4PM4bb7zB5Zdfzre//W2am5tpaWnhtddeY968eXzlK1/hoosu4pVXzv1zLONHCmZ2E/BBYImfbnRoDzA5ZbGqYFpGHIrWMvnQdk60tTOssCBTbysiAzRnzhyOHj3KpEmTmDBhAgDXX389H/rQh5g3bx51dXW9fmO+5ZZbuPnmm5k1axazZs3ibW9LnEq+4IILWLBgAeeffz6TJ09m0aJFyXWWLl3KFVdcwcSJE1mxYkVy+sKFC7npppu4+OLEWe/PfOYzLFiwoMdTRd1ZtmwZn/vc52htbWX69Ok88sgjtLe388lPfpLm5mbcndtuu43Ro0fzD//wD6xYsYJIJMKcOXN43/ve1+/368zS2RicmVUD/+buc4PxK4D7gMXu3piy3BzgFySuI0wEngNm9nahua6uznu7r7gvtj36Jaq3PcKOpds4f5L6VhDpyZYtW5g1a1bYZUgfdfX3MrPV7l7X1fLpvCX1MeBFoNbM6s3s0yTuRooCfzSztWb2QwB33wQ8AWwGfg/cmok7jzqMmLqAYmtn33Y92Swi+S1tp4/c/bouJv+kh+XvAu5KVz09qZh5Efw7HHt9LbAkjBJERLJCfj/RHCiumMExhlHUqOYuRPpCfZAMDQP5OykUACIF7C+ZztiWrWFXIpL1SkpKOHjwoIIhy7k7Bw8e7PcDbXnbR3NnLaNncd6+39N64hSlw4rCLkcka1VVVVFfX09jY2PvC0uoSkpKqKqq6n3BFAqFQGTCfEbtf5LNr21l9uy5YZcjkrWKioqYNm1a2GVImuj0UaD8vMQ9yod2rA65EhGR8CgUArEZC4m70b53fdiliIiERqEQKCgpY0/BJEa82XPDVyIiuUyhkKKprIaJx7aHXYaISGgUCilOjpvDRA7QfEh3VYhIflIopCiZnGhGe+/Wl0OuREQkHAqFFLGaiwBo2b025EpERMKhUEgRmziFJh9F5MDG3hcWEclBCoUUZsYbw2ZQfkQd7ohIflIodNI86nyq2nbjbSfCLkVEJOMUCp1Y5TyKaePQbp1CEpH8o1DoZOS0hQA0bVdzFyKSfxQKnUyZMY9jXszJet2BJCL5R6HQydiRpWy3qQw/pOYuRCT/KBS60FA6k1jrq6BOREQkzygUunB87Byi3kL88BthlyIiklFpCwUze9jMDpjZxpRpY8zsj2b2avCzPJhuZvaAmW03s/VmtjBddfVFcdUFABzUxWYRyTPpPFL4KXBFp2l3AM+5+0zguWAc4H3AzOC1FPhBGuvqVcV5ib4VjuxaE2YZIiIZl7ZQcPeVwKFOk68ElgXDy4CPpEz/mSf8GRhtZhPSVVtvZlSNZ6dXQsOGsEoQEQlFpq8pxNx9XzC8H4gFw5OA1BP49cG0UERLithZeB6jmtXchYjkl9AuNLu7A/2+vcfMlprZKjNb1diYvn4P3hxZy7hT++DY4bS9h4hItsl0KDR0nBYKfh4Ipu8BJqcsVxVMO4u7P+Tude5eV1FRkbZC47E5ALTt0ykkEckfmQ6FXwM3BsM3Ak+nTL8huAvpEqA55TRTKKJTEzdAHXpNdyCJSP4oTNeGzewx4J3AODOrB+4E7gaeMLNPA7uBTwSLPwO8H9gOtAI3p6uuvpoyZRqNPpLj9evCLkVEJGPSFgrufl03s5Z0sawDt6arloGYEYvyF59KbdOmsEsREckYPdHcjZKiAvaUzGTMWzug7WTY5YiIZIRCoQet5bMo4hQ0bQu7FBGRjFAo9KBwYqK5i5N7dF1BRPKDQqEHFdPmcMyLObJTzV2ISH5QKPSgpnI0W30y8f16VkFE8oNCoQfVY0t5xauJvrlFfSuISF5QKPSgsCBCU7SW4e1H4EiXD1iLiOQUhUIv2ioSzV2gU0gikgcUCr0onTyfuBvH69eGXYqISNopFHpx3qQYO72SY68rFEQk9ykUelETi7LFp1J4YGPvC4uIDHEKhV5MGj2cV62a6LF6ON4cdjkiImmlUOhFJGIcHT0rMdKgxvFEJLcpFPogMmF+YkB3IIlIjlMo9MGEqupE3wpv6GKziOQ2hUIf1FaOZEt8Km171TCeiOQ2hUIf1FSWsdmrGf7mNmg/FXY5IiJpo1Dog4qyYewumk6Bq28FEcltCoU+MDNOjFVzFyKS+xQKfRStOp9jXozvWx92KSIiaaNQ6KOZlaPZ6lWcUC9sIpLDQgkFM/s7M9tkZhvN7DEzKzGzaWb2kpltN7PHzaw4jNq6U1sZZXN8KgUNG9W3gojkrIyHgplNAm4D6tx9LlAAXAt8G/iuu88A3gQ+nenaelIzPspmr6bo5GH1rSAiOSus00eFwHAzKwRKgX3Au4DlwfxlwEdCqq1Lo0qLaBg+MzGii80ikqMyHgruvge4F3idRBg0A6uBw+7eFixWD0zKdG29sco5xDGFgojkrDBOH5UDVwLTgInACOCKfqy/1MxWmdmqxsbGNFXZtakTxrPbY7oDSURyVhinj94N7HT3Rnc/BTwJLAJGB6eTAKqALk/cu/tD7l7n7nUVFRWZqThQE4uyKT6Vtr0KBRHJTWGEwuvAJWZWamYGLAE2AyuAjwfL3Ag8HUJtPeq4A6noyG44fiTsckREBl0Y1xReInFBeQ2wIajhIeArwO1mth0YC/wk07X1Zsb4MrYwNTGivhVEJAcV9r7I4HP3O4E7O03eAVwcQjl9VlpcSPPIWXCMxMXmqe8IuyQRkUGlJ5r7aWzlFN60UbBf1xVEJPcoFPqptnIkG9unENdtqSKSgxQK/VRTmbgDiQNb1LeCiOQchUI/1cYSdyBF2k9A06thlyMiMqgUCv00bdwItlGdGNEpJBHJMQqFfioujMC4GZy0Yl1sFpGc06dQMLMRZhYJhmvM7MNmVpTe0rLXjMrRbLcpOlIQkZzT1yOFlUBJ0Oz1H4BPAT9NV1HZrjYWZe3Jyfj+DepbQURySl9Dwdy9Ffgo8H/c/WpgTvrKym41lYm+FezYITiyN+xyREQGTZ9DwczeAVwP/DaYVpCekrJfxx1IgE4hiUhO6WsofBH4KvCUu28ys+kkGrDLS5PHlLK7cCquvhVEJMf0qe0jd38eeB4guODc5O63pbOwbFYQMSaOH8/+5olM0B1IIpJD+nr30S/MbKSZjQA2ApvN7MvpLS271cSibGrXHUgiklv6evpotrsfIdFv8u9I9Jr2qbRVNQTUVpax5uRkeHOn+lYQkZzR11AoCp5L+Ajw66DHtLy+F7MmFmWLq28FEcktfQ2F/wvsItGf8kozmwrk9dfjjl7YAJ1CEpGc0adQcPcH3H2Su7/fE3YDl6e5tqxWObKE1pIK3ioYreYuRCRn9PVC8ygzu8/MVgWv/03iqCFvmRm1sZG8VjBNRwoikjP6evroYeAo8IngdQR4JF1FDRU1lVHWnKzC1beCiOSIvobCee5+p7vvCF7fBKans7ChoDYW5a8nJ2PqW0FEckRfQ+GYmf23jhEzW0Si+/q8VhNLtIEE6BSSiOSEvobC54AHzWyXme0Cvg/8j4G+qZmNNrPlZvaKmW0xs3eY2Rgz+6OZvRr8LB/o9jOlJlbGDp9AW0R9K4hIbujr3Ufr3P0CYD4w390XAO86h/f9Z+D37n4+cAGwBbgDeM7dZwLPBeNZbWzZMMrLStlXPB0aNoZdjojIOetXz2vufiR4shng9oG8oZmNAi4DfhJs86S7HwauBJYFiy0j8aBc1qutLEs8xKa+FUQkB5xLd5w2wPWmAY3AI2b2VzP7cdCmUszd9wXL7AdiXb6p2dKOW2MbGxsHWMLgqYlFeenYJGg9CEf39b6CiEgWO5dQGOjX4kJgIfCD4DTUW3Q6VeTu3t323f0hd69z97qKiooBljB4amNR1p6anBjRxWYRGeJ6DAUzO2pmR7p4HQUmDvA964F6d38pGF9OIiQazGxC8L4TgAMD3H5G1VRGecWnJEZ0sVlEhrgeQ8Hdo+4+sotX1N371BdDF9vcD7xhZrXBpCXAZuDXwI3BtBuBpwey/UybOb6MtxjO4ZLJOlIQkSFvQB/sg+DzwKNmVgzsAG4mEVBPmNmngd0knpzOetGSIiaNHs7OwuksUCiIyBAXSii4+1qgrotZSzJdy2CorYyybt9kFrQ8DyeOwrBo2CWJiAzIuVxolkBNLMoLLRMSI+pbQUSGMIXCIKitLGNDu/pWEJGhT6EwCGpiURoo50Rxue5AEpEhTaEwCM6rKKMgEmH/8Jk6UhCRIU2hMAhKigqoHlvKK1RDw2Zobwu7JBGRAVEoDJLayigvH58E7SfgoPpWEJGhSaEwSGpiUVYeDe5A0ikkERmiFAqDpDYW5bX4BOIFw3SxWUSGLIXCIKmpjNJOAYfLZuhIQUSGLIXCIJk6ppTiwgivF09X3woiMmQpFAZJYUGEGRVlbGibor4VRGTIUigMotrKKC+0BC2K6xSSiAxBCoVBVBOL8l9Hgw7jdLFZRIYghcIgqq0so4VSjken6khBRIYkhcIgqoklmsw+UKrmLkRkaFIoDKJJo4czoriAVyPT4NCORN8KIiJDiEJhEJkZNZVRVp+oSkxo2BxuQSIi/aRQGGS1sSjPvamLzSIyNCkUBllNLMrWY1HiJWN0XUFEhhyFwiCrrYwCxpHR5ysURGTICS0UzKzAzP5qZv8WjE8zs5fMbLuZPW5mxWHVdi467kB6o3gGHFDfCiIytIR5pPAFYEvK+LeB77r7DOBN4NOhVHWOxpUVM2ZEMZviU6DtOBzcHnZJIiJ9FkoomFkV8AHgx8G4Ae8ClgeLLAM+EkZt58rMqImV8WKrmrsQkaEnrCOF+4G/B+LB+FjgsLt3nGupByaFUdhgqI1F+c+mUbj6VhCRISbjoWBmHwQOuPvqAa6/1MxWmdmqxsbGQa5ucNRURmk+aZwaW6sjBREZUsI4UlgEfNjMdgG/JHHa6J+B0WZWGCxTBezpamV3f8jd69y9rqKiIhP19lttcLG5qaxGfSuIyJCS8VBw96+6e5W7VwPXAv/h7tcDK4CPB4vdCDyd6doGy8wgFF6LTIfWJji6P+SKRET6JpueU/gKcLuZbSdxjeEnIdczYKOGFzFhVAl/PTU5MUGnkERkiAg1FNz9P939g8HwDne/2N1nuPvV7n4izNrOVU0syvPNau5CRIaWbDpSyCm1lVE2NMXx8mk6UhCRIUOhkCY1sSgn2+K8NWaWQkFEhgyFQpp03IG0d9hM9a0gIkOGQiFNZowvwwy2+BTA1beCiAwJCoU0GV5cwNQxpfzlWPBgti42i8gQUNj7IjJQNbEofz4ADC/XdQURGRJ0pJBGtZVRdh06RntsnkJBRIYEhUIa1cSitMedw9Fa9a0gIkOCQiGNEr2wwa6i89S3gogMCQqFNKoeO4KiAmNtm5q7EJGhQaGQRsWFEaaPK+Ol5rFQUKw7kEQk6ykU0qymMsrmA8dg/Cxo2Bh2OSIiPVIopFltrIz6N49xqmIu7FuvvhVEJKspFNKsJmjuYn/pzETfCi0NIVckItI9hUKaddyBtM2qExN0sVlEsphCIc0ml5dSUhRhlZq7EJEhQKGQZpGIUROLsqHJobxaRwoiktUUChlQE4uyteEoVKq5CxHJbgqFDKiNRWk8eoLWMXPg4GtwoiXskkREuqRQyICa4GLz68XnAZ5oB0lEJAspFDKgoxe2je1TEhN0sVlEslTGQ8HMJpvZCjPbbGabzOwLwfQxZvZHM3s1+Fme6drSJTZyGCNLCvnr4VL1rSAiWS2MI4U24EvuPhu4BLjVzGYDdwDPuftM4LlgPCeYGbWVUbYdaNHFZhHJahkPBXff5+5rguGjwBZgEnAlsCxYbBnwkUzXlk41sShb9x/FY/OgYZP6VhCRrBTqNQUzqwYWAC8BMXffF8zaD8S6WWepma0ys1WNjY0ZqXMw1FZGOXK8jeZRsxJ9Kxx6LeySRETOEloomFkZ8Cvgi+5+JHWeuzvQZctx7v6Qu9e5e11FRUUGKh0cHW0gbS+YlpigU0gikoVCCQUzKyIRCI+6+5PB5AYzmxDMnwAcCKO2dOkIhbWtFepbQUSyVhh3HxnwE2CLu9+XMuvXwI3B8I3A05muLZ3GjCimIjqMVxqPQ8X5OlIQkawUxpHCIuBTwLvMbG3wej9wN/C3ZvYq8O5gPKfUxqJsazgKlfPVt4KIZKXCTL+hu78AWDezl2SylkyriUX5xV92E3/bXCJrf57oWyFaGXZZIiJJeqI5g2oryzh+Ks6BETWJCTqFJCJZRqGQQR0XmzfH1dyFiGQnhUIGzewIhUPA6Kk6UhCRrKNQyKCyYYVUlQ9na4OauxCR7KRQyLDaWJRt+4M7kA6+BiffCrskEZEkhUKG1VRGea2xhVPj5wAODepbQUSyh0Ihw2pjUdrizutFMxITdLFZRLKIQiHDOu5A2vRWFEpG67qCiGSVjD+8lu/OGz+CgoixreNi8941cGgHtJ8KXich3tZp+OTp+fHOywXzulzuZKKJ7tTh9pMp20jZnseDCg3MUobpND2Y0NXwGev1NJy6Hp22EYFIIUQKEj8tkjIc/IxEOo0XdLFeQTBccOZyncdTl0tdzyJdvKyX8cjp36GnZfo6rWN/pQ4np3X3/KfIuVEoZNiwwgKmjRvB1oajMOECePH78MCCwdm4FSQa2ysoSrwiRZ2Gi6GgMPEzUgTFpaeHI5Ezm91Ibai2Yzg5v6th73695DBnrhePn70Nj0O8PRFyHk/8TI63J9ZJDrd1Gg+mdd3Abg6y04HSbYB0nt/XZSNBdqeGVTdhdlYQdrV8ynCXy1s32++8vHUK7ZThSKTr6T3NS27Lulinuy8HwQmWM74MdfOlKbkPu/vi1J95lpwNlmgNYeTEQf9XpVAIQW0sysa9zfCx22H87NPfUrv8QC8+c16XyxWf/gYtiaBIDYnkcHtKmKQGT/vZQePdvDqCy737Zbwvy3Rsq5dlUgP5jOF418Op9UE/lu3pPeJdjHf+/br5PSDYx93to07DdLc/SPx9UqfF21PWb+9ierC9XLXoi/C33xz0zSoUQlATi/LMxn20Fo2idMH1YZeTeyIRIJIITclvncMqNTC8/fT8eKfA8ZTA6WodvIufyTftfpmOmvo8L3V7nbY9ZnpadplCIQS1lWW4w/YDLcyvGh12OSK5q+O0EAVhVzJk6HxDCDruQNq6/2jIlYiInEmhEIKpY0dQXBhJ9K0gIpJFFAohKIgYM8eXJdpAEhHJIgqFkCTbQBIRySIKhZDUVEbZf+Q4za2nwi5FRCRJoRCS2uBi87YDOloQkeyhUAhJTaXuQBKR7KNQCMnEUSWUDSvUHUgiklWyLhTM7Aoz22pm283sjrDrSRczoyZWpiMFEckqWfVEs5kVAA8CfwvUAy+b2a/dPSd7oqmtjPKr1Xu48vsvUFwYoaggcsbPYQVnTysusC6XLU75WZQcN4oLCigqtMT0ggjDOq1bVGCYWtwUkUBWhQJwMbDd3XcAmNkvgSuBnAyFT9RN5mDLSU60xTkZvFpOtCWG2+Ocak9MO9XuyWkn2+K9b7ifigsjFHQTDN5Dg2Le/ayem3KLp1oAAAY6SURBVCHrrY2yoHFJMzAs+Jk4urIz5ifmRYLpFsy0HtanY3owL2Jdb/fM3/N0wWeU3un3SB3tdh3O3G+d9+9ZDdWmbM+DaR3reNA0jne0j3PGtNNbTrRz56QsdsYyybbz8OT6pEzrYMEOMoJ93svfJXVe6t8m0oe/S3fb7nKf9vHvcPa81Ol9+zsMRH+/c/V1+evfPpXPLT6v/wX1IttCYRLwRsp4PfD21AXMbCmwFGDKlCmZqywNFkwp56Eb6vq1jrtzqt1TAiPOieDnyfY4p9qck+3tnGzzYPx0wHSET+q6ibBx2uPxbo8Yevw32sNM62Fmd//wkx96qR9uKR9+HR9cHfuiY3r8jA84Tzb4mfpB1+W2gXinD03Hz67duhw8a5+dOa/r6Z3XO2tXnLGeJbfTOehOv8fpD1E4+4M19f065p0e7vgwttNv3fk96Hr/xePe69+l8/7v+NvEu/i7dv67nBVw3nnfdL0/z57X7e7t199hIHr6UtXNCn02afTw/m27j7ItFHrl7g8BDwHU1dWdY4YPPWaWOC1UGGHEsLCrEZFck20XmvcAk1PGq4JpIiKSAdkWCi8DM81smpkVA9cCvw65JhGRvJFVp4/cvc3M/hfwLIkG0B92900hlyUikjeyKhQA3P0Z4Jmw6xARyUfZdvpIRERCpFAQEZEkhYKIiCQpFEREJMk6PwY+lJhZI7B7gKuPA5oGsZyhTvvjTNofp2lfnCkX9sdUd6/oasaQDoVzYWar3L1/bUzkMO2PM2l/nKZ9caZc3x86fSQiIkkKBRERScrnUHgo7AKyjPbHmbQ/TtO+OFNO74+8vaYgIiJny+cjBRER6SQvQyFf+oHuCzObbGYrzGyzmW0ysy+EXVPYzKzAzP5qZv8Wdi1hM7PRZrbczF4xsy1m9o6wawqLmf1d8H9ko5k9ZmYlYdeUDnkXCin9QL8PmA1cZ2azw60qVG3Al9x9NnAJcGue7w+ALwBbwi4iS/wz8Ht3Px+4gDzdL2Y2CbgNqHP3uSRacb423KrSI+9CgZR+oN39JNDRD3Recvd97r4mGD5K4j/9pHCrCo+ZVQEfAH4cdi1hM7NRwGXATwDc/aS7Hw63qlAVAsPNrBAoBfaGXE9a5GModNUPdN5+CKYys2pgAfBSuJWE6n7g74F42IVkgWlAI/BIcDrtx2Y2IuyiwuDue4B7gdeBfUCzu/8h3KrSIx9DQbpgZmXAr4AvuvuRsOsJg5l9EDjg7qvDriVLFAILgR+4+wLgLSAvr8GZWTmJMwrTgInACDP7ZLhVpUc+hoL6ge7EzIpIBMKj7v5k2PWEaBHwYTPbReK04rvM7OfhlhSqeqDe3TuOHJeTCIl89G5gp7s3uvsp4Engb0KuKS3yMRTUD3QKMzMS54y3uPt9YdcTJnf/qrtXuXs1iX8X/+HuOfltsC/cfT/whpnVBpOWAJtDLClMrwOXmFlp8H9mCTl60T3ruuNMN/UDfZZFwKeADWa2Npj2taBbVJHPA48GX6B2ADeHXE8o3P0lM1sOrCFxx95fydEnm/VEs4iIJOXj6SMREemGQkFERJIUCiIikqRQEBGRJIWCiIgkKRREemBm7Wa2NuU1aE/0mlm1mW0crO2JDIa8e05BpJ+OufuFYRchkik6UhAZADPbZWbfMbMNZvYXM5sRTK82s/8ws/Vm9pyZTQmmx8zsKTNbF7w6mkgoMLMfBe30/8HMhof2S4mgUBDpzfBOp4+uSZnX7O7zgO+TaF0V4HvAMnefDzwKPBBMfwB43t0vINF+UMdT9DOBB919DnAY+Fiafx+RHumJZpEemFmLu5d1MX0X8C533xE0KLjf3ceaWRMwwd1PBdP3ufs4M2sEqtz9RMo2qoE/uvvMYPwrQJG7fyv9v5lI13SkIDJw3s1wf5xIGW5H1/kkZAoFkYG7JuXni8Hw/+N0N43XA38Khp8DboFkH9CjMlWkSH/oW4lIz4antB4Lif6KO25LLTez9SS+7V8XTPs8iZ7Kvkyi17KOVkW/ADxkZp8mcURwC4kevESyiq4piAxAcE2hzt2bwq5FZDDp9JGIiCTpSEFERJJ0pCAiIkkKBRERSVIoiIhIkkJBRESSFAoiIpKkUBARkaT/D26vqDomeTgSAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cover Image\")\n",
        "plt.imshow(X_test[10])\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.show()\n",
        "print(\"Predicted Rating: \",model.predict(X_test)[10].item())"
      ],
      "metadata": {
        "id": "7UbL9QX1xMvH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "f38c9103-dd7f-494a-ce56-1ddcd99ff646"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cover Image\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOsAAADrCAYAAACICmHVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO19eZxdVZXuPtO9t+reqlQqlZGEIQGCjCGCdBAZEkWkRWltkHZqfa1N0wpiK0p3Q+OEjYiKOLbgBCKiD/Q5ADYqo0hQCCRAmEMghEyVSk13OOP7o6rO+ta6dY65vF//mtNvff9kVfa+++yzz9n3rrXXt9aykiQxCoXi5Q/7v3sCCoVi96CbVaEoCHSzKhQFgW5WhaIg0M2qUBQEulkVioLA7aTzrL6eZNGC2RN/JBFrsy10AVkvaTIJfE46lCz4n7zR/99n0X5tPo/d/ZyV2ZLXljV+voONfwr72n/mk1lIXtLqvVQ34Et9Ull4qU8w75nt7pjwnjpyeznUZonfyUkX6sYXtpgdO4ennWRHm3XRgtnmN9d+euJi4Thr63aDVA4Th7W5Jk7lGKaRxLxfCD/0seFwcREsanXEGoYwviN9yNCG3y3yxeRfQ7zNhmuzQYwxcQIPgK0Bv5sY7tMSbVmqTturAteOxXrHCc3Zg/Etm98ZjumKCzTh1cA5ybcogv9xxMph7wiubSX8Lm22buJZWJ1/ATh2yP8jhvEtsVYgW3YJLuyLUWnMttfKLtN4Me2D8ox+MUZPKpW8Lj6PeGJ9Vrz5H0wWOtqsSRKbKGgaY4zxHL7gfkB34CX8BdxVpolVfeo3Kp58FXZexbT4tXGTWzTecMhvwfXHUrmnm4/faNKC++5s+n/xzdBj0bXLVjNzHlEoNwnNJbTo5bSdCutXShr0h+2xtqhMfWd00RyNxRcrtmn96zs38zH8eir7Nq1VFPCX2IVn6Jsya7NhjpZLaxCL7erB2oXidapHdG+9CVzb4pt6HD4Xia8rN6bP2Ta28R2TxDSRwO1lbVZIzzMUm9B16dpJRP1ahr88NYvWwxVfBoGhDRrBOjaH6qxfEu9M5YG5M1nb2K6hic9H/H1DqM2qUBQEulkVioJAN6tCURB0ZLMaQzZLyQrY/0dgMMdi2NM/eHkq3/LND6fyrfdsYP1W//7eVL7sw6extoZPNknDIbtg1d+cx8f44SdSOQi4PRiD7fXxz381lZ94bpD1+83XzoEPsSbjx3RvrsNtlyv+992pfP2v/pjKt3/3w6wfnmzb4lQ9GaWDu7A8ixpsbvfGYH8+PcoPK8782Ffo2j8k2ROHNREettjc/n7Lu/4ula//9hWpXHO4zZfAodKHLryUtd22en0q33X9Z1K51eS/EV433Wct3s7aBlt038efRut493WfZ/0cOHn99Ge/ztou/uf3pfKb3nsha+udsySVb/zCmTTHgK9VE/6slUqs7bCTPprK99z4hVTucbnNeu7nb0zly88/g7VNHaDmnVXrL6tCURDoZlUoCoIO1WDLGGtCtUyE+laukA9pdIwfP2/e/GIqbxshFfa663/F+l3zDVIhqmWuZpfAV+bFpIbEIddTKzMXkWz3sLaWTWPGMamOVsTVZeORWua6wkXlw7yEKWDAXzirt0bDlfk8qj10bB9EXPFxE7g3dE9Y/FFFHrknTn37O1nbut/fksplUNV94d+0QOmyhH/zhh98N5VtcMU1DXeLtEJ6Dxbsv5y1lR56mua0jdbg6AMW8nk4tP5WNIO1DdjVVI5j6te3x0GsnwNq/Jcv+yJrC8B/Wunhvs8I3iurfxmNHzdYvxq48+oJd3MNzCYX2/FvPTuV/3jrdazfVZeSyTa09QXWNmtgYOI+HPEuAvSXVaEoCHSzKhQFgW5WhaIg6IxuaLkmdPuMMcbUZnI6VgT81J4KdyWEAdk18+bukco/uZLbFoe+/m2p/PDtv2ZtyHG1gVoWx8K34pHN4yfc7ijZZAOWgOsZ85N44/WSDeJG/Ai/XCHbzhV+nRDcOgnYeV5lPusXhHRtSeiOgFaI7ohEfK8GAdlQscfn6IRI7aM1sGNBKXTpWhddwt0dN9xyWyr/6Xc/S+VusVaHHnNSKv/kx99nbaeefHIqn/LX9Gz/+NsbWb8ZsMZ1l9usCbiXHANuoyT7dya0+CTRY+W3+DNbvHBeKuNmuGvtE6zf8cvJHu/2uH1/9y/ovjc8P5zKK972Idbv7HeTu+b9bz2GtUWTVMpEcJcR+suqUBQEulkVioKgIzXYsl3jdU+oiInLj5hRu4gdrobU+vtS2SuRipyE4ni8Rsf7lldlbXaLmC0xqJvGFtEX+EfMbw/TrqIy5AY8wsdE1JqI8LONz29K5SV7LmBtqJGHPkSLJHz8GNwwm7Zw9tTee8yhMWJUZ/k8uoGN9ZrDD2VtB618Yyo/evdN1BDx9XYh+qV/FncvlUo0Rw+iXTaPcQbTH+66PZVnutyVFYe03nsuIJfauRdw9tFV//5JmBNrMk1wbSXwunplweiCyBqZXtcC0yKUUXwQuoev9Mrly1g3DPEbEYExjkPv6kF707Xu+eXVrN9hx/xVKr/vjFPEPCbnrGqwQlF86GZVKAoCq5OM/MsPPSj5/U0/MsYYk8SCFA4B1k8/u5W1lfuIETS8hcj7M3v5ifK8BXQy1yUYJLZD6sW6p4j90TOLn7QOb92Yyofsx9vGx0lVeuhJmkf/3L1Yvy3PEfNGntYedeRhqewP72Bt9657KpXnzN0zlbcPvmg4aMwTjj+WtVjNEeiVbaU4LqllTsTVzyEIenj4MVqPiz7zWdbPb1DQwNJDX8naLrnw31L57t/Syfxjz/NA91cvJxX82KOPYG1NCPTesYuSAnzruv/D+o0NkinwqYv+mc/jUmK1LT2YTmQ3PL6e9fv4h4iE70Q8wGLrDhr/oxdfxtq276Q2f5ROcq0SN8Nuvv571CZU9RNOOTWVE/B87L90f9bvii9+LpW7hfk2NeTRf/lOc//aR6fl8+svq0JREOhmVSgKAt2sCkVB0JHNuuzQg5Nbf/4TY4wxpe4B1lbpJuZJaHGbwYYUjBFErUShyELHMhPy8/GwQcmmXAh4rogAcO6eEZkJbfobv6X8xiifBziASiLQ2ILA91CwYTz0O8A8AsF0chzMhsfdOhHYqWgbWeI5JUDLsWTIMvxp452KRHYWRKrEMR+jCe4sD5KKyayTON9EtLqw3i7MX2a/ZMcfYo74zJAxZstbdqgtCvlahZjcsMmzcpY8uDewdWNxVuHC+In0/8CDYm4iEcCOAf6JIzKATrLVjjr53eb+tevVZlUoigzdrApFQdAZg8lY6c91SyTojhvkanFEILPlkEoVhaQGuy5XMZGUH8ScIWVViNnTApXNSoZYP0wllLS4+yeEQHUH1Ei7XGP9Eph/JHITtXxQpQXLKnTJfYWJtmPxlVipkcmQhJwRhKqThyqa4ep+y8dgBhFsAKq7W0a2l3jceG/CH1HNSK4tAycCeBaOoB85Fpod9LmSUHXxJ6PR5Nf9wY9+nMpfuuLLNLbHF7VvJgXFn/yaV7O2D/wtMYe6K9xd6IO6X0J2XcBNoxB1aWl2wJQduLeSw+8zgnciiYX5NpUvWK4NQH9ZFYqCQDerQlEQ6GZVKAqCzmxWyzJuacLt0Ha2DAV5EmH/+HCUHkGgcSLsMHYt+R9oF4A9FVh9mf2C0izWhBXVbPb/0v1D9nIsa6o4dJ+WWD6L+VpIrPXyJGMJUM0Sh99pdxVcN1jbRbhuvCjb5YY1YRJW0Ev2TDLkbDiOdIft3vgYjC8jmZ56nmib7z/rfNY2OkoUTr9JtM2xTdymHN1GdvrX169lbd+75spUPuSgw1nbNd+5JpWdKp1dOLZILNCiswVH3ick1RsfI1plJKK5HHgucoipYl2JqIuE0F9WhaIg0M2qUBQEHeZgsk1kTR59l7hq50Dtv64yd7twFShbbcIIl0QyWZyMoFyhvcXwuUAECWPaHnRBCPKOqYCa7Xp8iZAcYwn3BkYixXCfTeFaKUGAcRKLarC4KDnsMl7+MAcZAffGGGO3663TAufUFtgN7LQ4EqojlPhwy8TaskTJxAvPvySVR8Z4Pt2kSWaHDaU+A8PLbIR1YDeJOZagBOTq+x9gbZ+4jHJPfe7TpILXRUpo45HLJxAMKRv+dqvE7BOpmti8/EiUTZmavnSv4eczWxQKxcsKulkVioKg4ypyU3qnLdgqFpC9x4Ns1S4vboCrlXx8JE8jM0aqdqim2YLlwlQ4m+nErF8AKUB9ceqK9xLntOH8E6Eut0AttmzO4hqDtUNV2pJqb+46whyZWi064vhyDJTRjBGqswdHo1K1Q7Z9gGOI1+65FyigfeGp32VtiUO2TANMkn0fuY31KzV3pfLIlvtZ25o7iAVV6uLr+MyTj6TyeADzlb9juHbiOBi1YlwBmaABq7O3bbypVKTy/7FLTptCoXgZQTerQlEQ6GZVKAqCzlw3SWKiSb1b2mHM6hN2DQvCwUDd3Y97Z66KCCyDkvi+ccHF04iyIxhYkLAjSliwUovic8gIEhHQmbcj1yPnLwx6xmvJSCbpbuKAz2E+5zjbHRaJeVjJ9OypRCwIVmC3RM5b5soCe1YEo5i93/aJVB6RgeMPXJ/Kc+ZTwrSNa37M+kXdUIJjjNvOBxz52lTe/NwjrO2qq66ia8FbLBMXOHjcIdyKeJ/MtBXnDLh28uxGltycDvrLqlAUBLpZFYqCoMPgc2PsqfxKoopXHX7WKyJ/Daq7SCxvV1JRFRB6AqgJnkWf9IX2gC6CWOjZ2BWZTpIchUwc6TJJsFK5IKSjaoNjVCpC8QUtTTKYXKiAxuIChJsowhIfbnbJBc4YE9XTW3RtW3xvY24BzM9kCdPCBTdGLHQ7NEkiyDXlJ5wetGIpBfH/ej1fj9HuJTTevKWpXOvngf/VWQek8pDI51yt0Jyv/I+rWFsC6x2C66YmkyugU8YVTC14Thhg7iQiFxmqzwkn7NvhhItK5tpifTJbFArFywq6WRWKgkA3q0JREHRks258ccj8/SduMMYYc+BSHsQbxlSjJfJEArKM8WzZgLllRU7hEgT4vv5IKrU4JoxWB3IWlyxuGwUWRU4k4EqwSrxfxUCitUTaJ3RvtqDXeS4ExUOWtLIIbkc72BIG8+I9KWC+EZE9Jd0FJfiYJ90AIMfoXhL2N/4VinuJWD+69uDObazfHgN7p/LW7RtY25xZlORuHJ6FJQ4rVu5BgeS/e7yLtc2FmkHPrqbylUNPPsz6vaJEkV67tvKIHHsulZs02x9lbc9sJ9sxTGg7uCL4vAFuqWFBER0N6NqPbaR9sG3McOBzEgkBd02ef2wcFKFiAP1lVSgKAt2sCkVB0JEaHPrjZufm1cYYY+7cto61VbtIPQwTydyAI3xoq1Z4/qQE1JByhavSMbhJ1q+lMoYygiOC7x9bBofDtDAXlG3J+U4vG2OYDmdbsoz29Mhjw7T1hTVAUotke+0G4WWyH6rgIlIK5m+JZ4YVuAPIt2xsrr712WtSeVhEmQRgunRhLmaRG7huSPV1+7hLxtv7qFTe/3CIhqq8h/V75H7KpdQ/axFrK0NE2BW3DbO2R2v70efgabfas4ARhIrM2Ue8gnynCHO2pP6yKhQFgW5WhaIg6Cz43KI0mq2mKC/gU3Wuao2nAG3V66mcAH1n5wivou1YpGJFknQOdJ4eSBnZ1SVKcIR0LUfom6gyRyGylLhqx6uQCRI+pIpsZGdSZaUvXHGSG0AJEVGdw7gu5SoqeTSvZpOntcRTapmPKYKTXQ9y+vii4p5lkbroeLzUiD9Kpsas2cQieq6xgPVLDltB813HTaNxONG3QrrRecuXs34tKE3hWGXWFjo0r/V3/TCVm0//lPWzy6R+zt+LVxxHm+Hx2/+DNT30COVdeuNFVOG9OSYqBMJpcyTNPJaXy/yXQX9ZFYqCQDerQlEQ6GZVKAqCjmxW16ua2fMmyumFEbctMO44EuyM7h6ItAF3QcnjzCHbEPujPrKVtTXHKCFWDLbX1kF+FI+sqEhWPmcpeemPUltOYkicFYkEsmif2CL3K5b1gKgNW0a7JFSKwbP5OqK96cDNhMJXg1XGHWH4okump0asrVbAr9XfQ8/Jbz7J2jCJ3Iubnk3l3v6ZfB6PPpbKdsDLV1Zg7eoxVHuPuP3d8/QfUrk75Gchey6g35OxlSel8oEncrv0N396PJWdgFc3v/mmq2lO4p2owbnAvZ99VSrPGJjD+i0+9fJUbsxYzNqSmFxP+G4a4dpzsQyoPAuZsoNz3Hr6y6pQFAS6WRWKgsCS5RDyUOvpSQ5etswYY0yY8ArSGIRsd/E2PDoPWM4ergr0VOn4PWr7HqG+vTViudgif1IL3QUmO6DAgc+FbW4icPGIsuUOsGGqvQOsLQJVL8DA9JAzuj27P5XHG9x9VYPq6Y3x51O5FfIK7yGUlRiYzxk7YUKus8giuSrC/bdtuyWVu6tzedtWIuXPmU1t9RYfY2AhqY4761wNriZw3+Aec6JdrN+WJ+9I5TGb36c7Qn1rMyl45OmNa1i/0Z30OdfjarZrICBC5IkqQZV434f5u9z86QKWVXnOUtY27+iPp/LA0kNoToabHQbyWLsyuH2S/fWHL7zBDD//0LQOIP1lVSgKAt2sCkVBoJtVoSgIOrJZe/tmJUcd+wZjjDGRzRM+1Sq070fGeQDt/L2OTuVGi3R/S0Yh86llN4FtGFmcQhcn2cnDeLVzrILOj9gxJ28sjt8xsMSWni+goVnMjcP7eUg/tLnryQ+2UBPYdo6IDMIyPqMjnCrYCiCZGrh/XJc/62qZbP+dIslYBer9dNfoLGFkVERUQ8K3cpVHnMzoJ9uuAhO+/WeXsH69fWTPtkRETgRnED7Us2kF2cnwZBQVhiyhjWqMMX6L7FsMwA9CPoYNa+cJV5xVoffx6JO+SmOIvNKWQ1RY6c5L/Il53fXzfzG7djyjNqtCUWToZlUoCoLO8gbbnvG65xljjJnRdwhrC0E17enhavBYi1QPxrwR4ycyADoLNuTzkSwlUGkjoRJjyt8Qy1TIfLeQL8iOuNpXtunedu18jrXVxwdTeWyEZDvm62GX6W/RZCyoKN8D6ufMmfNYv8RghJKMyKE1cCEiJ27UWbdtoPqWu7gKi4FHW7aRal6tcDUy8IlxVPL4evujVGX8tpuvTeWe3tmsX+SQaWT7g6wNS1baDl3bS3JCnqQSCa7Dep0veBDAs8boJfkqYvC8uHYpoM533nxeKq885V9Zv2aDTEeHp5oy9WCi4nuSyJLr2VNSKBQvU+hmVSgKAt2sCkVB0GGmCMvEk5kSGuJoOwzJbsIsCcZAfRzDk0tFiejHQu5lMlyMMiFamGtze23z5mfoIy1O5cOj/wQogKPjPM8s1mgJm5xCh8zEvpk8MsOrzEjlrjLZV5U+bqMtWUR1WbZt53Pc9iLZwTHQ3wa386gYpEtGIlFZDN/BUQuzMLBupgSZNMouT143Pkr2bAXOGayQ270Gat/U65t4W4Ou7dvgshM239B2olVWHE7Rc5D6Ca6VNpcj2rYyMRw8z1bA3xd8nh70a0tpDf8jr133yQ7uL0PSteH7WL8IaKal7gNYW2/3BHXVsTVhmkJReOhmVSgKgs7U4CQwdvjihFjnLo2oSarA0BgvsTCOboyE1BBbMjxA1QjqPPoigoDisTFg7MRcpar1UpRJq8HZRz0zKXC6XCX2zuz+fVg/DAxOZvDvs4GZFGmzatUq1nbXXXem8uBOYiYFYztZvyceuyeVo4jPv+xlfX+KKA24Nem+wp6JjSaITPQF5SANj5TyIDduwsqacBXQYW8Qf51CGGMGmAWR1GCh1KIjTShwp1TK5PqQCeSCkEyGQBDjgojaZHI59PNgZXhb2gyoGItILxs+NzJGrpfBzY+zfoFNa2y/8ABra4xPJF5o1vneYdfJbFEoFC8r6GZVKAqCjoj8Xd2VZPHSvY0xxthCpXJLdIpnCfUW1UqrBAEAET9p9Ruk6toOz+NUq9FpZRnoH6HIyYunxpZQHV04aVy8J+XRedVRR7B+v7rl5lQeHuNEewyYj0M+f7x2AkHriSCW23mJdjIgnxOqbLLNg7xCIZzWemI9Qg+YPc1e1lbzuBmSOS+Q2xRHyDU1uImC2YeGuFmQwL1Uq7x8Bt5nE0yt9vWAPF/ilWj6pJo6Ln8WeMKMz9YSJQ4dOCmWSRNwjha+jyK31/y9KP9yXw/PZTU6+Z499dhTpjFeVyK/QlFk6GZVKAoC3awKRUHQkevGth1TmSzt2GYzYFC2y1ko3WDPeh5E4AjTLa4Sw8OS3yMQEV6GAOJlrziIdZszh1hFd993D2sbBRfSo8+sJXnDetbPZb4PUd4PbVZpe+LRP9jtMqonD1jTB22hwOfRGBFcG21UY4wJgKWTwDrWY1EJPiLGlWvJyB1wXwGDKRJjOJAITb4TyBZqQL0jaZC58E5Ie3BsnM4xwhAjqsQgkvEGSCCBgLRnWT90ZUW8owM+qlgwxiz4O8HzGTGl0UFiylUqPMqp0j3xLGxZ/Aigv6wKRUGgm1WhKAg6YzAZy9iTak9Xl8zJ60KvnDLd4PKpVbi6fOyrX53KBx7I1duvXPGVVI6hLMODD65m/XyfVC90JxljzEiDAqW7QHUsCX0FVfBY5NqtQ86eGT1clfHrwM4C1Su0ecA2Igo5y6oC5PoKzNEW5SvdCrmvRuucXI/PwoNA/UYsc0bRvXU73J0S2+RCcVwkuGdXe4+FGoz5k0Ioc+k4Mncvupo4owuDw5GsLy0LiLdvGx8fb9vnMrTnkng3UTuPQz7HBE0edP+IMRtjxPqr1USF9Mk8wm35owD6y6pQFAS6WRWKgkA3q0JREHRc6+awV05Q8zyP6/S9QAc86aQ3sLahYaKu/e6236RyKCJmkgSpgtxW9FsUaXPEsiNT+cKLLmL93nTqyakcCaMBXRws+iLkHe++9dZU/osTV7I2G47pHY/nTr7rZipzf+yJx9E8DLdZozCbpHf6X70plVetpDHOOvcjrF8FbKpQ2FAtqIPTWybbdiTg1Ml9TrwglTfdcjlrs2DK6E6IY26zRkC5jAWdESOlnn/i4VTu7uYRPjh/1+V29dAuShgQwishPCu5vzoWs3Wz33cXIn68Eh/RB9tZeJeYTYz5nW3RsauLnsU1P7qRtV177XXGGGNuvOEGs33bNqUbKhRFhm5WhaIg6Mh109XdbQ4+dCJf8Lp161jbEOTs+f7132ZtqA4whooMQgZ1S+bRsT3MS0wqdyIqgtsu5JZ1hPoJardjQd5dS+agpTFvuO7HrMUDNSpyRAkEjIRhJdL5jdouK8HOrwxNey3aM5Uv+Beeg3bDBspbdPXV32dtZVCRh0HFTLyFrN/ONb9N5TGPq7c1FlWVrTrG4LYoCdNo2/YXph0iFjQiZGdJtwuCq7DZ5VVkgHlWZI0EupdiUeoTry3HZ8wnlpuar9s+C/dK5X/51Of4GJNTbIigeoT+sioUBYFuVoWiIOhIDa7Xx82aNX8yxhiTCHUiALXJFZoMnvImjE0iifB44sbHL5cxuB0HF0PAmIkIbmenpiyljlBr4Dvsr972Dj4PUNP8mI//h1vpNBhvNDac/O7adC9xlK1SbdtMZSsuuviTrJ/tQ8UzsQgJtLmg+i9/+2Ws39o7SMXvd7gaXPfpc1i2Qqr0MVCHmsAQM8aY1iidPiMLqk2NhPnXG7wiHrKDkL2f9ysj3yv2Lkm2GrQ5TjZjjDOpxPVg/qg9S3V/6zZKO7uoNsDapgI/cmon6i+rQlEU6GZVKAoC3awKRUHQYd7gJI14kTYlRj3EFg+GRlhocEomSM6l0WY45jVUSb3Sza+FUSGRoLmwRG4W2pR8GSKwNRzh1mm1IKlbmbuG0EYpl4itErX4GA6WRhTV31etPD6VFy/dN5VXHnMM6/eed7wrld975t/zecAZAbpW7v3BOaxfydC8xoQLzEAZyQRKYLYlHQD2l+uI9QY7GF0y4xBQbgy3YSUbi7tFcqJu0G7PIeW1u3VwzpBjWfTbXZcSVk+XkxyDqBtjCSbY5LuT5Exef1kVioJAN6tCURB0lje42p0sOWh/Y8w0Ab6golQEwR0DrG0oPSB/8i3I6ZqIY+8Q1OAwh5GCZH1krkjg/DGPkDH5OXmxrIIkteepSggXXCFyjjG4J3A8mZuHuRLEV66d0P24XdS4NV7C+s2qP5jKvsXHt1mQOZLTxT2CORG2uNvlxQ1PpfKMGiUrGBrmAQX4PEU6apbvCNfKtrjpgu+BVHXxeUahiACA+ZfLkE9KvJuonkuXDFYd9IDVFoh358DDltEYMpf05JwfWv2AGRsZVSK/QlFk6GZVKAoC3awKRUHQWd5gyzJdk0nIGoIWViphST9+/G5BlAlGvrTZg5GT2YZ/IfXQ97MphbGwB0sVsKVh/ED0wwBoaTwEkJAtFsHzaCuhLOmMOEdp53oZ146EnWSVINol4WcEgUM1YXr2fVsqz9/vtazfhh+/kz4jgv0x9hqjpiJBsXTBdnRtuVq0xi8OUlSWI+w1fE6uiJRCNxQmp45kjSOALerUsHdJuhzRzYVyToLh9pzZ9Pce++5H84Bgc2OMSeDcIc9NmQX9ZVUoCgLdrApFQdCRGmxZlilNukYW7sWrhf/w299N5ZJQ+2x0yQBTpj7OVek3n/7WVB71eS5cVBdRRZGlI1D9LHXxYGjHp2ufe87ZdN2/PIX1e3bjxlTeZx9+n+g+uOtuXp7jgk9cSHOElQ0DrmYjk0qWFswyE2SpwjgkV8hvf/0L1vaWNxLDy97vpFT2Rp9k/bpA13VcrrKVLSwXQet93PHHsn4XfvSfU9kSES1YcgJzFDcb/NmuW0elTE477a9Z22hIOZhQQ05EtBKaCZFQ6dENYwuTp1qlfFAtyAktXYIsTZeMGgK1vtxF+ZZtUSEdx5RMLXs33H76y6pQFAS6WRWKgqAjBlO1Vk0OOPQAY4wxsWDUfPLjlCPojSe/kbWtOIHKYtigtp52yltZvw9/kFTTo094DWsLrOlZRXkMpqrHVbtf/4oqmi//i1dSgzAGUPHxTj8AABpgSURBVJ1zRJ6lEpTC+M7Xr2JtS/dbmspnfvAfUvnBxx8R42PAM19Hdm+Q2tMSJ6jXfOd7qbxk4SLWdvZHPpDKdz8L448Osn7d5rlUboiyFRWoLo9zlKfvq2+7I5UlX2zJkj1SuY4V5NtoSjT+5s3bWROu/4KFs+kjCZ+HH9D85ck5njZ3iZIqjN0E/WJxXMtUWDH+gYceRvMt0cm83FtZphyOv+6PDyqDSaEoOnSzKhQFgW5WhaIg6LDkI7lGpE4/b/7cVJalL2zMoAZfD3fcdSfrd845H0rlQFYcBxaUDVmpEuEucMGWvvWXN7G2Z58nG80t0a0nMiCZRVjwG20kFO3y7rPez9r+cMfvU/lrX/lqKq86+UTWDxOctSf3IhldDo6wcbphTe+7j5e9vPSyr6XyylVk+wfCVgw8uljN48yhAJhKcUJtriMSC6DNJwLYXbA3a91U4lAyy5DOs3BRP2vavJlKr7ywaWsqz58/k/VDy98V5wB4NWkMsgR7bE4i+BxarRJfKxdKlLBBxMV4oPv0LKu8MyT9ZVUoCgLdrApFQdCZGmxRbhpPqkOgYlmimtiC2XtAPxKvv/Zq1u+EE8nF45X51HwosRCDKuq5nMQeB0A6D7g74p57SE3FXE2O+M5iqpEIMEdSe5jwfMC7Rsg9MQuqog+LYOtSjVguVk6OWywrcc/vOVvq4FcuT+WZvTNY252/vS2Vz//Ix1L5ki99nvVDDd+yRaXvrFIjkh2EgeMiMH14J913Tw3daKLkCaiclQqvMPcfV5J77H3vp1xTYczXreTSHFlgvjGmDO6aNncKy++MLkF+Lw7kEZ45wHP+ZoecSEyfWGDiehb7dzroL6tCURDoZlUoCgLdrApFQdBh3mBjoklami3LHWIpREE82zZIFDL0tLgut5PO/sePpvLnLud1WTByJ/bB7SJsqPEm1lfhczzjjDNS+Qtf+wLNV7oSco7P0TshrQus6M0SyFW4Xc3qBAkXVQwJvc58z3tT+fbf3cb6fewDRM2UOW5Xr1mfym8+hSKKLr7031k/rF4fijVANmlsAbVP1IBhEURiRXAN6nWKtKmIoGyk3slA/RVHUpV7F8bvqfAxmj4F3JcEpdCHhAHyyaJ9a7kYHJ79Dszo62N/80Ru2VRSjLTphOabjt3xJxQKxX8LdLMqFAVBZ2qwbRlnkq0h2SoGjrpl1XIMsB5rkrrymhN5TqDf/eqWVH7zSSeztiNfu5ImDapYCOrPxLVIXnnSCazttluJMXX1ldem8tv/7l2sH96abWerdv09vaytAjmFD1p2cCrXZnG1KYY8yo7NH4EDY5z5/jNT+S+OPZr1CwJSTZtxjbXtfwa5wK47mMa753d3sH6r3khr3LJ4xW2s6oFRSGEg61ZgTmGZY5kGqZTRfcJVbgz6rlT4vRx2+OGpvGA+uUyCiJeXRBdeIswwDNxvhSIRgKxPOgnXlmoqPSdPRHMZO0N9FkOgWiyDz2UShemgv6wKRUGgm1WhKAg6zMFkjOdN/Lb/3elvZ20HLl2cyuNYLcsY883Lv5jK74dTzDDkAcQr/5II71+8lLNt7r+dTkN3DFNayze8iavLmINp29gIa1ux6rhUfs/baf4P/f4+1g+J/ILPbVoQfH3c8VzNPupYUj/dPlLnLEGgT4B989rXcZL/xRdekMp1OKmUJ5A7d1Fuoursw1nbICSAuukxCjh/wys4Sf5nP/5ZKp/90Q+ztg0bn0hlLDlx+GFHsn6Yj8gV6ufmTeQFwBNTVwQNNJuUi+uk1/P1WLyY2G+VCqisDaGK5gZHZLOCUDVlSQHa0qqCmSfGa7bonahUsEq8GMH+83mW8qC/rApFQaCbVaEoCHSzKhQFQWcJ03pqycHLJ1wSQSxZP9l2QRiR7YWuiTiSERyQ31UwWdiJOPgVpDmSsIiZ7GRqyJqJZSmG3VySPFsI5yHvBQO4o0i4OzyIXoLx/SbPsWyB+2r+67/B2uI+svOc58nW3/rHK/kkIxrTEtFLGFTeCsg95snSkGB/jgzyhGw7X3yehoP7lOuGa+UKV4rnTZ+/GEuoGGNMq0nun0C4RQKMvhK5fPEFQnKW3BclsEUrM7jt3z9nHgxP43nCNsfnLrxXaY7hNfeuNqMjI5owTaEoMnSzKhQFQYdE/iQ9grfamD3Tq2/G8JIQqMpI9RCP0dtyv8bZqm8WZG5WZMrwquJSNTKZbRGrui5cMqBOY1W9Qw5exvo99NAaGj/nND/w6Vo9VZ5zaGiY2hbMqrK2JwMKKAhfIBdMxeZqWb1OLoculzNoIoeeWU+ZAun9BmeM4Zi1WbNZWzBE+ZPKVXK17Nixw2QBkwwYw2MqsLpfEGTncZLPBZ+1ZArxIA50/4hnC2r8wgULWVuIfVkOLf7+BRGtnWSuxZMflBXXEfrLqlAUBLpZFYqCQDerQlEQdJwwbSocwxEf5XaqiHqAaIw4xiN8WUEaaH5tLhk4fk/AthVB03kuE/x7dylocnz2OYeP4UDSsRIE53/rK19j/Y5dRRFEjYhHuxi4nge5jestXiZx7eo/pPLbL/gRaxtYQAnUNm55mOYkErzdfy8lYTv2RE6djMEVF/i09rawbX/6E6Is3n4rLz153vmUrK2nSnMa2rWT9UN6Z0nYlBa4Wv7mb6hS++f+/cus3+Ilc+Avfp/szZTPE16RtWupJOZV3/4O6/fNbxBl1o/4c/+nf6S6Rm95C5WsPOEkHlUWOnDeIX03MhH3NNBfVoWiINDNqlAUBB3nYLKSiY9EksFkfOzGYLFjdfojjz2VVRLPGJ5PNyv/6nRguXJAJX6puXJkZWsXuv72ll+n8umQ+8kYY+66jVhFx7yOq5+YEwhdTbYlzI6Y2rbe/U3WNuRek8qeTzmpZkAuY2N4blyx3IzVhWvatr7ge/JFYDr+uX0HlHIUQ6A7RZLJMDDrjNPfQUO4XNU995zzUvnzX7yYtbH5Gwlw10DZyyDm43sVYJ2JwPQvffMrqXzTf/5nKt/5G543a+VJq1K5KSLO2sqSTAP9ZVUoCgLdrApFQdCRGpyYxASTP9/yVI2pkla2CsvUW0H+T5LpZQkkd0ciGKCNjZQB7CfLLSD7qC1NKUzZczkjaNmBVAE7hCD1b3+PV0hPYM6vWLw/a7t//UM0PrDEWoHMHUTXHos5q8iDCnCJS9faKYLxmQposp9ZrikAy+1WuCqXRDSP976PKu594xtfZf3QnAiFefXcphdS+eprr0/l+9Y+yPp95OMfT+VLL7uEteEBNp5sG2OYjWbBCX4U8PXACuxGlO4IwQR89pmnU9kWQRpBSH/LeTiVP78V9ZdVoSgIdLMqFAWBblaFoiDosPK5RZXP5Vk/IM8VwlhEstQi2AJ5zCT8jpE2ah6DCe0wbJOBzFmfMcYwyy7x+Rwv+exnUnnFSqo4XinzqJiuEkWg/Oamm1nbihMoqdt4azyVZ1R5Wcc4Y02NMSaEZ4OB/yURDI0VyGU0SpjxLKT92gXV02PhuilD2ZArv0WB720B92CbD/QvYG3vfhfldL7jTu4KQbxiX0rY9+zGzaxt8T7z4VoiigqYRF1Q1sMT70Sc4fabaKT3/ac//Xkqn3zqm1k3C3x7bizzRf/5ZGr6y6pQFAS6WRWKgqCzHEy1anLAYQcYY4wJQ8lgwlF3z50SC3WIk/zbmPypiO6aNhYRBCj7PmeJZBH581hQ0q3D7kWsHar7qFbKana45tKcKMPwuyA3sKwU199PwehDQ9wl09tHOYJaUEEtFrmJ+vup35jI9eyACovrMz4+zvrNrJKKX/dlUALd57x+Itqvvu9u1m3uPGqTTC0shfHcc89RP7EelRLN44gVx7C2wa2bUvnpp59gbd1Vyse83/4HprLn8vGPWE6V5i3xzv3opzemcrWH5pFnosnnPuUuXHvfGjM2Mqo5mBSKIkM3q0JREOhmVSgKgo5s1u5ad7L/wUuNMflB2WVBncIkWNhP2r08ny5vQ9vRtjHZGVfv8+iGaM+20QgBeZE7PHFbdj+WUE4sMctZLF1gYA8leC1po4EbJt82h+ii3SgrOAVcK7TF81xZMnRn69NEvauPU/C8HAOTxsn003Gyey6kMtiYnkhGhjmup6LG6HpY1wjOTIRXE89JZi/iCdNKYLeXy+T+CcPs8w4ZXVQqTzzPdfc9qDarQlF06GZVKAqCl8xgksoz5tHJi4RB9UWqdqgaOCL3q9sFkTAQveBWRBkFUJcrMR9jbv8sGiMgN8OOMe6OiKBcRCTyx9ouXc+yRfkPCCi24XOhyNmDqqksH1gOqS0qkX4481XnsX4OqHYbnlrL2mbtogDo8Qao+zmuBMlgwsD3PPMhL49ybSaxruqNscx+PNpKuMPY+CYTmOfXjyS7DlhWCXdf2TAXLG1ZKvM5WjDm+PAwayvXKE9zq5Wt7ocwviNyOO9OLmz9ZVUoCgLdrApFQdBZ8HmSpBW65K82qkp5J7LNJqmYMu8MMkN8kQOnDCyas//Xe1P5Na96JR8DSnVs3jrE2mb2kVoWwUndE888w/rtt2RJKncJQveuMaq89k//egFra8BJY+iQmuMJdRlPV13Bbgogt5BbfkUqO/sey/p1Q+rKffc5nrVtvYEqude6SZ2NPBnsTypnKNhNWXmXJNsLA/XH65zB1AvV2nds2YIXZv1QB5SVBbPepbZUUBmm1p9DklHORa5HGdLCjo2MsraBRYvg2vT/eeR8OUWas5bPUCgKD92sCkVBoJtVoSgIOnTdmFTZliUZ8/R9xqJhidVE1A1EWBx+wAGs7V/P+VAq/3EdlUy89lpeOuK0U09L5fl7zGNtMQRio718xIEHs37XXE9RFCuO4xEcNiQju/qrl7O2NY9TRMfnvkwlM/LKV0qbNbRpXosWUQD7eMzXNACbeI7NbcVhSODVBLeRJwy9AJhPbW40MKpY/mIZ6N6iMcoet+/9AN0YODbrZhwYsy1fNDDB8lhnhiUdECVHo2zWGU6FlSMVpVEw+FyWO8VkapgILRb2J66ptGenrp1nbesvq0JREOhmVSgKgs6I/NXuZOnBE+ppLPLMul62GpwN/l2xYjlVCD/vAx9gbb++lVg5fTMo8HrZoYfwebi7l+82DwmyyS2urjQg79JT6x9hbYceRsHLWwYpcPzcf/sUHz/HFZI0yTW05PTvpvK428/6hVARbqC5hbU9fOMHaXxWJoSr3Hm5k1FdRFW9jZUDn4tz1tsCetrGJx/n88B+UoWFhARJTt4vZGAF8v3LycuVZZJEQiEtwcd8MY2F+y5NZct5ae/f1PzXP/CwGR8dVyK/QlFk6GZVKAoC3awKRUHQsesmdUMIt0tWsjBj+JE70g3LXhfrd+7fUz2UuMGTgB1/PFULt1k5QnHUD23JNAX+dge8Iju3f6ou3cuhhyxlbWjrzoNkZFVh945i5IcwgFoxJCBzyfXk2jwyyI9o7TY9cjtrc6C4i4VlDIVdijaVzCkchGiLwnob6dKASBKP36cLNnIL6t7MnD2b9RveTuUgpZ3HrpZTfwdtT2nbui7NS5qRrNxkjmvFMtgmgudhXlFOcoK8+kG7Y9/qL6tCURDoZlUoCoIOSz5SaUBbBhCD5hGKcnn4C+8C8wZdNcYYc+MvqFq4K9gw9WFyhcyZR2rUkUe9ivVrjFCQc7WPq1tdXaTabN9BETmlhOcw6pnRm8p/up+XFlz/GLkd5s3j45944ompPDpKkRmfvfgTrN9HL6C/E5erSgOzDkrlMIEA8ICX4Ci7NOddg08ZDrrPyML8Q1zVwnzGYSSCskHVw/IisUgehKURpdrHc0NRv2ofLwWya+cgXXc33R2S6cSSGrRFcoOrTObsQhU2QlVamHk25H+S6i2oyFgUveTx7YV5sVsRN0mmWGJxnH3/+suqUBQEulkVioJAN6tCURB06LpJUltB2gx2TuQE2gU2HInvtc/erN8xy6ieSKnE3T8NsCsTsIXK4g66+sm2833u7nAispdnz6AkV65TY/18nyh/K17F7eqjj6K/ZTSNA/bhzB5yrYwJGx4petJC6V1K9MkGfpcKWzGACCVvbCdrq1u0PiXIKCHtTczz2+Y6gD/r9XpmPyzbmZdFIoBkcjJ6hmV5EFTBvGRqCBzTcWWGhmyXSWZOZHEpjORJrOzfOE7h5PfSgve2VJFlRq32OcixM1sUCsXLCrpZFYqC4CXnDZY/13m5ZVH1xbaf/fIXrN9pb3hdKvsi2LofmD276qROPPbok6zf4M4dqXzc8cextgcfovy6W7ZT7tetW55j/QZmkUtm2bLDWNv6xx5L5de/9gTWlgBLB9lTax7keX0bAarxXN3vPZCC3cOIVKW612T93IRUzLFgkLWVIlArodq2E2eXtmx7ZsC6cnKeLTKAZLQVKxPCynuKnNCgLsuc0xFTW6FkotAWWYI3wbJK4my3C6rurDSKLdxc4A6LjXT/TD/ftrKOsFZtQfDKYFIo/udAN6tCURB0fBqc9XPtQy4eeRqHBHL8+ZenpOM+jV0WB3rY877V96ZyX99M1g9VjWajztpmA4H8wEMOT+Xt215g/Wb0EsNGVmg74pVQAVtWPEO1B3IpXfGtq1i/Sok+2Ix7WNugNZDKJahw1kj4gsx1idH1gs+rlrtQySwwQMjPYf1URH7kKKPSnRyDV/ezM9sYxMJ1d9PJ/NCoqMDOWFbZRHtUz+UpLDKJ8vJh5RHtmXouKp9jNfiuKnkW8iqfS1QmK83L/FEI/WVVKAoC3awKRUGgm1WhKAg6rnUThhPRAeUSDxxPnJx9j0fbePQv7Id3nnVWKv/gm19nbd3gylm1kuq+SHeBh3l4hYlQmz8H/iJbdI+5PHomhiDynm5+nzYEo/eU+D2PgjvlHR/8GI3n8okkUKV7YGA5a3PBOo8g0L1blAQfenYDjS/tN7BhE3ANOcKGQhtNJjuLYL2Z7SWiQlhlcmGjskrlYIs5Lp9HuYvWuC2BHLwjZQiQb0/Khwyj7Dm2A+xguM8oEs8Mc+iJ8epQ+8bGwH/BdHJwj4iom8bYZNRNTm5k/WVVKAoC3awKRUHQkRpsWVbKVMKSCsYYUyrR0b88HsfgZR/UT6lSodrwt2d9kLV9Esor7rMHqa1dZZ476IF1FIi91z57sLY/3f9AKr+waVMqn/HXb2P9BgcpMN1v7GJtRxxORPvnt+1gbWedd34qD48S48jyhErVoGWfPZ8HCozB0sU2sbYswejqNVB20BHuCGDbuBnB1RKSUZOVU1i6YxjTSeYtwtzD8GwDn4+BAQaJcF0kYfacs+a7u+UrjRGuG1DP41gGFGRXiY8gcD+LEWWMKEMiXJNTKriWz1Ao/gdAN6tCURDoZlUoCoKOat1UuirJoiUTJdmlfcL/lt8BEHwONokfcLsXh8ijxtlA5TvikINYv4vOJ7sxDjhVMADbAl08ccTnERka/2vf/j5ru+8BKjeJAdVyjpgfWdo4eG+Szojr6OTVmMkKmpbXAzdGC+roGGNMpQJJ2BIZSUJ/47Xags9ZLR3+TjDbEQLzA3Hegc9ibGiItQUtWscwzKY9hjAvGWPvQFK6sqj3k5VoTdbLwevJ+/QgUcLA/Pmp7IuJlODaMmrInRzzyYefMvXxhta6USiKDN2sCkVB0JEa3NXdlSw+YLExJj8HkxwTA9MTUA1aLR5QnVflmh2dgxoStKlldC3HZKuHqKLFDnf/YHkOQbYxdYiwKItIFVnFfApS1UVMRVtMAY/38Z7l2M0WRRRhrqO868l+FvPcCc0L1cq8nLygZnsibxaucQAmjyv9FsiCavJ3YniIXGetVnZVcV4+Q0wRnmFFlvhAcwiji3LKc8h334Gonvl77pnKQSwC+jGflGD8TanBTz36jGmoGqxQFBu6WRWKgqAjBlOcxKn6lcd4scVpWQsYK8hkaSvnkCDThH+PRKBSWKC6uEJdxvw7ccKZMhiUjLN3BGnbBjXNEt9nqOolhl/bh/FZRW1xL8gCqofZp8FI6m4F2SeoRjCTKkB4TzBvUcjn6zDGDl+DABg8rHq6uBcfTtijplxvTHVK6v6eey9i/TZtJNbZlq28ijtPwYREe/ncYV6CyI9jxKKtieuP+ZOkeYXvu/iJw9VHE6Qt+BxkeSKeTL5zsmwHQn9ZFYqCQDerQlEQ6GZVKAqCjmxW27LS4/+2E3y0RUXkROBPfySep9O3XRvLc4C9IscIA2jLCYhHhkpJMozg7D/0ZfQF2GFtthFUEkc3ibQpwV3THkQ9PfKqyee53/KqlqN9lAgGU2jQ/gY2U45NJeex/QWyPyGVsRncsoH1i304j5CV1Vn9DBIti68HMqSkawXXWwa+tzJKg+RFEMkA8XkL5qZyXuVz5ooTtv9U35zqGfrLqlAUBbpZFYqCoOPK51MqRrvrhn7ig5bIFxsz/QX+OztXThtZGtTAIIQ8xGKOWIXaE8wkVDkjIIUHlpgvI4ULtgrMS6osqJqG4MZJJBsL5LJgFSGDCa8l1X2p6rHxMV9QBLmP2qq8EQOrzWUQTv/MuKNCqL7iPmfPphzIGNggq4+7feiukhX3aB1bTXKLSHZQEmfnicJg91ZLPE9gvOG6tZXxiFC9Fao0zMuCivHtlfnQBBS5piZzMuWZNPrLqlAUBLpZFYqCQDerQlEQdJw3eIoqJ6NF0F6z29Tu6YN68462bVEvpyWiMdLrigReLuRtDXxO6UKb1XOQHinLV9IYkUjulVeZugI2IF5LRucgJU0mIMMoEKRHykga10ZXmbBn0d7KKevYhGB06W5DwzqEMwJXBG/jfB1xn80mrX8J3FwyggjdXI06r09UQeon2KJxS1A9E/hbuhXh3mzpKYund21VStnROfLdL8O7FOa4XpC26YoIpcy6QAD9ZVUoCgLdrApFQdBR8LllWduNMRv/66ajUPx/j72SJJk9XUNHm1WhUPz3QdVghaIg0M2qUBQEulkVioJAN6tCURDoZlUoCgLdrApFQaCbVaEoCHSzKhQFgW5WhaIg+L/imk3uPf+MagAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "243/243 [==============================] - 1s 4ms/step\n",
            "Predicted Rating:  70.27294635772705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cr6UUJD_auqD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}